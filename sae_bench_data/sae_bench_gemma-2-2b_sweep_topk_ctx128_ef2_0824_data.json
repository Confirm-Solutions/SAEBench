{
    "sae_config_dictionary_learning": {
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19/trainer_4": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 320,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19/trainer_3": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 160,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19/trainer_2": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 80,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19/trainer_5": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 640,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19/trainer_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 20,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19/trainer_1": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 40,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11/trainer_4": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 320,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11/trainer_3": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 160,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11/trainer_2": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 80,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11/trainer_5": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 640,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11/trainer_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 20,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11/trainer_1": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 40,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7/trainer_4": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 320,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7/trainer_3": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 160,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7/trainer_2": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 80,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7/trainer_5": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 640,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7/trainer_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 20,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7/trainer_1": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 40,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_0_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 20,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_3_step_29292": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "29292",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 160,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_1_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 40,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_1_step_9764": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "9764",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 40,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_3_step_19528": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "19528",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 160,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_2_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 80,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_1_step_29292": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "29292",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 40,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_4_step_19528": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "19528",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 320,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_4_step_29292": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "29292",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 320,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_0_step_9764": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "9764",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 20,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_1_step_19528": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "19528",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 40,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_0_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 20,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_4_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 320,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_5_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 640,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_5_step_9764": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "9764",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 640,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_2_step_19528": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "19528",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 80,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_1_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 40,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_3_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 160,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_3_step_9764": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "9764",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 160,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_3_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 160,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_2_step_29292": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "29292",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 80,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_4_step_9764": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "9764",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 320,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_5_step_29292": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "29292",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 640,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_4_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 320,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_0_step_19528": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "19528",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 20,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_2_step_9764": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "9764",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 80,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_2_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 80,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_0_step_29292": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "29292",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 20,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_5_step_19528": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "19528",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 640,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_5_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 640,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_0_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 20,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_3_step_29292": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "29292",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 160,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_1_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 40,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_1_step_9764": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "9764",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 40,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_3_step_19528": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "19528",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 160,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_2_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 80,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_1_step_29292": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "29292",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 40,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_4_step_19528": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "19528",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 320,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_4_step_29292": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "29292",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 320,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_0_step_9764": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "9764",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 20,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_1_step_19528": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "19528",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 40,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_0_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 20,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_4_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 320,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_5_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 640,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_5_step_9764": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "9764",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 640,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_2_step_19528": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "19528",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 80,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_1_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 40,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_3_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 160,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_3_step_9764": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "9764",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 160,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_3_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 160,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_2_step_29292": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "29292",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 80,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_4_step_9764": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "9764",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 320,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_5_step_29292": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "29292",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 640,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_4_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 320,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_0_step_19528": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "19528",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 20,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_2_step_9764": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "9764",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 80,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_2_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 80,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_0_step_29292": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "29292",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 20,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_5_step_19528": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "19528",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 640,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_5_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 640,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15/trainer_4": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 320,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15/trainer_3": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 160,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15/trainer_2": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 80,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15/trainer_5": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 640,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15/trainer_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 20,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15/trainer_1": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 40,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3/trainer_4": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 320,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3/trainer_3": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 160,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3/trainer_2": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 80,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3/trainer_5": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 640,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3/trainer_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 20,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3/trainer_1": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 40,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_0_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 20,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_3_step_29292": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "29292",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 160,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_1_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 40,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_1_step_9764": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "9764",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 40,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_3_step_19528": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "19528",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 160,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_2_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 80,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_1_step_29292": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "29292",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 40,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_4_step_19528": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "19528",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 320,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_4_step_29292": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "29292",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 320,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_0_step_9764": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "9764",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 20,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_1_step_19528": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "19528",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 40,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_0_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 20,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_4_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 320,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_5_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 640,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_5_step_9764": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "9764",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 640,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_2_step_19528": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "19528",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 80,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_1_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 40,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_3_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 160,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_3_step_9764": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "9764",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 160,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_3_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 160,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_2_step_29292": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "29292",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 80,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_4_step_9764": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "9764",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 320,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_5_step_29292": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "29292",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 640,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_4_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 320,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_0_step_19528": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "19528",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 20,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_2_step_9764": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "9764",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 80,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_2_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 80,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_0_step_29292": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "29292",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 20,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_5_step_19528": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "19528",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 640,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_5_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 640,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_0_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 20,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_3_step_29292": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "29292",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 160,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_1_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 40,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_1_step_9764": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "9764",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 40,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_3_step_19528": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "19528",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 160,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_2_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 80,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_1_step_29292": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "29292",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 40,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_4_step_19528": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "19528",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 320,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_4_step_29292": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "29292",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 320,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_0_step_9764": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "9764",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 20,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_1_step_19528": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "19528",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 40,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_0_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 20,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_4_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 320,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_5_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 640,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_5_step_9764": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "9764",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 640,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_2_step_19528": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "19528",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 80,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_1_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 40,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_3_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 160,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_3_step_9764": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "9764",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 160,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_3_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 160,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_2_step_29292": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "29292",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 80,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_4_step_9764": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "9764",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 320,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_5_step_29292": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "29292",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 640,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_4_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 320,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_0_step_19528": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "19528",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 20,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_2_step_9764": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "9764",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 80,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_2_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 80,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_0_step_29292": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "29292",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 20,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_5_step_19528": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "19528",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 640,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_5_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 640,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_0_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 20,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_3_step_29292": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "29292",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 160,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_1_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 40,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_1_step_9764": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "9764",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 40,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_3_step_19528": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "19528",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 160,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_2_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 80,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_1_step_29292": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "29292",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 40,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_4_step_19528": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "19528",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 320,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_4_step_29292": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "29292",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 320,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_0_step_9764": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "9764",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 20,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_1_step_19528": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "19528",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 40,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_0_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 20,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_4_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 320,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_5_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 640,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_5_step_9764": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "9764",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 640,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_2_step_19528": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "19528",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 80,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_1_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 40,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_3_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 160,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_3_step_9764": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "9764",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 160,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_3_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 160,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_2_step_29292": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "29292",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 80,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_4_step_9764": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "9764",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 320,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_5_step_29292": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "29292",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 640,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_4_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 320,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_0_step_19528": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "19528",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 20,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_2_step_9764": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "9764",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 80,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_2_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 80,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_0_step_29292": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "29292",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 20,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_5_step_19528": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "19528",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 640,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_5_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0003771236166328254,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 4608,
                "k": 640,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        }
    },
    "basic_eval_results": {
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19/trainer_4": {
            "l2_loss": 94.48051452636719,
            "l1_loss": 2869.244140625,
            "l0": 320.0,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.8476707935333252,
            "cossim": 0.9440741539001465,
            "l2_ratio": 0.9446847438812256,
            "relative_reconstruction_bias": 1.0003492832183838,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 2.508500814437866,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.9924483299255371,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19/trainer_3": {
            "l2_loss": 96.97393798828125,
            "l1_loss": 1671.353271484375,
            "l0": 160.0,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.8248580694198608,
            "cossim": 0.9401258230209351,
            "l2_ratio": 0.9414183497428894,
            "relative_reconstruction_bias": 1.0012860298156738,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 2.5659074783325195,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.9867191910743713,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19/trainer_2": {
            "l2_loss": 119.04573822021484,
            "l1_loss": 1195.563232421875,
            "l0": 80.0,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.755996823310852,
            "cossim": 0.9124487638473511,
            "l2_ratio": 0.9094276428222656,
            "relative_reconstruction_bias": 0.9973056316375732,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 2.643705129623413,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.9789550304412842,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19/trainer_5": {
            "l2_loss": 74.29061889648438,
            "l1_loss": 5305.4443359375,
            "l0": 640.0,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.9836488962173462,
            "cossim": 0.9689752459526062,
            "l2_ratio": 0.9680597186088562,
            "relative_reconstruction_bias": 1.000023603439331,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 2.4771974086761475,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.9955723881721497,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19/trainer_0": {
            "l2_loss": 139.7944793701172,
            "l1_loss": 592.4727783203125,
            "l0": 20.0,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.6663755178451538,
            "cossim": 0.8737000823020935,
            "l2_ratio": 0.8763696551322937,
            "relative_reconstruction_bias": 1.004531979560852,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 2.9560647010803223,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.9477818012237549,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19/trainer_1": {
            "l2_loss": 122.14802551269531,
            "l1_loss": 799.7659912109375,
            "l0": 40.0,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.7167680263519287,
            "cossim": 0.8975834846496582,
            "l2_ratio": 0.9016139507293701,
            "relative_reconstruction_bias": 1.0039094686508179,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 2.777651071548462,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.9655873775482178,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11/trainer_4": {
            "l2_loss": 41.90699005126953,
            "l1_loss": 1377.961181640625,
            "l0": 320.0,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.9864957928657532,
            "cossim": 0.9463949203491211,
            "l2_ratio": 0.9470862150192261,
            "relative_reconstruction_bias": 0.9996516704559326,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 2.471369981765747,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.9961540102958679,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11/trainer_3": {
            "l2_loss": 54.310035705566406,
            "l1_loss": 828.75244140625,
            "l0": 160.0,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.7805294990539551,
            "cossim": 0.9223535060882568,
            "l2_ratio": 0.9223586916923523,
            "relative_reconstruction_bias": 0.9998683333396912,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 2.507658004760742,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.99253249168396,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11/trainer_2": {
            "l2_loss": 54.87159729003906,
            "l1_loss": 723.476806640625,
            "l0": 80.0,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.9748724699020386,
            "cossim": 0.9227075576782227,
            "l2_ratio": 0.923245906829834,
            "relative_reconstruction_bias": 0.9991494417190552,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 2.568875789642334,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.9864229559898376,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11/trainer_5": {
            "l2_loss": 37.13270950317383,
            "l1_loss": 2475.72412109375,
            "l0": 640.0,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.8971688747406006,
            "cossim": 0.9678254127502441,
            "l2_ratio": 0.9685451984405518,
            "relative_reconstruction_bias": 1.000097393989563,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 2.448883295059204,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.9983981847763062,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11/trainer_0": {
            "l2_loss": 67.49139404296875,
            "l1_loss": 374.22015380859375,
            "l0": 20.0,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.964016854763031,
            "cossim": 0.8791265487670898,
            "l2_ratio": 0.8818876147270203,
            "relative_reconstruction_bias": 0.999987006187439,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 2.8616955280303955,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.95719975233078,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11/trainer_1": {
            "l2_loss": 62.41285705566406,
            "l1_loss": 355.3955993652344,
            "l0": 40.0,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.6621794700622559,
            "cossim": 0.8916462659835815,
            "l2_ratio": 0.8916468620300293,
            "relative_reconstruction_bias": 1.0010241270065308,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 2.665125608444214,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.9768173098564148,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7/trainer_4": {
            "l2_loss": 30.146133422851562,
            "l1_loss": 963.605224609375,
            "l0": 320.0,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.8677959442138672,
            "cossim": 0.9525677561759949,
            "l2_ratio": 0.9551536440849304,
            "relative_reconstruction_bias": 1.0028576850891113,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 2.47757625579834,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.9955345988273621,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7/trainer_3": {
            "l2_loss": 33.76993179321289,
            "l1_loss": 548.6383056640625,
            "l0": 160.0,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.821861982345581,
            "cossim": 0.9382086992263794,
            "l2_ratio": 0.9394890666007996,
            "relative_reconstruction_bias": 1.00113844871521,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 2.510012626647949,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.9922974705696106,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7/trainer_2": {
            "l2_loss": 38.483734130859375,
            "l1_loss": 407.1531677246094,
            "l0": 80.0,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.791956901550293,
            "cossim": 0.9279565215110779,
            "l2_ratio": 0.9268617033958435,
            "relative_reconstruction_bias": 0.9985658526420593,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 2.5364067554473877,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.9896634221076965,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7/trainer_5": {
            "l2_loss": 23.207204818725586,
            "l1_loss": 2115.75634765625,
            "l0": 640.0,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.991014301776886,
            "cossim": 0.9709804058074951,
            "l2_ratio": 0.9717317819595337,
            "relative_reconstruction_bias": 1.000156283378601,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 2.448847770690918,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.9984017014503479,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7/trainer_0": {
            "l2_loss": 47.487998962402344,
            "l1_loss": 301.2238464355469,
            "l0": 20.0,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.9622535109519958,
            "cossim": 0.8962193727493286,
            "l2_ratio": 0.894823431968689,
            "relative_reconstruction_bias": 0.9997734427452087,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 2.7507824897766113,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.968268871307373,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7/trainer_1": {
            "l2_loss": 40.47846984863281,
            "l1_loss": 266.11810302734375,
            "l0": 40.0,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.7353709936141968,
            "cossim": 0.9043003916740417,
            "l2_ratio": 0.9059428572654724,
            "relative_reconstruction_bias": 1.0038297176361084,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 2.6081817150115967,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.9825002551078796,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_0_step_0": {
            "l2_loss": 140.22834167480468,
            "l1_loss": 98.64285278320312,
            "l0": 20.0,
            "frac_variance_explained": 0.050036942958831786,
            "cossim": 0.2577689528465271,
            "l2_ratio": 0.1593092456459999,
            "relative_reconstruction_bias": 0.6184685826301575,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 16.008501625061037,
            "loss_zero": 12.452933025360107,
            "frac_recovered": -0.3552884042263031,
            "frac_alive": 0.3155381977558136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_3_step_29292": {
            "l2_loss": 54.63136711120605,
            "l1_loss": 881.3888854980469,
            "l0": 160.0,
            "frac_variance_explained": 0.8345121264457702,
            "cossim": 0.9252553105354309,
            "l2_ratio": 0.9256245136260987,
            "relative_reconstruction_bias": 0.9998716294765473,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.5540466785430906,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9894868016242981,
            "frac_alive": 0.934678852558136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_1_step_4882": {
            "l2_loss": 64.76068153381348,
            "l1_loss": 465.4642364501953,
            "l0": 40.0,
            "frac_variance_explained": 0.8046410381793976,
            "cossim": 0.8882701575756073,
            "l2_ratio": 0.8901397287845612,
            "relative_reconstruction_bias": 1.0015433490276338,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.7527161836624146,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9696499407291412,
            "frac_alive": 0.704210102558136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_1_step_9764": {
            "l2_loss": 64.46492881774903,
            "l1_loss": 379.1844207763672,
            "l0": 40.0,
            "frac_variance_explained": 0.6922758400440217,
            "cossim": 0.8899014353752136,
            "l2_ratio": 0.8929189562797546,
            "relative_reconstruction_bias": 1.0026697158813476,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.731973338127136,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9717266738414765,
            "frac_alive": 0.7269965410232544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_3_step_19528": {
            "l2_loss": 55.64139862060547,
            "l1_loss": 807.5322570800781,
            "l0": 160.0,
            "frac_variance_explained": 0.7856369316577911,
            "cossim": 0.9218478798866272,
            "l2_ratio": 0.9234746754169464,
            "relative_reconstruction_bias": 1.0013280093669892,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.5544615507125856,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9894399881362915,
            "frac_alive": 0.9259982705116272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_2_step_0": {
            "l2_loss": 143.93877716064452,
            "l1_loss": 363.6844970703125,
            "l0": 80.0,
            "frac_variance_explained": 0.1325601279735565,
            "cossim": 0.41495075821876526,
            "l2_ratio": 0.2902939677238464,
            "relative_reconstruction_bias": 0.698175972700119,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 13.765501117706298,
            "loss_zero": 12.452933025360107,
            "frac_recovered": -0.13095996156334877,
            "frac_alive": 0.5881076455116272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_1_step_29292": {
            "l2_loss": 64.33890838623047,
            "l1_loss": 397.7929748535156,
            "l0": 39.954167175292966,
            "frac_variance_explained": 0.7240905225276947,
            "cossim": 0.8950527369976043,
            "l2_ratio": 0.8956998527050019,
            "relative_reconstruction_bias": 1.0003690481185914,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.7170053243637087,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9732168734073638,
            "frac_alive": 0.7059462070465088,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_4_step_19528": {
            "l2_loss": 46.94860153198242,
            "l1_loss": 1319.9393798828125,
            "l0": 319.5625061035156,
            "frac_variance_explained": 0.8729190289974212,
            "cossim": 0.9427316188812256,
            "l2_ratio": 0.9439197540283203,
            "relative_reconstruction_bias": 1.0006155848503113,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.506819009780884,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9941898584365845,
            "frac_alive": 0.9626736044883728,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_4_step_29292": {
            "l2_loss": 47.266455841064456,
            "l1_loss": 1307.7858764648438,
            "l0": 316.9666748046875,
            "frac_variance_explained": 0.8963655054569244,
            "cossim": 0.9429206728935242,
            "l2_ratio": 0.9436131536960601,
            "relative_reconstruction_bias": 0.9998559534549714,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.5019499540328978,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9946748733520507,
            "frac_alive": 0.9301215410232544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_0_step_9764": {
            "l2_loss": 68.22085914611816,
            "l1_loss": 329.7154052734375,
            "l0": 19.983333587646484,
            "frac_variance_explained": 0.7519674062728882,
            "cossim": 0.8745894014835358,
            "l2_ratio": 0.8751376569271088,
            "relative_reconstruction_bias": 1.0012023448944092,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.958352971076965,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9490915060043335,
            "frac_alive": 0.4895833432674408,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_1_step_19528": {
            "l2_loss": 64.14101448059083,
            "l1_loss": 467.503466796875,
            "l0": 39.99583358764649,
            "frac_variance_explained": 0.8552559971809387,
            "cossim": 0.8949825286865234,
            "l2_ratio": 0.8957539498806,
            "relative_reconstruction_bias": 1.0010384380817414,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.7260730981826784,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9723196566104889,
            "frac_alive": 0.70703125,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_0_step_4882": {
            "l2_loss": 70.24636192321778,
            "l1_loss": 339.7719451904297,
            "l0": 20.0,
            "frac_variance_explained": 0.7693337380886078,
            "cossim": 0.8707762777805328,
            "l2_ratio": 0.8716555535793304,
            "relative_reconstruction_bias": 1.0007238805294036,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 3.0010818243026733,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9448277950286865,
            "frac_alive": 0.4678819477558136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_4_step_0": {
            "l2_loss": 124.4012321472168,
            "l1_loss": 1126.9787353515626,
            "l0": 320.0,
            "frac_variance_explained": 0.2962450087070465,
            "cossim": 0.5877427399158478,
            "l2_ratio": 0.5198725759983063,
            "relative_reconstruction_bias": 0.8802358925342559,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 9.55947265625,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.28945784717798234,
            "frac_alive": 0.8569878339767456,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_5_step_4882": {
            "l2_loss": 41.40818634033203,
            "l1_loss": 2255.588037109375,
            "l0": 640.0,
            "frac_variance_explained": 0.8773461401462554,
            "cossim": 0.9557119905948639,
            "l2_ratio": 0.9561412274837494,
            "relative_reconstruction_bias": 1.0000572979450226,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.4832009077072144,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9965398967266083,
            "frac_alive": 0.9290364384651184,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_5_step_9764": {
            "l2_loss": 38.82290840148926,
            "l1_loss": 2625.244921875,
            "l0": 639.333349609375,
            "frac_variance_explained": 0.9560034573078156,
            "cossim": 0.9612709164619446,
            "l2_ratio": 0.9627401769161225,
            "relative_reconstruction_bias": 1.0027657389640807,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.4773441553115845,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9971231460571289,
            "frac_alive": 0.9407551884651184,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_2_step_19528": {
            "l2_loss": 59.21841621398926,
            "l1_loss": 571.2026794433593,
            "l0": 79.90416717529297,
            "frac_variance_explained": 0.7965272247791291,
            "cossim": 0.90695641040802,
            "l2_ratio": 0.9078916192054749,
            "relative_reconstruction_bias": 1.0003175497055055,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.6189221858978273,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9830141842365265,
            "frac_alive": 0.8589409589767456,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_1_step_0": {
            "l2_loss": 144.4525604248047,
            "l1_loss": 192.01743927001954,
            "l0": 40.0,
            "frac_variance_explained": 0.08208202123641968,
            "cossim": 0.3312031954526901,
            "l2_ratio": 0.21455406844615937,
            "relative_reconstruction_bias": 0.6461938858032227,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 15.170895195007324,
            "loss_zero": 12.452933025360107,
            "frac_recovered": -0.27149948477745056,
            "frac_alive": 0.4453125,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_3_step_4882": {
            "l2_loss": 55.39626274108887,
            "l1_loss": 1017.8611267089843,
            "l0": 160.0,
            "frac_variance_explained": 0.8999287486076355,
            "cossim": 0.9238397359848023,
            "l2_ratio": 0.9252147078514099,
            "relative_reconstruction_bias": 1.0004359781742096,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.564697098731995,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9884246706962585,
            "frac_alive": 0.9498698115348816,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_3_step_9764": {
            "l2_loss": 53.795952224731444,
            "l1_loss": 871.8751525878906,
            "l0": 159.97083435058593,
            "frac_variance_explained": 0.8347902953624725,
            "cossim": 0.9241668879985809,
            "l2_ratio": 0.9250428736209869,
            "relative_reconstruction_bias": 0.9996844828128815,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.561699366569519,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9887275159358978,
            "frac_alive": 0.9455295205116272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_3_step_0": {
            "l2_loss": 138.14516525268556,
            "l1_loss": 663.5649597167969,
            "l0": 160.0,
            "frac_variance_explained": 0.20654147267341613,
            "cossim": 0.5051366269588471,
            "l2_ratio": 0.3911669194698334,
            "relative_reconstruction_bias": 0.7679625511169433,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 12.31823787689209,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.013722707331180573,
            "frac_alive": 0.7445746660232544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_2_step_29292": {
            "l2_loss": 58.82225494384765,
            "l1_loss": 555.3606628417969,
            "l0": 79.69583435058594,
            "frac_variance_explained": 0.7911265790462494,
            "cossim": 0.9074726343154907,
            "l2_ratio": 0.9081804633140564,
            "relative_reconstruction_bias": 0.9997006833553315,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.615405488014221,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9833661496639252,
            "frac_alive": 0.87109375,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_4_step_9764": {
            "l2_loss": 49.395613479614255,
            "l1_loss": 1343.3776733398438,
            "l0": 319.92083435058595,
            "frac_variance_explained": 0.8575047075748443,
            "cossim": 0.9374608278274537,
            "l2_ratio": 0.9377544343471527,
            "relative_reconstruction_bias": 0.9991987764835357,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.508084464073181,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9940681397914887,
            "frac_alive": 0.9635416865348816,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_5_step_29292": {
            "l2_loss": 37.907478713989256,
            "l1_loss": 2424.6693359375,
            "l0": 635.8791748046875,
            "frac_variance_explained": 0.914753520488739,
            "cossim": 0.9635128676891327,
            "l2_ratio": 0.9641001999378205,
            "relative_reconstruction_bias": 1.000330775976181,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.4731401443481444,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9975415706634522,
            "frac_alive": 0.8090277910232544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_4_step_4882": {
            "l2_loss": 50.233224105834964,
            "l1_loss": 1231.7789306640625,
            "l0": 319.95,
            "frac_variance_explained": 0.8130932033061982,
            "cossim": 0.9353844404220581,
            "l2_ratio": 0.9370408236980439,
            "relative_reconstruction_bias": 1.0021764934062958,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.516188406944275,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9932597875595093,
            "frac_alive": 0.9644097089767456,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_0_step_19528": {
            "l2_loss": 68.50454330444336,
            "l1_loss": 324.9698028564453,
            "l0": 19.983333587646484,
            "frac_variance_explained": 0.7560151815414429,
            "cossim": 0.8743724763393402,
            "l2_ratio": 0.8766503691673279,
            "relative_reconstruction_bias": 1.0013978719711303,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.944248652458191,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9504948318004608,
            "frac_alive": 0.486328125,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_2_step_9764": {
            "l2_loss": 58.49151840209961,
            "l1_loss": 610.2651336669921,
            "l0": 79.99166717529297,
            "frac_variance_explained": 0.8273317277431488,
            "cossim": 0.9085235714912414,
            "l2_ratio": 0.9099835395812989,
            "relative_reconstruction_bias": 1.0007033586502074,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.6255603313446043,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9823521554470063,
            "frac_alive": 0.8569878339767456,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_2_step_4882": {
            "l2_loss": 60.16131248474121,
            "l1_loss": 581.5718322753906,
            "l0": 80.0,
            "frac_variance_explained": 0.7672513663768769,
            "cossim": 0.9034546434879303,
            "l2_ratio": 0.9044839680194855,
            "relative_reconstruction_bias": 1.0000970840454102,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.6369505882263184,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9812154769897461,
            "frac_alive": 0.8854166865348816,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_0_step_29292": {
            "l2_loss": 68.25609474182129,
            "l1_loss": 304.351416015625,
            "l0": 19.966666984558106,
            "frac_variance_explained": 0.7288932979106904,
            "cossim": 0.8753464639186859,
            "l2_ratio": 0.8757953941822052,
            "relative_reconstruction_bias": 1.0010730385780335,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.9404220581054688,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9508787572383881,
            "frac_alive": 0.478081613779068,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_5_step_19528": {
            "l2_loss": 38.84301834106445,
            "l1_loss": 2392.897314453125,
            "l0": 638.6541687011719,
            "frac_variance_explained": 0.9026995718479156,
            "cossim": 0.9625115990638733,
            "l2_ratio": 0.9631280064582824,
            "relative_reconstruction_bias": 0.9999796211719513,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.4738996505737303,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9974690735340118,
            "frac_alive": 0.8309462070465088,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_5_step_0": {
            "l2_loss": 127.38837509155273,
            "l1_loss": 2074.3221801757813,
            "l0": 640.0,
            "frac_variance_explained": 0.4066521465778351,
            "cossim": 0.656653767824173,
            "l2_ratio": 0.6683750569820404,
            "relative_reconstruction_bias": 1.0112313449382782,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 7.774596166610718,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.46791832745075224,
            "frac_alive": 0.9683159589767456,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_0_step_0": {
            "l2_loss": 81.60491485595703,
            "l1_loss": 58.363695526123045,
            "l0": 20.0,
            "frac_variance_explained": 0.050828677415847776,
            "cossim": 0.2625784814357758,
            "l2_ratio": 0.1624852940440178,
            "relative_reconstruction_bias": 0.6182221531867981,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 13.154533576965331,
            "loss_zero": 12.452933025360107,
            "frac_recovered": -0.07019788369070738,
            "frac_alive": 0.3463541567325592,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_3_step_29292": {
            "l2_loss": 30.037468910217285,
            "l1_loss": 486.1518585205078,
            "l0": 160.0,
            "frac_variance_explained": 0.8068443596363067,
            "cossim": 0.923032534122467,
            "l2_ratio": 0.9244553685188294,
            "relative_reconstruction_bias": 1.0012077927589416,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.555750012397766,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9893117547035217,
            "frac_alive": 0.9418402910232544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_1_step_4882": {
            "l2_loss": 34.91946086883545,
            "l1_loss": 252.42002716064454,
            "l0": 40.0,
            "frac_variance_explained": 0.7625840246677399,
            "cossim": 0.8965424656867981,
            "l2_ratio": 0.897282749414444,
            "relative_reconstruction_bias": 1.001072883605957,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.6890223264694213,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9760135650634766,
            "frac_alive": 0.630859375,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_1_step_9764": {
            "l2_loss": 32.98552551269531,
            "l1_loss": 237.37463989257813,
            "l0": 40.0,
            "frac_variance_explained": 0.7714282274246216,
            "cossim": 0.9096734821796417,
            "l2_ratio": 0.9122908115386963,
            "relative_reconstruction_bias": 1.0030517339706422,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.6778592824935914,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9771290361881256,
            "frac_alive": 0.6141493320465088,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_3_step_19528": {
            "l2_loss": 30.071097373962402,
            "l1_loss": 481.19397888183596,
            "l0": 160.0,
            "frac_variance_explained": 0.779244863986969,
            "cossim": 0.9257762372493744,
            "l2_ratio": 0.9272996485233307,
            "relative_reconstruction_bias": 1.0020264625549316,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.5619956254959106,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9886905431747437,
            "frac_alive": 0.9457465410232544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_2_step_0": {
            "l2_loss": 74.1490852355957,
            "l1_loss": 192.60494537353514,
            "l0": 80.0,
            "frac_variance_explained": 0.14279006123542787,
            "cossim": 0.4221298724412918,
            "l2_ratio": 0.29508012235164643,
            "relative_reconstruction_bias": 0.6993300378322601,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 11.143733978271484,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.13089674189686776,
            "frac_alive": 0.6770833134651184,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_1_step_29292": {
            "l2_loss": 36.0049409866333,
            "l1_loss": 243.7784454345703,
            "l0": 40.0,
            "frac_variance_explained": 0.760254418849945,
            "cossim": 0.8934316098690033,
            "l2_ratio": 0.8959870159626007,
            "relative_reconstruction_bias": 1.00284885764122,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.668852710723877,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9780248045921326,
            "frac_alive": 0.6208767294883728,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_4_step_19528": {
            "l2_loss": 26.96903266906738,
            "l1_loss": 842.4563659667969,
            "l0": 315.5625,
            "frac_variance_explained": 0.8776214063167572,
            "cossim": 0.9405360877513885,
            "l2_ratio": 0.941471916437149,
            "relative_reconstruction_bias": 1.0009671092033385,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.5297523498535157,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9919104397296905,
            "frac_alive": 0.9876301884651184,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_4_step_29292": {
            "l2_loss": 27.61470947265625,
            "l1_loss": 855.1590759277344,
            "l0": 320.0,
            "frac_variance_explained": 0.8281284987926483,
            "cossim": 0.942937833070755,
            "l2_ratio": 0.9441697239875794,
            "relative_reconstruction_bias": 1.001548057794571,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.5254783630371094,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9923313617706299,
            "frac_alive": 0.9752604365348816,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_0_step_9764": {
            "l2_loss": 36.43039379119873,
            "l1_loss": 172.19175415039064,
            "l0": 20.0,
            "frac_variance_explained": 0.705664438009262,
            "cossim": 0.8877724170684814,
            "l2_ratio": 0.8900944888591766,
            "relative_reconstruction_bias": 1.00287966132164,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.751595973968506,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9697539567947387,
            "frac_alive": 0.4249131977558136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_1_step_19528": {
            "l2_loss": 32.99094161987305,
            "l1_loss": 237.34082641601563,
            "l0": 40.0,
            "frac_variance_explained": 0.7646812319755554,
            "cossim": 0.9073082745075226,
            "l2_ratio": 0.9069424927234649,
            "relative_reconstruction_bias": 0.9995895445346832,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.669806170463562,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9779294967651367,
            "frac_alive": 0.6184895634651184,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_0_step_4882": {
            "l2_loss": 36.221987915039065,
            "l1_loss": 170.05139923095703,
            "l0": 20.0,
            "frac_variance_explained": 0.7039879262447357,
            "cossim": 0.889911812543869,
            "l2_ratio": 0.8913323223590851,
            "relative_reconstruction_bias": 1.0020899832248689,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.762668418884277,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9686597228050232,
            "frac_alive": 0.4392361044883728,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_4_step_0": {
            "l2_loss": 72.3552173614502,
            "l1_loss": 659.7115478515625,
            "l0": 320.0,
            "frac_variance_explained": 0.31064493060112,
            "cossim": 0.5923145115375519,
            "l2_ratio": 0.5236501455307007,
            "relative_reconstruction_bias": 0.8829647541046143,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 7.692648220062256,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.4758260101079941,
            "frac_alive": 0.9422743320465088,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_5_step_4882": {
            "l2_loss": 23.077243423461915,
            "l1_loss": 1362.479150390625,
            "l0": 640.0,
            "frac_variance_explained": 0.8888723492622376,
            "cossim": 0.9588618636131286,
            "l2_ratio": 0.9596916437149048,
            "relative_reconstruction_bias": 1.0006249845027924,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.4918998003005983,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.995673406124115,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_5_step_9764": {
            "l2_loss": 21.886396980285646,
            "l1_loss": 1351.7629638671874,
            "l0": 640.0,
            "frac_variance_explained": 0.8795795381069184,
            "cossim": 0.9610089719295501,
            "l2_ratio": 0.9619713425636292,
            "relative_reconstruction_bias": 1.0013710141181946,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.4894513845443726,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9959214448928833,
            "frac_alive": 0.974609375,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_2_step_19528": {
            "l2_loss": 30.81721076965332,
            "l1_loss": 327.5837677001953,
            "l0": 80.0,
            "frac_variance_explained": 0.7958967685699463,
            "cossim": 0.9171338438987732,
            "l2_ratio": 0.9179856479167938,
            "relative_reconstruction_bias": 1.0011873126029969,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.613906002044678,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9835043311119079,
            "frac_alive": 0.8153212070465088,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_1_step_0": {
            "l2_loss": 82.93051071166992,
            "l1_loss": 111.98180694580078,
            "l0": 40.0,
            "frac_variance_explained": 0.08388793468475342,
            "cossim": 0.3367439866065979,
            "l2_ratio": 0.21895972043275833,
            "relative_reconstruction_bias": 0.647374814748764,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 12.368183422088624,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.008452777238562702,
            "frac_alive": 0.4906684160232544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_3_step_4882": {
            "l2_loss": 31.157272720336913,
            "l1_loss": 497.3577911376953,
            "l0": 160.0,
            "frac_variance_explained": 0.760944277048111,
            "cossim": 0.9195334255695343,
            "l2_ratio": 0.921225118637085,
            "relative_reconstruction_bias": 1.0021921038627624,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.579826307296753,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9869141399860382,
            "frac_alive": 0.9609375,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_3_step_9764": {
            "l2_loss": 29.70755558013916,
            "l1_loss": 507.5087097167969,
            "l0": 160.0,
            "frac_variance_explained": 0.7973709106445312,
            "cossim": 0.9268065512180328,
            "l2_ratio": 0.9283122181892395,
            "relative_reconstruction_bias": 1.0018665134906768,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.575825643539429,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9873146176338196,
            "frac_alive": 0.971788227558136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_3_step_0": {
            "l2_loss": 75.71269378662109,
            "l1_loss": 365.96434631347654,
            "l0": 160.0,
            "frac_variance_explained": 0.20976685285568236,
            "cossim": 0.5093407809734345,
            "l2_ratio": 0.39439783096313474,
            "relative_reconstruction_bias": 0.7727922976016999,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 9.364989852905273,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.3086751788854599,
            "frac_alive": 0.8127170205116272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_2_step_29292": {
            "l2_loss": 30.484017181396485,
            "l1_loss": 324.80751647949216,
            "l0": 80.0,
            "frac_variance_explained": 0.8115719497203827,
            "cossim": 0.9194135546684266,
            "l2_ratio": 0.9188806295394898,
            "relative_reconstruction_bias": 0.9996795296669007,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.6142709970474245,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9834712505340576,
            "frac_alive": 0.794053852558136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_4_step_9764": {
            "l2_loss": 26.397164726257323,
            "l1_loss": 803.6726257324219,
            "l0": 320.0,
            "frac_variance_explained": 0.8355386555194855,
            "cossim": 0.9417271077632904,
            "l2_ratio": 0.9428332030773163,
            "relative_reconstruction_bias": 1.0011697351932525,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.526944661140442,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9921814858913421,
            "frac_alive": 0.999131977558136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_5_step_29292": {
            "l2_loss": 21.057858085632326,
            "l1_loss": 1367.2457641601563,
            "l0": 634.3875061035156,
            "frac_variance_explained": 0.9149715840816498,
            "cossim": 0.964511901140213,
            "l2_ratio": 0.9650763809680939,
            "relative_reconstruction_bias": 1.000309282541275,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.48186194896698,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9966731429100036,
            "frac_alive": 0.942491352558136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_4_step_4882": {
            "l2_loss": 26.845576667785643,
            "l1_loss": 847.5353698730469,
            "l0": 320.0,
            "frac_variance_explained": 0.8864954829216003,
            "cossim": 0.939923083782196,
            "l2_ratio": 0.9414181053638458,
            "relative_reconstruction_bias": 1.001222151517868,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.532769966125488,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9916015923023224,
            "frac_alive": 0.9997829794883728,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_0_step_19528": {
            "l2_loss": 37.18422508239746,
            "l1_loss": 181.67832794189454,
            "l0": 20.0,
            "frac_variance_explained": 0.7593629121780395,
            "cossim": 0.8854795515537262,
            "l2_ratio": 0.885137552022934,
            "relative_reconstruction_bias": 0.9994236171245575,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.744368648529053,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9704704642295837,
            "frac_alive": 0.4279513955116272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_2_step_9764": {
            "l2_loss": 30.88884449005127,
            "l1_loss": 347.0178497314453,
            "l0": 80.0,
            "frac_variance_explained": 0.8208382070064545,
            "cossim": 0.9182794332504273,
            "l2_ratio": 0.918784749507904,
            "relative_reconstruction_bias": 1.0004864931106567,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.6195780992507935,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9829427003860474,
            "frac_alive": 0.8344184160232544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_2_step_4882": {
            "l2_loss": 34.026140975952146,
            "l1_loss": 364.8033477783203,
            "l0": 80.0,
            "frac_variance_explained": 0.7647668123245239,
            "cossim": 0.9038422465324402,
            "l2_ratio": 0.9059076368808746,
            "relative_reconstruction_bias": 1.0015076100826263,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.6322536706924438,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9816796839237213,
            "frac_alive": 0.8626301884651184,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_0_step_29292": {
            "l2_loss": 33.00802478790283,
            "l1_loss": 179.9744659423828,
            "l0": 20.0,
            "frac_variance_explained": 0.8063652515411377,
            "cossim": 0.9053735733032227,
            "l2_ratio": 0.9054069280624389,
            "relative_reconstruction_bias": 1.0003725588321686,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.739673066139221,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9709482610225677,
            "frac_alive": 0.4173177182674408,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_5_step_19528": {
            "l2_loss": 21.685357093811035,
            "l1_loss": 1402.634521484375,
            "l0": 638.6041687011718,
            "frac_variance_explained": 0.8937265932559967,
            "cossim": 0.9622324228286743,
            "l2_ratio": 0.9651769280433655,
            "relative_reconstruction_bias": 1.0028077125549317,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.4852607250213623,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9963402569293975,
            "frac_alive": 0.9583333134651184,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_5_step_0": {
            "l2_loss": 65.23782386779786,
            "l1_loss": 1071.1736389160155,
            "l0": 640.0,
            "frac_variance_explained": 0.41862353682518005,
            "cossim": 0.661382132768631,
            "l2_ratio": 0.6705290734767914,
            "relative_reconstruction_bias": 1.0124364614486694,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 6.003529739379883,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.6446952760219574,
            "frac_alive": 0.986328125,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15/trainer_4": {
            "l2_loss": 61.32383346557617,
            "l1_loss": 1747.08349609375,
            "l0": 320.0,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.8432307839393616,
            "cossim": 0.9481091499328613,
            "l2_ratio": 0.9490343332290649,
            "relative_reconstruction_bias": 1.0006136894226074,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 2.4776952266693115,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.9955227375030518,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15/trainer_3": {
            "l2_loss": 68.53919219970703,
            "l1_loss": 1117.41943359375,
            "l0": 160.0,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.8082948327064514,
            "cossim": 0.9321434497833252,
            "l2_ratio": 0.9317147731781006,
            "relative_reconstruction_bias": 0.9995356202125549,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 2.527860641479492,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.9905162453651428,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15/trainer_2": {
            "l2_loss": 71.70529174804688,
            "l1_loss": 743.0734252929688,
            "l0": 80.0,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.7825905680656433,
            "cossim": 0.9230632781982422,
            "l2_ratio": 0.922292947769165,
            "relative_reconstruction_bias": 0.9989379644393921,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 2.594818592071533,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.9838339686393738,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15/trainer_5": {
            "l2_loss": 46.26561737060547,
            "l1_loss": 3198.428466796875,
            "l0": 640.0,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.9107916951179504,
            "cossim": 0.9690170288085938,
            "l2_ratio": 0.9703583121299744,
            "relative_reconstruction_bias": 1.0018606185913086,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 2.450376033782959,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.9982491135597229,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15/trainer_0": {
            "l2_loss": 88.7180404663086,
            "l1_loss": 361.3934020996094,
            "l0": 20.0,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.6500481963157654,
            "cossim": 0.8843460083007812,
            "l2_ratio": 0.8863910436630249,
            "relative_reconstruction_bias": 1.0036771297454834,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 2.9764466285705566,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.9457477331161499,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15/trainer_1": {
            "l2_loss": 78.94015502929688,
            "l1_loss": 512.9586791992188,
            "l0": 40.0,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.7321163415908813,
            "cossim": 0.9140005111694336,
            "l2_ratio": 0.914179801940918,
            "relative_reconstruction_bias": 1.0002009868621826,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 2.7251315116882324,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.9708287119865417,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3/trainer_4": {
            "l2_loss": 25.606550216674805,
            "l1_loss": 867.0609130859375,
            "l0": 320.0,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.8439143300056458,
            "cossim": 0.945669412612915,
            "l2_ratio": 0.9476838111877441,
            "relative_reconstruction_bias": 1.0016050338745117,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 2.4758589267730713,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.9957060217857361,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3/trainer_3": {
            "l2_loss": 35.579776763916016,
            "l1_loss": 532.7467041015625,
            "l0": 160.0,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.7384930849075317,
            "cossim": 0.904355525970459,
            "l2_ratio": 0.9056121706962585,
            "relative_reconstruction_bias": 1.0016363859176636,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 2.50300669670105,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.9929966330528259,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3/trainer_2": {
            "l2_loss": 27.87135887145996,
            "l1_loss": 360.9143981933594,
            "l0": 80.0,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.9545732736587524,
            "cossim": 0.9251397848129272,
            "l2_ratio": 0.9237889051437378,
            "relative_reconstruction_bias": 0.9996307492256165,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 2.5592029094696045,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.9873883128166199,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3/trainer_5": {
            "l2_loss": 20.40424346923828,
            "l1_loss": 1323.970947265625,
            "l0": 640.0,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.8902573585510254,
            "cossim": 0.9654150009155273,
            "l2_ratio": 0.9646708965301514,
            "relative_reconstruction_bias": 0.9998243451118469,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 2.4475302696228027,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.9985331296920776,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3/trainer_0": {
            "l2_loss": 31.408935546875,
            "l1_loss": 217.4376678466797,
            "l0": 20.0,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.9488142132759094,
            "cossim": 0.9213129878044128,
            "l2_ratio": 0.9211422204971313,
            "relative_reconstruction_bias": 1.0002436637878418,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 2.7017786502838135,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.9731593728065491,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_3/trainer_1": {
            "l2_loss": 29.927814483642578,
            "l1_loss": 203.11460876464844,
            "l0": 40.0,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.7205890417098999,
            "cossim": 0.9113695025444031,
            "l2_ratio": 0.9114006757736206,
            "relative_reconstruction_bias": 1.0000991821289062,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 2.617891788482666,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.9815312623977661,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_0_step_0": {
            "l2_loss": 236.66222534179687,
            "l1_loss": 159.2909957885742,
            "l0": 20.0,
            "frac_variance_explained": 0.04329325556755066,
            "cossim": 0.2555850237607956,
            "l2_ratio": 0.1577560633420944,
            "relative_reconstruction_bias": 0.6150440037250519,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 16.14886064529419,
            "loss_zero": 12.452933025360107,
            "frac_recovered": -0.369425630569458,
            "frac_alive": 0.3036024272441864,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_3_step_29292": {
            "l2_loss": 67.4743782043457,
            "l1_loss": 1162.7762878417968,
            "l0": 159.95,
            "frac_variance_explained": 0.8550934016704559,
            "cossim": 0.9350503504276275,
            "l2_ratio": 0.9358275711536408,
            "relative_reconstruction_bias": 0.9997937202453613,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.5751985549926757,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9873783707618713,
            "frac_alive": 0.9422743320465088,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_1_step_4882": {
            "l2_loss": 82.05625076293946,
            "l1_loss": 581.3744140625,
            "l0": 40.0,
            "frac_variance_explained": 0.7542903363704682,
            "cossim": 0.9054535865783692,
            "l2_ratio": 0.9071548998355865,
            "relative_reconstruction_bias": 1.0019328594207764,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.804633617401123,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9644672870635986,
            "frac_alive": 0.6898871660232544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_1_step_9764": {
            "l2_loss": 80.44334411621094,
            "l1_loss": 603.5619384765625,
            "l0": 39.983334350585935,
            "frac_variance_explained": 0.8165294766426087,
            "cossim": 0.9046604216098786,
            "l2_ratio": 0.9073511719703674,
            "relative_reconstruction_bias": 1.0023674488067627,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.792437529563904,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9656919777393341,
            "frac_alive": 0.7024739384651184,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_3_step_19528": {
            "l2_loss": 67.6245849609375,
            "l1_loss": 1170.764013671875,
            "l0": 160.0,
            "frac_variance_explained": 0.8431155025959015,
            "cossim": 0.9361370623111724,
            "l2_ratio": 0.9364897608757019,
            "relative_reconstruction_bias": 0.9993862211704254,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.5758557081222535,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9873120009899139,
            "frac_alive": 0.934678852558136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_2_step_0": {
            "l2_loss": 205.03658599853514,
            "l1_loss": 510.772802734375,
            "l0": 80.0,
            "frac_variance_explained": 0.12847638726234437,
            "cossim": 0.4134197473526001,
            "l2_ratio": 0.28859314918518064,
            "relative_reconstruction_bias": 0.695404314994812,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 13.902075290679932,
            "loss_zero": 12.452933025360107,
            "frac_recovered": -0.14475906640291214,
            "frac_alive": 0.5796440839767456,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_1_step_29292": {
            "l2_loss": 79.60863723754883,
            "l1_loss": 544.8429077148437,
            "l0": 39.99166679382324,
            "frac_variance_explained": 0.7765570223331452,
            "cossim": 0.907872873544693,
            "l2_ratio": 0.9088487207889557,
            "relative_reconstruction_bias": 1.0008788585662842,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.7815106868743897,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9667753338813782,
            "frac_alive": 0.7220051884651184,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_4_step_19528": {
            "l2_loss": 60.97667694091797,
            "l1_loss": 1754.8052490234375,
            "l0": 319.94166870117186,
            "frac_variance_explained": 0.8615978121757507,
            "cossim": 0.948495227098465,
            "l2_ratio": 0.9493318557739258,
            "relative_reconstruction_bias": 1.0007663428783418,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.5279545545578004,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9920924365520477,
            "frac_alive": 0.9676649570465088,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_4_step_29292": {
            "l2_loss": 59.328755950927736,
            "l1_loss": 1767.498046875,
            "l0": 318.44166870117186,
            "frac_variance_explained": 0.8837356507778168,
            "cossim": 0.950613158941269,
            "l2_ratio": 0.950822776556015,
            "relative_reconstruction_bias": 1.0000936627388,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.5218298196792603,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9927023231983185,
            "frac_alive": 0.9661458134651184,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_0_step_9764": {
            "l2_loss": 86.42047348022462,
            "l1_loss": 450.6054626464844,
            "l0": 19.983333587646484,
            "frac_variance_explained": 0.8193862795829773,
            "cossim": 0.8879261255264282,
            "l2_ratio": 0.8924715936183929,
            "relative_reconstruction_bias": 1.002683514356613,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 3.038171625137329,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9411266684532166,
            "frac_alive": 0.4830729067325592,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_1_step_19528": {
            "l2_loss": 83.41486282348633,
            "l1_loss": 539.0597045898437,
            "l0": 39.99583358764649,
            "frac_variance_explained": 0.7372199594974518,
            "cossim": 0.904109925031662,
            "l2_ratio": 0.9059991955757141,
            "relative_reconstruction_bias": 1.001555871963501,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.790386915206909,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9658935546875,
            "frac_alive": 0.6987847089767456,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_0_step_4882": {
            "l2_loss": 90.40935440063477,
            "l1_loss": 420.9271209716797,
            "l0": 20.0,
            "frac_variance_explained": 0.7294710755348206,
            "cossim": 0.8823458790779114,
            "l2_ratio": 0.8844953060150147,
            "relative_reconstruction_bias": 1.0038217842578887,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 3.0645169734954836,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.938496470451355,
            "frac_alive": 0.4750434160232544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_4_step_0": {
            "l2_loss": 180.564306640625,
            "l1_loss": 1618.9441040039062,
            "l0": 320.0,
            "frac_variance_explained": 0.2955034554004669,
            "cossim": 0.5860609531402587,
            "l2_ratio": 0.5195332169532776,
            "relative_reconstruction_bias": 0.8803926229476928,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 8.402252388000488,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.4052217185497284,
            "frac_alive": 0.8641493320465088,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_5_step_4882": {
            "l2_loss": 52.56303672790527,
            "l1_loss": 2940.841064453125,
            "l0": 640.0,
            "frac_variance_explained": 0.9008825242519378,
            "cossim": 0.9619503974914551,
            "l2_ratio": 0.9634300708770752,
            "relative_reconstruction_bias": 1.0010261476039886,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.4972012996673585,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.995151799917221,
            "frac_alive": 0.9976128339767456,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_5_step_9764": {
            "l2_loss": 50.354166412353514,
            "l1_loss": 3130.264404296875,
            "l0": 640.0,
            "frac_variance_explained": 0.9246617734432221,
            "cossim": 0.9638988018035889,
            "l2_ratio": 0.9645557940006256,
            "relative_reconstruction_bias": 0.9998265922069549,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.4890290021896364,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.995962792634964,
            "frac_alive": 0.9861111044883728,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_2_step_19528": {
            "l2_loss": 74.45595321655273,
            "l1_loss": 794.4246765136719,
            "l0": 79.86250076293945,
            "frac_variance_explained": 0.8187402307987213,
            "cossim": 0.9231294572353363,
            "l2_ratio": 0.9239488482475281,
            "relative_reconstruction_bias": 1.0004619002342223,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.658865451812744,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9790247321128845,
            "frac_alive": 0.8595920205116272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_1_step_0": {
            "l2_loss": 210.99351196289064,
            "l1_loss": 275.99495086669924,
            "l0": 40.0,
            "frac_variance_explained": 0.07945453524589538,
            "cossim": 0.3297470808029175,
            "l2_ratio": 0.21413452178239822,
            "relative_reconstruction_bias": 0.6453020870685577,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 14.975034046173096,
            "loss_zero": 12.452933025360107,
            "frac_recovered": -0.25202602744102476,
            "frac_alive": 0.4450954794883728,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_3_step_4882": {
            "l2_loss": 69.4132308959961,
            "l1_loss": 1182.2499633789062,
            "l0": 159.96666717529297,
            "frac_variance_explained": 0.8422987282276153,
            "cossim": 0.9322271525859833,
            "l2_ratio": 0.9336176812648773,
            "relative_reconstruction_bias": 1.001206487417221,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.5879765272140505,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9861078381538391,
            "frac_alive": 0.960069477558136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_3_step_9764": {
            "l2_loss": 65.76894493103028,
            "l1_loss": 1202.304541015625,
            "l0": 159.975,
            "frac_variance_explained": 0.8729835450649261,
            "cossim": 0.9383390665054321,
            "l2_ratio": 0.9389985263347626,
            "relative_reconstruction_bias": 1.0009360432624816,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.5770392417907715,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9871963739395142,
            "frac_alive": 0.9442274570465088,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_3_step_0": {
            "l2_loss": 174.04456329345703,
            "l1_loss": 836.9079406738281,
            "l0": 160.0,
            "frac_variance_explained": 0.2058010220527649,
            "cossim": 0.5018537759780883,
            "l2_ratio": 0.3886971056461334,
            "relative_reconstruction_bias": 0.7741727352142334,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 11.16289529800415,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.12919693514704705,
            "frac_alive": 0.7345920205116272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_2_step_29292": {
            "l2_loss": 75.41564559936523,
            "l1_loss": 780.3167541503906,
            "l0": 79.9875,
            "frac_variance_explained": 0.7844070613384246,
            "cossim": 0.9172825992107392,
            "l2_ratio": 0.91889608502388,
            "relative_reconstruction_bias": 1.0013719856739045,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.651613473892212,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9797489583492279,
            "frac_alive": 0.8752170205116272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_4_step_9764": {
            "l2_loss": 60.69626159667969,
            "l1_loss": 1773.8881469726562,
            "l0": 320.0,
            "frac_variance_explained": 0.8706678509712219,
            "cossim": 0.9466986358165741,
            "l2_ratio": 0.9474980294704437,
            "relative_reconstruction_bias": 1.0004671156406402,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.5279696941375733,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9920899033546448,
            "frac_alive": 0.9750434160232544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_5_step_29292": {
            "l2_loss": 47.25303268432617,
            "l1_loss": 3096.0229736328124,
            "l0": 640.0,
            "frac_variance_explained": 0.9130009949207306,
            "cossim": 0.9690293073654175,
            "l2_ratio": 0.9697292745113373,
            "relative_reconstruction_bias": 1.0004399478435517,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.485596942901611,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9963062465190887,
            "frac_alive": 0.922960102558136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_4_step_4882": {
            "l2_loss": 62.15762214660644,
            "l1_loss": 1917.4341796875,
            "l0": 320.0,
            "frac_variance_explained": 0.88750741481781,
            "cossim": 0.9482483267784119,
            "l2_ratio": 0.9487722039222717,
            "relative_reconstruction_bias": 0.9995041847229004,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.531095361709595,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.991776829957962,
            "frac_alive": 0.9889323115348816,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_0_step_19528": {
            "l2_loss": 91.79298477172851,
            "l1_loss": 375.99668579101564,
            "l0": 20.0,
            "frac_variance_explained": 0.6566198647022248,
            "cossim": 0.8799449265003204,
            "l2_ratio": 0.878799444437027,
            "relative_reconstruction_bias": 0.9992294609546661,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 3.0327491998672484,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9416764378547668,
            "frac_alive": 0.4865451455116272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_2_step_9764": {
            "l2_loss": 74.94713897705078,
            "l1_loss": 806.8152587890625,
            "l0": 80.0,
            "frac_variance_explained": 0.8153622448444366,
            "cossim": 0.9212305247783661,
            "l2_ratio": 0.9224987924098969,
            "relative_reconstruction_bias": 1.0003503262996674,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.6611244916915893,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9788063168525696,
            "frac_alive": 0.8654513955116272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_2_step_4882": {
            "l2_loss": 76.41778869628907,
            "l1_loss": 780.8839416503906,
            "l0": 80.0,
            "frac_variance_explained": 0.7825441062450409,
            "cossim": 0.9165175795555115,
            "l2_ratio": 0.9193883776664734,
            "relative_reconstruction_bias": 1.0034920930862428,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.673315715789795,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9775769531726837,
            "frac_alive": 0.8810763955116272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_0_step_29292": {
            "l2_loss": 88.09227294921875,
            "l1_loss": 412.0151824951172,
            "l0": 19.958333587646486,
            "frac_variance_explained": 0.7679335713386536,
            "cossim": 0.8913029313087464,
            "l2_ratio": 0.8937200129032135,
            "relative_reconstruction_bias": 1.0015840411186219,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 3.0258269548416137,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9423598647117615,
            "frac_alive": 0.4900173544883728,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_5_step_19528": {
            "l2_loss": 47.44679908752441,
            "l1_loss": 3095.0809326171875,
            "l0": 638.7375,
            "frac_variance_explained": 0.9161863803863526,
            "cossim": 0.968922781944275,
            "l2_ratio": 0.9697557151317596,
            "relative_reconstruction_bias": 1.0004246413707734,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.4869659662246706,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9961687624454498,
            "frac_alive": 0.9485676884651184,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_5_step_0": {
            "l2_loss": 186.2280700683594,
            "l1_loss": 3000.1493896484376,
            "l0": 640.0,
            "frac_variance_explained": 0.401243656873703,
            "cossim": 0.6540390014648437,
            "l2_ratio": 0.6688965618610382,
            "relative_reconstruction_bias": 1.011786025762558,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 6.891996431350708,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.55618916451931,
            "frac_alive": 0.9691840410232544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_0_step_0": {
            "l2_loss": 107.08137588500976,
            "l1_loss": 75.28442840576172,
            "l0": 20.0,
            "frac_variance_explained": 0.04979556202888489,
            "cossim": 0.25824144184589387,
            "l2_ratio": 0.1599188968539238,
            "relative_reconstruction_bias": 0.6196783661842347,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 12.0888165473938,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.036408080346882345,
            "frac_alive": 0.3146701455116272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_3_step_29292": {
            "l2_loss": 36.10165538787842,
            "l1_loss": 654.0172546386718,
            "l0": 160.0,
            "frac_variance_explained": 0.8550565540790558,
            "cossim": 0.9333893120288849,
            "l2_ratio": 0.9349802136421204,
            "relative_reconstruction_bias": 1.0012199401855468,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.5257066965103148,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9923109233379364,
            "frac_alive": 0.9259982705116272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_1_step_4882": {
            "l2_loss": 42.14891929626465,
            "l1_loss": 300.70030517578124,
            "l0": 40.0,
            "frac_variance_explained": 0.7821955204010009,
            "cossim": 0.9060506105422974,
            "l2_ratio": 0.9076599895954132,
            "relative_reconstruction_bias": 1.0018868803977967,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.6647752285003663,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9784341931343079,
            "frac_alive": 0.6822916865348816,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_1_step_9764": {
            "l2_loss": 44.72839698791504,
            "l1_loss": 286.0165222167969,
            "l0": 40.0,
            "frac_variance_explained": 0.7200008809566498,
            "cossim": 0.9025460302829742,
            "l2_ratio": 0.905003571510315,
            "relative_reconstruction_bias": 1.0029137313365937,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.6480942964553833,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9800994575023652,
            "frac_alive": 0.6725260615348816,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_3_step_19528": {
            "l2_loss": 36.93412780761719,
            "l1_loss": 614.4428405761719,
            "l0": 160.0,
            "frac_variance_explained": 0.8261658430099488,
            "cossim": 0.9333479702472687,
            "l2_ratio": 0.9347514331340789,
            "relative_reconstruction_bias": 1.0012900471687316,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.5299219131469726,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9918931722640991,
            "frac_alive": 0.9388020634651184,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_2_step_0": {
            "l2_loss": 104.9067626953125,
            "l1_loss": 265.4046157836914,
            "l0": 80.0,
            "frac_variance_explained": 0.1352146804332733,
            "cossim": 0.41605434417724607,
            "l2_ratio": 0.29070858359336854,
            "relative_reconstruction_bias": 0.6962904870510102,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 11.198446655273438,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.12534187585115433,
            "frac_alive": 0.614366352558136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_1_step_29292": {
            "l2_loss": 44.08017997741699,
            "l1_loss": 291.59278259277346,
            "l0": 40.0,
            "frac_variance_explained": 0.7410507202148438,
            "cossim": 0.9008072555065155,
            "l2_ratio": 0.9013695895671845,
            "relative_reconstruction_bias": 1.00115727186203,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.643741250038147,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9805340766906738,
            "frac_alive": 0.6875,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_4_step_19528": {
            "l2_loss": 32.28419570922851,
            "l1_loss": 945.4452514648438,
            "l0": 320.0,
            "frac_variance_explained": 0.8440732181072235,
            "cossim": 0.9488677561283112,
            "l2_ratio": 0.9495885610580445,
            "relative_reconstruction_bias": 1.0008410215377808,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.4993526220321653,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9949434399604797,
            "frac_alive": 0.9587673544883728,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_4_step_29292": {
            "l2_loss": 32.1046365737915,
            "l1_loss": 1001.3568115234375,
            "l0": 318.7916687011719,
            "frac_variance_explained": 0.8775784373283386,
            "cossim": 0.9492373943328858,
            "l2_ratio": 0.9505591273307801,
            "relative_reconstruction_bias": 1.0011770963668822,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.4951005458831785,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.995363998413086,
            "frac_alive": 0.960069477558136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_0_step_9764": {
            "l2_loss": 44.7341064453125,
            "l1_loss": 207.26839294433594,
            "l0": 20.0,
            "frac_variance_explained": 0.7177547574043274,
            "cossim": 0.8940526366233825,
            "l2_ratio": 0.8953704595565796,
            "relative_reconstruction_bias": 1.0012017011642456,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.78453905582428,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9664794743061066,
            "frac_alive": 0.4698350727558136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_1_step_19528": {
            "l2_loss": 43.47607307434082,
            "l1_loss": 297.78590393066406,
            "l0": 40.0,
            "frac_variance_explained": 0.7538618266582489,
            "cossim": 0.9077682256698608,
            "l2_ratio": 0.9106729447841644,
            "relative_reconstruction_bias": 1.002778708934784,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.6452993869781496,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9803775727748871,
            "frac_alive": 0.6881510615348816,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_0_step_4882": {
            "l2_loss": 47.228475952148436,
            "l1_loss": 235.17080078125,
            "l0": 20.0,
            "frac_variance_explained": 0.7611524760723114,
            "cossim": 0.8860170364379882,
            "l2_ratio": 0.886613953113556,
            "relative_reconstruction_bias": 1.000320154428482,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.8010507345199587,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9648211658000946,
            "frac_alive": 0.4739583432674408,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_4_step_0": {
            "l2_loss": 92.08378143310547,
            "l1_loss": 833.4138732910156,
            "l0": 320.0,
            "frac_variance_explained": 0.30485352873802185,
            "cossim": 0.5884904384613037,
            "l2_ratio": 0.5189642548561096,
            "relative_reconstruction_bias": 0.8778730630874634,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 8.172922945022583,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.4279408514499664,
            "frac_alive": 0.8865017294883728,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_5_step_4882": {
            "l2_loss": 27.798292922973634,
            "l1_loss": 1901.8121948242188,
            "l0": 640.0,
            "frac_variance_explained": 0.9192956030368805,
            "cossim": 0.9631024062633514,
            "l2_ratio": 0.9644128084182739,
            "relative_reconstruction_bias": 1.0000497460365296,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.4740395545959473,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.997461587190628,
            "frac_alive": 0.985460102558136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_5_step_9764": {
            "l2_loss": 27.067481422424315,
            "l1_loss": 1931.8766967773438,
            "l0": 639.8250061035156,
            "frac_variance_explained": 0.9201988458633423,
            "cossim": 0.9640509426593781,
            "l2_ratio": 0.9646131217479705,
            "relative_reconstruction_bias": 0.999680894613266,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.4703719139099123,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9978213250637055,
            "frac_alive": 0.9359809160232544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_2_step_19528": {
            "l2_loss": 40.72418212890625,
            "l1_loss": 408.65142822265625,
            "l0": 80.0,
            "frac_variance_explained": 0.776144164800644,
            "cossim": 0.9175802946090699,
            "l2_ratio": 0.9188616394996643,
            "relative_reconstruction_bias": 1.0011290907859802,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.5801558256149293,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9868837356567383,
            "frac_alive": 0.8391926884651184,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_1_step_0": {
            "l2_loss": 102.7399284362793,
            "l1_loss": 137.68185119628907,
            "l0": 40.0,
            "frac_variance_explained": 0.08475648164749146,
            "cossim": 0.33289490938186644,
            "l2_ratio": 0.21612198352813722,
            "relative_reconstruction_bias": 0.6478755056858063,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 12.101439952850342,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.03507674731081352,
            "frac_alive": 0.4659288227558136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_3_step_4882": {
            "l2_loss": 36.70189743041992,
            "l1_loss": 613.1770141601562,
            "l0": 160.0,
            "frac_variance_explained": 0.8315385341644287,
            "cossim": 0.9313120186328888,
            "l2_ratio": 0.9339539587497712,
            "relative_reconstruction_bias": 1.0032928526401519,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.5437010765075683,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9905225038528442,
            "frac_alive": 0.9724392294883728,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_3_step_9764": {
            "l2_loss": 36.85532112121582,
            "l1_loss": 624.8154602050781,
            "l0": 160.0,
            "frac_variance_explained": 0.838605260848999,
            "cossim": 0.9319119155406952,
            "l2_ratio": 0.9315447270870209,
            "relative_reconstruction_bias": 0.9993637800216675,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.5351162195205688,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9913766324520111,
            "frac_alive": 0.9516059160232544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_3_step_0": {
            "l2_loss": 95.76123809814453,
            "l1_loss": 464.96160888671875,
            "l0": 160.0,
            "frac_variance_explained": 0.2155470371246338,
            "cossim": 0.5061569690704346,
            "l2_ratio": 0.3934949845075607,
            "relative_reconstruction_bias": 0.7745991706848144,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 10.176505184173584,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.22761329561471938,
            "frac_alive": 0.7799479365348816,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_2_step_29292": {
            "l2_loss": 40.50752258300781,
            "l1_loss": 420.8312255859375,
            "l0": 80.0,
            "frac_variance_explained": 0.7750738978385925,
            "cossim": 0.9176967144012451,
            "l2_ratio": 0.918823879957199,
            "relative_reconstruction_bias": 1.0006450712680817,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.576049256324768,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9872942864894867,
            "frac_alive": 0.8485243320465088,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_4_step_9764": {
            "l2_loss": 33.49109382629395,
            "l1_loss": 971.7022094726562,
            "l0": 320.0,
            "frac_variance_explained": 0.8503769278526306,
            "cossim": 0.9462782084941864,
            "l2_ratio": 0.947282361984253,
            "relative_reconstruction_bias": 1.00059335231781,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.4987437963485717,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9950013101100922,
            "frac_alive": 0.9728732705116272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_5_step_29292": {
            "l2_loss": 25.905238533020018,
            "l1_loss": 1944.7534545898438,
            "l0": 636.375,
            "frac_variance_explained": 0.9188972532749176,
            "cossim": 0.9673456907272339,
            "l2_ratio": 0.9676195502281189,
            "relative_reconstruction_bias": 1.001111477613449,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.4710344076156616,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9977548956871033,
            "frac_alive": 0.8967013955116272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_4_step_4882": {
            "l2_loss": 34.10336036682129,
            "l1_loss": 1027.7757385253906,
            "l0": 320.0,
            "frac_variance_explained": 0.8657257735729218,
            "cossim": 0.9429556906223298,
            "l2_ratio": 0.9436591565608978,
            "relative_reconstruction_bias": 0.9999759495258331,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.5025654077529906,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.994621193408966,
            "frac_alive": 0.991319477558136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_0_step_19528": {
            "l2_loss": 45.39714584350586,
            "l1_loss": 230.23885955810547,
            "l0": 20.0,
            "frac_variance_explained": 0.7433775722980499,
            "cossim": 0.8960484743118287,
            "l2_ratio": 0.8978495597839355,
            "relative_reconstruction_bias": 1.0016535639762878,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.7760775566101072,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9673215925693512,
            "frac_alive": 0.4704861044883728,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_2_step_9764": {
            "l2_loss": 40.2271484375,
            "l1_loss": 412.6097839355469,
            "l0": 80.0,
            "frac_variance_explained": 0.7945593535900116,
            "cossim": 0.916545706987381,
            "l2_ratio": 0.9181585788726807,
            "relative_reconstruction_bias": 1.0018475949764252,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.581222319602966,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9867854416370392,
            "frac_alive": 0.8480902910232544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_2_step_4882": {
            "l2_loss": 41.26954650878906,
            "l1_loss": 415.5445281982422,
            "l0": 80.0,
            "frac_variance_explained": 0.7774689495563507,
            "cossim": 0.9168214321136474,
            "l2_ratio": 0.9197173595428467,
            "relative_reconstruction_bias": 1.0034611403942109,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.59203462600708,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9857054710388183,
            "frac_alive": 0.850694477558136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_0_step_29292": {
            "l2_loss": 47.86895866394043,
            "l1_loss": 235.41092376708986,
            "l0": 19.975000190734864,
            "frac_variance_explained": 0.728620845079422,
            "cossim": 0.8858761131763458,
            "l2_ratio": 0.886972838640213,
            "relative_reconstruction_bias": 1.0011590898036957,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.768544149398804,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9680706560611725,
            "frac_alive": 0.4796006977558136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_5_step_19528": {
            "l2_loss": 26.14837646484375,
            "l1_loss": 1903.4630004882813,
            "l0": 638.6583374023437,
            "frac_variance_explained": 0.9102248430252076,
            "cossim": 0.9673497974872589,
            "l2_ratio": 0.9678224146366119,
            "relative_reconstruction_bias": 1.0005301713943482,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.469423699378967,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9979145884513855,
            "frac_alive": 0.9032118320465088,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_5_step_0": {
            "l2_loss": 82.66757125854492,
            "l1_loss": 1351.9484741210938,
            "l0": 640.0,
            "frac_variance_explained": 0.4130748093128204,
            "cossim": 0.6570005774497986,
            "l2_ratio": 0.6692958414554596,
            "relative_reconstruction_bias": 1.018416428565979,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 6.31883134841919,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.6132606267929077,
            "frac_alive": 0.9767795205116272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_0_step_0": {
            "l2_loss": 312.7357879638672,
            "l1_loss": 217.66961364746095,
            "l0": 20.0,
            "frac_variance_explained": 0.04759427309036255,
            "cossim": 0.2587917596101761,
            "l2_ratio": 0.1597227305173874,
            "relative_reconstruction_bias": 0.6171136498451233,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 13.819368839263916,
            "loss_zero": 12.452933025360107,
            "frac_recovered": -0.13659483566880226,
            "frac_alive": 0.3207465410232544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_3_step_29292": {
            "l2_loss": 109.50934524536133,
            "l1_loss": 1748.9181762695312,
            "l0": 160.0,
            "frac_variance_explained": 0.8218507289886474,
            "cossim": 0.9213970482349396,
            "l2_ratio": 0.9230452179908752,
            "relative_reconstruction_bias": 1.0014376223087311,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.612067627906799,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9837026059627533,
            "frac_alive": 0.9622395634651184,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_1_step_4882": {
            "l2_loss": 130.69567108154297,
            "l1_loss": 828.1859191894531,
            "l0": 40.0,
            "frac_variance_explained": 0.7182818233966828,
            "cossim": 0.8931558132171631,
            "l2_ratio": 0.8939738154411316,
            "relative_reconstruction_bias": 1.0001182734966279,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.849925661087036,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9599497139453887,
            "frac_alive": 0.7248263955116272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_1_step_9764": {
            "l2_loss": 132.80433044433593,
            "l1_loss": 847.8756958007813,
            "l0": 40.0,
            "frac_variance_explained": 0.7208008110523224,
            "cossim": 0.8914670407772064,
            "l2_ratio": 0.8918397426605225,
            "relative_reconstruction_bias": 1.0001900434494018,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.833556294441223,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9615828394889832,
            "frac_alive": 0.716796875,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_3_step_19528": {
            "l2_loss": 112.30783309936524,
            "l1_loss": 1760.1436401367187,
            "l0": 160.0,
            "frac_variance_explained": 0.8032046437263489,
            "cossim": 0.9188546240329742,
            "l2_ratio": 0.9205192387104034,
            "relative_reconstruction_bias": 1.0016388952732087,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.6182549238204955,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9830809772014618,
            "frac_alive": 0.955078125,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_2_step_0": {
            "l2_loss": 295.0479675292969,
            "l1_loss": 742.0042602539063,
            "l0": 80.0,
            "frac_variance_explained": 0.1312829375267029,
            "cossim": 0.41586191952228546,
            "l2_ratio": 0.2901207238435745,
            "relative_reconstruction_bias": 0.6924564421176911,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 11.278066825866699,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.11768896728754044,
            "frac_alive": 0.604600727558136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_1_step_29292": {
            "l2_loss": 130.0480583190918,
            "l1_loss": 824.4392883300782,
            "l0": 40.0,
            "frac_variance_explained": 0.7070431172847748,
            "cossim": 0.8955200374126434,
            "l2_ratio": 0.8958064556121826,
            "relative_reconstruction_bias": 1.0005642175674438,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.822776198387146,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9626509010791778,
            "frac_alive": 0.704210102558136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_4_step_19528": {
            "l2_loss": 97.07017669677734,
            "l1_loss": 2789.21162109375,
            "l0": 318.21250610351564,
            "frac_variance_explained": 0.8734239101409912,
            "cossim": 0.9395074427127839,
            "l2_ratio": 0.9407199144363403,
            "relative_reconstruction_bias": 1.0013349533081055,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.55876362323761,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.989018440246582,
            "frac_alive": 0.9793837070465088,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_4_step_29292": {
            "l2_loss": 95.86326446533204,
            "l1_loss": 2770.3046875,
            "l0": 319.04583435058595,
            "frac_variance_explained": 0.85227872133255,
            "cossim": 0.9415181279182434,
            "l2_ratio": 0.9433636844158173,
            "relative_reconstruction_bias": 1.0015927314758302,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.562959837913513,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9886004984378814,
            "frac_alive": 0.9759114384651184,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_0_step_9764": {
            "l2_loss": 137.68091430664063,
            "l1_loss": 625.5960815429687,
            "l0": 19.991666793823242,
            "frac_variance_explained": 0.717439717054367,
            "cossim": 0.8763020455837249,
            "l2_ratio": 0.8804173171520233,
            "relative_reconstruction_bias": 1.0031277894973756,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 3.0440035820007325,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9405534446239472,
            "frac_alive": 0.5119357705116272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_1_step_19528": {
            "l2_loss": 127.68928909301758,
            "l1_loss": 894.8322570800781,
            "l0": 39.96666717529297,
            "frac_variance_explained": 0.7787669181823731,
            "cossim": 0.8900634169578552,
            "l2_ratio": 0.8937020123004913,
            "relative_reconstruction_bias": 1.0030580103397368,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.833037757873535,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9616297721862793,
            "frac_alive": 0.7174479365348816,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_0_step_4882": {
            "l2_loss": 138.44332275390624,
            "l1_loss": 670.7379272460937,
            "l0": 20.0,
            "frac_variance_explained": 0.7423519253730774,
            "cossim": 0.8729063928127289,
            "l2_ratio": 0.8757324457168579,
            "relative_reconstruction_bias": 1.0029554903507232,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 3.0538971185684205,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9395672976970673,
            "frac_alive": 0.510850727558136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_4_step_0": {
            "l2_loss": 270.9858596801758,
            "l1_loss": 2427.2340087890625,
            "l0": 320.0,
            "frac_variance_explained": 0.29935314059257506,
            "cossim": 0.5865900099277497,
            "l2_ratio": 0.5207772493362427,
            "relative_reconstruction_bias": 0.8814326405525208,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 6.388378000259399,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.6064374566078186,
            "frac_alive": 0.9058159589767456,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_5_step_4882": {
            "l2_loss": 85.3322967529297,
            "l1_loss": 4559.99697265625,
            "l0": 640.0,
            "frac_variance_explained": 0.8845648407936096,
            "cossim": 0.9555666148662567,
            "l2_ratio": 0.9566182136535645,
            "relative_reconstruction_bias": 1.0012004315853118,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.5264959573745727,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9922325074672699,
            "frac_alive": 0.9984809160232544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_5_step_9764": {
            "l2_loss": 84.2859504699707,
            "l1_loss": 4657.8841796875,
            "l0": 640.0,
            "frac_variance_explained": 0.8868956148624421,
            "cossim": 0.9548284769058227,
            "l2_ratio": 0.9557991921901703,
            "relative_reconstruction_bias": 1.001058703660965,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.5146856546401977,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9934073865413666,
            "frac_alive": 0.9861111044883728,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_2_step_19528": {
            "l2_loss": 116.40393905639648,
            "l1_loss": 1299.3549438476562,
            "l0": 80.0,
            "frac_variance_explained": 0.8562032759189606,
            "cossim": 0.913584190607071,
            "l2_ratio": 0.9146600961685181,
            "relative_reconstruction_bias": 1.001969450712204,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.703508400917053,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9745656967163085,
            "frac_alive": 0.8444010615348816,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_1_step_0": {
            "l2_loss": 297.56995849609376,
            "l1_loss": 396.5432495117187,
            "l0": 40.0,
            "frac_variance_explained": 0.08247098326683044,
            "cossim": 0.3324948400259018,
            "l2_ratio": 0.21494100242853165,
            "relative_reconstruction_bias": 0.6454720675945282,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 12.641379928588867,
            "loss_zero": 12.452933025360107,
            "frac_recovered": -0.01866046098875813,
            "frac_alive": 0.4607204794883728,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_3_step_4882": {
            "l2_loss": 110.60435028076172,
            "l1_loss": 1940.7088134765625,
            "l0": 160.0,
            "frac_variance_explained": 0.841539877653122,
            "cossim": 0.9242340147495269,
            "l2_ratio": 0.9263074457645416,
            "relative_reconstruction_bias": 1.0021615862846374,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.630650210380554,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9818341493606567,
            "frac_alive": 0.9624565839767456,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_3_step_9764": {
            "l2_loss": 111.34126663208008,
            "l1_loss": 1780.3982177734374,
            "l0": 160.0,
            "frac_variance_explained": 0.8160711228847504,
            "cossim": 0.9216336369514465,
            "l2_ratio": 0.923462575674057,
            "relative_reconstruction_bias": 1.0017536282539368,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.6253177642822267,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9823686599731445,
            "frac_alive": 0.9572482705116272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_3_step_0": {
            "l2_loss": 273.0045822143555,
            "l1_loss": 1315.5190063476562,
            "l0": 160.0,
            "frac_variance_explained": 0.20657851696014404,
            "cossim": 0.5032265454530715,
            "l2_ratio": 0.39295206069946287,
            "relative_reconstruction_bias": 0.7782644510269165,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 8.656596469879151,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.37977272272109985,
            "frac_alive": 0.7543402910232544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_2_step_29292": {
            "l2_loss": 121.13732147216797,
            "l1_loss": 1171.0870971679688,
            "l0": 80.0,
            "frac_variance_explained": 0.745656818151474,
            "cossim": 0.9062001645565033,
            "l2_ratio": 0.9080981433391571,
            "relative_reconstruction_bias": 1.002163714170456,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.6950029134750366,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9754131019115448,
            "frac_alive": 0.8841145634651184,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_4_step_9764": {
            "l2_loss": 97.43392715454101,
            "l1_loss": 2756.7733154296875,
            "l0": 320.0,
            "frac_variance_explained": 0.8452295660972595,
            "cossim": 0.940710598230362,
            "l2_ratio": 0.9418825805187225,
            "relative_reconstruction_bias": 1.0009587824344635,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.5639143228530883,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9885053873062134,
            "frac_alive": 0.9900173544883728,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_5_step_29292": {
            "l2_loss": 79.53888397216797,
            "l1_loss": 4798.411474609375,
            "l0": 638.7375,
            "frac_variance_explained": 0.9005192399024964,
            "cossim": 0.9616288483142853,
            "l2_ratio": 0.9619738221168518,
            "relative_reconstruction_bias": 1.0002726554870605,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.5111447095870973,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.993765777349472,
            "frac_alive": 0.947265625,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_4_step_4882": {
            "l2_loss": 100.68852157592774,
            "l1_loss": 2739.2739501953124,
            "l0": 320.0,
            "frac_variance_explained": 0.8412795960903168,
            "cossim": 0.9362496256828308,
            "l2_ratio": 0.9364138722419739,
            "relative_reconstruction_bias": 1.0003404676914216,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.572627377510071,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9876359105110168,
            "frac_alive": 0.9973958134651184,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_0_step_19528": {
            "l2_loss": 140.51988830566407,
            "l1_loss": 632.6427124023437,
            "l0": 19.991666793823242,
            "frac_variance_explained": 0.7136194348335266,
            "cossim": 0.8755758345127106,
            "l2_ratio": 0.8768346548080445,
            "relative_reconstruction_bias": 1.0011521518230437,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 3.0345953702926636,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9414920508861542,
            "frac_alive": 0.5164930820465088,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_2_step_9764": {
            "l2_loss": 120.93914184570312,
            "l1_loss": 1165.956884765625,
            "l0": 80.0,
            "frac_variance_explained": 0.7477370798587799,
            "cossim": 0.9110545098781586,
            "l2_ratio": 0.9126319050788879,
            "relative_reconstruction_bias": 1.001459038257599,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.7068527936935425,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9742290496826171,
            "frac_alive": 0.8572048544883728,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_2_step_4882": {
            "l2_loss": 122.65049057006836,
            "l1_loss": 1226.2430419921875,
            "l0": 80.0,
            "frac_variance_explained": 0.7799512505531311,
            "cossim": 0.901749712228775,
            "l2_ratio": 0.9048132181167603,
            "relative_reconstruction_bias": 1.0030490040779114,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.721208906173706,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9727979719638824,
            "frac_alive": 0.885850727558136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_0_step_29292": {
            "l2_loss": 142.11297912597655,
            "l1_loss": 661.4550415039063,
            "l0": 20.0,
            "frac_variance_explained": 0.7398670613765717,
            "cossim": 0.8756579160690308,
            "l2_ratio": 0.8785574913024903,
            "relative_reconstruction_bias": 1.0044013142585755,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 3.028001379966736,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9421488165855407,
            "frac_alive": 0.5082465410232544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_5_step_19528": {
            "l2_loss": 81.11087799072266,
            "l1_loss": 4801.650830078125,
            "l0": 638.5916748046875,
            "frac_variance_explained": 0.9037192165851593,
            "cossim": 0.9598217725753784,
            "l2_ratio": 0.9598796010017395,
            "relative_reconstruction_bias": 1.0000588238239287,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.511209750175476,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9937564551830291,
            "frac_alive": 0.9505208134651184,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_5_step_0": {
            "l2_loss": 246.4438491821289,
            "l1_loss": 4003.55654296875,
            "l0": 640.0,
            "frac_variance_explained": 0.4044389247894287,
            "cossim": 0.6553459882736206,
            "l2_ratio": 0.6696077227592468,
            "relative_reconstruction_bias": 1.0142831265926362,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 5.08550534248352,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.736601573228836,
            "frac_alive": 0.9802517294883728,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        }
    }
}