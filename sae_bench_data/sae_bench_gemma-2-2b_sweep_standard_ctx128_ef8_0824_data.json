{
    "sae_config_dictionary_learning": {
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19/trainer_4": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "48828"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19/trainer_3": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "48828"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19/trainer_2": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "48828"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19/trainer_5": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "48828"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19/trainer_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "48828"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19/trainer_1": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "48828"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11/trainer_4": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "48828"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11/trainer_3": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "48828"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11/trainer_2": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "48828"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11/trainer_5": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "48828"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11/trainer_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "48828"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11/trainer_1": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "48828"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7/trainer_4": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "48828"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7/trainer_3": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "48828"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7/trainer_2": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "48828"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7/trainer_5": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "48828"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7/trainer_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "48828"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7/trainer_1": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "48828"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_0_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_0_step_15440": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "15440"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_3_step_154": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "154"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_2_step_154": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "154"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_2_step_1544": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "1544"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_1_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_3_step_488": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "488"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_2_step_488": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "488"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_2_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_5_step_15440": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "15440"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_4_step_1544": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "1544"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_4_step_488": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "488"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_5_step_488": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "488"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_5_step_48": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "48"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_2_step_15440": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "15440"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_3_step_1544": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "1544"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_0_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_4_step_154": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "154"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_5_step_154": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "154"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_4_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_4_step_48": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "48"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_5_step_1544": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "1544"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_1_step_48": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "48"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_5_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_4_step_15440": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "15440"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_0_step_488": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "488"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_1_step_488": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "488"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_1_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_0_step_1544": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "1544"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_1_step_15440": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "15440"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_3_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_3_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_0_step_48": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "48"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_0_step_154": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "154"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_1_step_154": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "154"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_4_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_2_step_48": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "48"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_1_step_1544": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "1544"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_3_step_48": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "48"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_2_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_3_step_15440": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "15440"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_5_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_0_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_0_step_15440": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "15440"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_3_step_154": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "154"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_2_step_154": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "154"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_2_step_1544": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "1544"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_1_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_3_step_488": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "488"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_2_step_488": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "488"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_2_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_5_step_15440": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "15440"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_4_step_1544": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "1544"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_4_step_488": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "488"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_5_step_488": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "488"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_5_step_48": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "48"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_2_step_15440": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "15440"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_3_step_1544": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "1544"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_0_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_4_step_154": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "154"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_5_step_154": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "154"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_4_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_4_step_48": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "48"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_5_step_1544": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "1544"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_1_step_48": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "48"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_5_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_4_step_15440": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "15440"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_0_step_488": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "488"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_1_step_488": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "488"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_1_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_0_step_1544": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "1544"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_1_step_15440": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "15440"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_3_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_3_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_0_step_48": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "48"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_0_step_154": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "154"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_1_step_154": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "154"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_4_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_2_step_48": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "48"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_1_step_1544": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "1544"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_3_step_48": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "48"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_2_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_3_step_15440": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "15440"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_5_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15/trainer_4": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "48828"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15/trainer_3": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "48828"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15/trainer_2": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "48828"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15/trainer_5": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "48828"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15/trainer_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "48828"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15/trainer_1": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "48828"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3/trainer_4": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "48828"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3/trainer_3": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "48828"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3/trainer_2": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "48828"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3/trainer_5": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "48828"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3/trainer_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "48828"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3/trainer_1": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "48828"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_0_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_0_step_15440": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "15440"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_3_step_154": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "154"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_2_step_154": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "154"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_2_step_1544": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "1544"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_1_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_3_step_488": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "488"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_2_step_488": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "488"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_2_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_5_step_15440": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "15440"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_4_step_1544": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "1544"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_4_step_488": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "488"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_5_step_488": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "488"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_5_step_48": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "48"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_2_step_15440": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "15440"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_3_step_1544": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "1544"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_0_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_4_step_154": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "154"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_5_step_154": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "154"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_4_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_4_step_48": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "48"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_5_step_1544": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "1544"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_1_step_48": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "48"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_5_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_4_step_15440": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "15440"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_0_step_488": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "488"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_1_step_488": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "488"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_1_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_0_step_1544": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "1544"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_1_step_15440": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "15440"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_3_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_3_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_0_step_48": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "48"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_0_step_154": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "154"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_1_step_154": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "154"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_4_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_2_step_48": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "48"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_1_step_1544": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "1544"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_3_step_48": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "48"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_2_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_3_step_15440": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "15440"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_5_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_0_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_0_step_15440": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "15440"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_3_step_154": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "154"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_2_step_154": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "154"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_2_step_1544": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "1544"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_1_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_3_step_488": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "488"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_2_step_488": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "488"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_2_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_5_step_15440": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "15440"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_4_step_1544": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "1544"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_4_step_488": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "488"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_5_step_488": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "488"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_5_step_48": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "48"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_2_step_15440": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "15440"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_3_step_1544": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "1544"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_0_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_4_step_154": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "154"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_5_step_154": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "154"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_4_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_4_step_48": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "48"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_5_step_1544": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "1544"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_1_step_48": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "48"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_5_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_4_step_15440": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "15440"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_0_step_488": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "488"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_1_step_488": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "488"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_1_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_0_step_1544": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "1544"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_1_step_15440": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "15440"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_3_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_3_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_0_step_48": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "48"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_0_step_154": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "154"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_1_step_154": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "154"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_4_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_2_step_48": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "48"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_1_step_1544": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "1544"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_3_step_48": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "48"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_2_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_3_step_15440": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "15440"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_5_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_0_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_0_step_15440": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "15440"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_3_step_154": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "154"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_2_step_154": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "154"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_2_step_1544": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "1544"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_1_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_3_step_488": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "488"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_2_step_488": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "488"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_2_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_5_step_15440": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "15440"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_4_step_1544": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "1544"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_4_step_488": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "488"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_5_step_488": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "488"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_5_step_48": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "48"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_2_step_15440": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "15440"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_3_step_1544": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "1544"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_0_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_4_step_154": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "154"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_5_step_154": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "154"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_4_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_4_step_48": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "48"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_5_step_1544": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "1544"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_1_step_48": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "48"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_5_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_4_step_15440": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "15440"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_0_step_488": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "488"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_1_step_488": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "488"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_1_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_0_step_1544": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "1544"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_1_step_15440": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "15440"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_3_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_3_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_0_step_48": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "48"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_0_step_154": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "154"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_1_step_154": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "154"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_4_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_2_step_48": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "48"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_1_step_1544": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "1544"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_3_step_48": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "48"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_2_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_3_step_15440": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "15440"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_5_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 18432,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        }
    },
    "basic_eval_results": {
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19/trainer_4": {
            "l2_loss": 161.2818618774414,
            "l1_loss": 432.40709228515624,
            "l0": 35.02916831970215,
            "frac_variance_explained": 0.5828464150428772,
            "cossim": 0.8308584272861481,
            "l2_ratio": 0.772969126701355,
            "relative_reconstruction_bias": 0.9414819777011871,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 3.6968069553375242,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.8754043757915497,
            "frac_alive": 0.0658637136220932,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19/trainer_3": {
            "l2_loss": 141.95765686035156,
            "l1_loss": 574.080859375,
            "l0": 65.35833473205567,
            "frac_variance_explained": 0.6718634366989136,
            "cossim": 0.8699315905570983,
            "l2_ratio": 0.8178958654403686,
            "relative_reconstruction_bias": 0.9495936155319213,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 3.064043641090393,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9386282324790954,
            "frac_alive": 0.155056431889534,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19/trainer_2": {
            "l2_loss": 118.12515640258789,
            "l1_loss": 760.8950073242188,
            "l0": 124.0583381652832,
            "frac_variance_explained": 0.7938235461711883,
            "cossim": 0.91240553855896,
            "l2_ratio": 0.8692996561527252,
            "relative_reconstruction_bias": 0.963777494430542,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 2.759493088722229,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9690388798713684,
            "frac_alive": 0.3219943642616272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19/trainer_5": {
            "l2_loss": 178.40693359375,
            "l1_loss": 341.96990966796875,
            "l0": 19.866667175292967,
            "frac_variance_explained": 0.572351050376892,
            "cossim": 0.7818877041339874,
            "l2_ratio": 0.7191039443016052,
            "relative_reconstruction_bias": 0.9454742312431336,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 4.59279203414917,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.7858266532421112,
            "frac_alive": 0.02707248367369175,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19/trainer_0": {
            "l2_loss": 91.28402938842774,
            "l1_loss": 1256.6742797851562,
            "l0": 435.30417785644534,
            "frac_variance_explained": 0.8860715329647064,
            "cossim": 0.9472658216953278,
            "l2_ratio": 0.9143549501895905,
            "relative_reconstruction_bias": 0.9769266545772552,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 2.5746376276016236,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9874874651432037,
            "frac_alive": 0.733018696308136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19/trainer_1": {
            "l2_loss": 110.14564514160156,
            "l1_loss": 852.2773986816406,
            "l0": 177.4000030517578,
            "frac_variance_explained": 0.7850531160831451,
            "cossim": 0.9229176878929138,
            "l2_ratio": 0.8877681434154511,
            "relative_reconstruction_bias": 0.965803575515747,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 2.677743363380432,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9771980524063111,
            "frac_alive": 0.4453125,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11/trainer_4": {
            "l2_loss": 77.07271423339844,
            "l1_loss": 209.26783905029296,
            "l0": 35.49583435058594,
            "frac_variance_explained": 0.673879736661911,
            "cossim": 0.8379469156265259,
            "l2_ratio": 0.7764925301074982,
            "relative_reconstruction_bias": 0.9512474119663239,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 3.923832106590271,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.8525889277458191,
            "frac_alive": 0.0455729179084301,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11/trainer_3": {
            "l2_loss": 69.19085235595703,
            "l1_loss": 260.5812042236328,
            "l0": 68.32500228881835,
            "frac_variance_explained": 0.6767194271087646,
            "cossim": 0.8739384233951568,
            "l2_ratio": 0.8242608070373535,
            "relative_reconstruction_bias": 0.9541641473770142,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 2.999904203414917,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9450006365776062,
            "frac_alive": 0.1184895858168602,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11/trainer_2": {
            "l2_loss": 60.528709411621094,
            "l1_loss": 360.99082946777344,
            "l0": 142.25417404174806,
            "frac_variance_explained": 0.7947052717208862,
            "cossim": 0.9053027153015136,
            "l2_ratio": 0.855720329284668,
            "relative_reconstruction_bias": 0.9635509788990021,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 2.675975728034973,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9773781895637512,
            "frac_alive": 0.28173828125,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11/trainer_5": {
            "l2_loss": 85.48247909545898,
            "l1_loss": 188.83019409179687,
            "l0": 20.800000953674317,
            "frac_variance_explained": 0.6401739776134491,
            "cossim": 0.7948622822761535,
            "l2_ratio": 0.7354530394077301,
            "relative_reconstruction_bias": 0.9544944584369659,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 4.871973085403442,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.757849270105362,
            "frac_alive": 0.0176866315305233,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11/trainer_0": {
            "l2_loss": 44.21599082946777,
            "l1_loss": 689.0535034179687,
            "l0": 653.0125183105469,
            "frac_variance_explained": 0.876203840970993,
            "cossim": 0.9503044188022614,
            "l2_ratio": 0.9132377088069916,
            "relative_reconstruction_bias": 0.9689015865325927,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 2.516097593307495,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9933268785476684,
            "frac_alive": 0.722276508808136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11/trainer_1": {
            "l2_loss": 54.783888244628905,
            "l1_loss": 430.45958251953124,
            "l0": 216.9250061035156,
            "frac_variance_explained": 0.821322637796402,
            "cossim": 0.9228447735309601,
            "l2_ratio": 0.8802441656589508,
            "relative_reconstruction_bias": 0.9668310403823852,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 2.602967619895935,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9846588850021363,
            "frac_alive": 0.4129774272441864,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7/trainer_4": {
            "l2_loss": 53.2313648223877,
            "l1_loss": 147.2660385131836,
            "l0": 37.40833435058594,
            "frac_variance_explained": 0.5986019253730774,
            "cossim": 0.8492132067680359,
            "l2_ratio": 0.7880723178386688,
            "relative_reconstruction_bias": 0.933878880739212,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 3.481455445289612,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.8968801438808441,
            "frac_alive": 0.0559353306889534,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7/trainer_3": {
            "l2_loss": 48.9877426147461,
            "l1_loss": 204.8866943359375,
            "l0": 65.37083511352539,
            "frac_variance_explained": 0.7179788053035736,
            "cossim": 0.8782737255096436,
            "l2_ratio": 0.8260804891586304,
            "relative_reconstruction_bias": 0.951469624042511,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 2.8807432413101197,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.956915944814682,
            "frac_alive": 0.1409505158662796,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7/trainer_2": {
            "l2_loss": 40.072514343261716,
            "l1_loss": 247.1628173828125,
            "l0": 123.87500381469727,
            "frac_variance_explained": 0.7669894337654114,
            "cossim": 0.9212132513523101,
            "l2_ratio": 0.8806450128555298,
            "relative_reconstruction_bias": 0.9582830250263215,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 2.6193800449371336,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9830265641212463,
            "frac_alive": 0.2927517294883728,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7/trainer_5": {
            "l2_loss": 62.87034683227539,
            "l1_loss": 116.25719909667968,
            "l0": 21.183333969116212,
            "frac_variance_explained": 0.4952318072319031,
            "cossim": 0.7969144999980926,
            "l2_ratio": 0.740835702419281,
            "relative_reconstruction_bias": 0.9371668994426727,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 4.547642850875855,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.7902627408504486,
            "frac_alive": 0.02191840298473835,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7/trainer_0": {
            "l2_loss": 29.080005836486816,
            "l1_loss": 426.9056671142578,
            "l0": 422.0083404541016,
            "frac_variance_explained": 0.923843252658844,
            "cossim": 0.9572624862194061,
            "l2_ratio": 0.9247695922851562,
            "relative_reconstruction_bias": 0.9795760452747345,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 2.501347064971924,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9947918713092804,
            "frac_alive": 0.6989474892616272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7/trainer_1": {
            "l2_loss": 36.03860740661621,
            "l1_loss": 283.4460815429687,
            "l0": 180.9875045776367,
            "frac_variance_explained": 0.8018329918384552,
            "cossim": 0.9354411423206329,
            "l2_ratio": 0.8980011582374573,
            "relative_reconstruction_bias": 0.9603017032146454,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 2.5653805255889894,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9884158194065094,
            "frac_alive": 0.4109157919883728,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_0_step_0": {
            "l2_loss": 217.6,
            "l1_loss": 12697.6,
            "l0": 9219.10849609375,
            "frac_variance_explained": -1.03125,
            "cossim": 0.0041290283203125,
            "l2_ratio": 1.1546875,
            "relative_reconstruction_bias": 242.8,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 19.563122940063476,
            "loss_zero": 12.452932643890382,
            "frac_recovered": -0.710543018579483,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_0_step_15440": {
            "l2_loss": 45.65,
            "l1_loss": 719.6,
            "l0": 673.3541748046875,
            "frac_variance_explained": 0.8828125,
            "cossim": 0.948046875,
            "l2_ratio": 0.91171875,
            "relative_reconstruction_bias": 0.974609375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.5144663572311403,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.992665809392929,
            "frac_alive": 0.6722548007965088,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_3_step_154": {
            "l2_loss": 140.9,
            "l1_loss": 3142.4,
            "l0": 3520.612548828125,
            "frac_variance_explained": -0.069140625,
            "cossim": 0.291015625,
            "l2_ratio": 0.3875,
            "relative_reconstruction_bias": 1.308203125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 9.744282913208007,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.2705884039402008,
            "frac_alive": 0.9943576455116272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_2_step_154": {
            "l2_loss": 141.2,
            "l1_loss": 3417.6,
            "l0": 3691.47509765625,
            "frac_variance_explained": -0.040234375,
            "cossim": 0.3244140625,
            "l2_ratio": 0.4064453125,
            "relative_reconstruction_bias": 1.22109375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 9.383785438537597,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.3066366076469421,
            "frac_alive": 0.99658203125,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_2_step_1544": {
            "l2_loss": 82.7,
            "l1_loss": 241.6,
            "l0": 60.62500152587891,
            "frac_variance_explained": 0.5109375,
            "cossim": 0.8140625,
            "l2_ratio": 0.765625,
            "relative_reconstruction_bias": 0.950390625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 4.482995939254761,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.7959964573383331,
            "frac_alive": 0.1371527761220932,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_1_step_4882": {
            "l2_loss": 68.95,
            "l1_loss": 354.8,
            "l0": 141.5416732788086,
            "frac_variance_explained": 0.626953125,
            "cossim": 0.87421875,
            "l2_ratio": 0.82109375,
            "relative_reconstruction_bias": 0.94296875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.8861867427825927,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9555670261383057,
            "frac_alive": 0.1347113698720932,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_3_step_488": {
            "l2_loss": 107.6,
            "l1_loss": 263.7,
            "l0": 187.25833892822266,
            "frac_variance_explained": 0.18203125,
            "cossim": 0.65,
            "l2_ratio": 0.5578125,
            "relative_reconstruction_bias": 0.87890625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 8.886247253417968,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.35650283098220825,
            "frac_alive": 0.7111545205116272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_2_step_488": {
            "l2_loss": 101.1,
            "l1_loss": 326.8,
            "l0": 210.6291702270508,
            "frac_variance_explained": 0.2640625,
            "cossim": 0.70234375,
            "l2_ratio": 0.614453125,
            "relative_reconstruction_bias": 0.890625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 7.406615495681763,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.5041129201650619,
            "frac_alive": 0.7194553017616272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_2_step_0": {
            "l2_loss": 227.9,
            "l1_loss": 13337.6,
            "l0": 9220.1462890625,
            "frac_variance_explained": -1.034375,
            "cossim": 0.00837249755859375,
            "l2_ratio": 1.15546875,
            "relative_reconstruction_bias": 130.1,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 19.563122940063476,
            "loss_zero": 12.452932643890382,
            "frac_recovered": -0.710543018579483,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_5_step_15440": {
            "l2_loss": 87.6,
            "l1_loss": 153.9,
            "l0": 20.15416736602783,
            "frac_variance_explained": 0.454296875,
            "cossim": 0.782421875,
            "l2_ratio": 0.7171875,
            "relative_reconstruction_bias": 0.9328125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 5.088769006729126,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.7355478584766388,
            "frac_alive": 0.013888888992369175,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_4_step_1544": {
            "l2_loss": 96.05,
            "l1_loss": 163.1,
            "l0": 23.87500057220459,
            "frac_variance_explained": 0.401171875,
            "cossim": 0.746484375,
            "l2_ratio": 0.683203125,
            "relative_reconstruction_bias": 0.932421875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 6.304030132293701,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.6141297578811645,
            "frac_alive": 0.0886501744389534,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_4_step_488": {
            "l2_loss": 111.1,
            "l1_loss": 228.8,
            "l0": 161.11667175292968,
            "frac_variance_explained": 0.181640625,
            "cossim": 0.63359375,
            "l2_ratio": 0.525390625,
            "relative_reconstruction_bias": 0.858984375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 9.610341358184815,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.2841554760932922,
            "frac_alive": 0.7009548544883728,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_5_step_488": {
            "l2_loss": 124.95,
            "l1_loss": 204.45,
            "l0": 160.62917098999023,
            "frac_variance_explained": 0.2703125,
            "cossim": 0.553515625,
            "l2_ratio": 0.316796875,
            "relative_reconstruction_bias": 0.708984375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 10.599821949005127,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.18526119142770767,
            "frac_alive": 0.7195637822151184,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_5_step_48": {
            "l2_loss": 182.1,
            "l1_loss": 11756.8,
            "l0": 8451.31689453125,
            "frac_variance_explained": -0.77421875,
            "cossim": 0.08115234375,
            "l2_ratio": 0.753515625,
            "relative_reconstruction_bias": 9.053125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 10.701376819610596,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.1750192239880562,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_2_step_15440": {
            "l2_loss": 63.65,
            "l1_loss": 358.4,
            "l0": 140.45833892822264,
            "frac_variance_explained": 0.72890625,
            "cossim": 0.897265625,
            "l2_ratio": 0.844921875,
            "relative_reconstruction_bias": 0.951953125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.716301202774048,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9725344896316528,
            "frac_alive": 0.241970494389534,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_3_step_1544": {
            "l2_loss": 91.6,
            "l1_loss": 197.6,
            "l0": 37.650001525878906,
            "frac_variance_explained": 0.503515625,
            "cossim": 0.78046875,
            "l2_ratio": 0.72265625,
            "relative_reconstruction_bias": 0.947265625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 5.352246809005737,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.709167218208313,
            "frac_alive": 0.1135525181889534,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_0_step_4882": {
            "l2_loss": 54.025,
            "l1_loss": 653.2,
            "l0": 478.7708465576172,
            "frac_variance_explained": 0.78828125,
            "cossim": 0.926953125,
            "l2_ratio": 0.87734375,
            "relative_reconstruction_bias": 0.951953125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.5821482658386232,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.98592569231987,
            "frac_alive": 0.2722981870174408,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_4_step_154": {
            "l2_loss": 148.3,
            "l1_loss": 3659.2,
            "l0": 3528.3126220703125,
            "frac_variance_explained": -0.00859375,
            "cossim": 0.284375,
            "l2_ratio": 0.3830078125,
            "relative_reconstruction_bias": 1.25,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 9.948379707336425,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.2501836001873016,
            "frac_alive": 0.9934353232383728,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_5_step_154": {
            "l2_loss": 142.9,
            "l1_loss": 3104.0,
            "l0": 3512.3501220703124,
            "frac_variance_explained": -0.062109375,
            "cossim": 0.2708984375,
            "l2_ratio": 0.3837890625,
            "relative_reconstruction_bias": 1.341015625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 10.05876636505127,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.23915767222642897,
            "frac_alive": 0.994140625,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_4_step_0": {
            "l2_loss": 225.7,
            "l1_loss": 13216.0,
            "l0": 9215.48349609375,
            "frac_variance_explained": -1.03046875,
            "cossim": 0.007458209991455078,
            "l2_ratio": 1.153125,
            "relative_reconstruction_bias": -8355.05,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 19.563122940063476,
            "loss_zero": 12.452932643890382,
            "frac_recovered": -0.710543018579483,
            "frac_alive": 0.9999457597732544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_4_step_48": {
            "l2_loss": 177.3,
            "l1_loss": 11411.2,
            "l0": 8449.48369140625,
            "frac_variance_explained": -0.7890625,
            "cossim": 0.080859375,
            "l2_ratio": 0.755859375,
            "relative_reconstruction_bias": 9.15,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 10.689292430877686,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.17622570991516112,
            "frac_alive": 0.9999457597732544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_5_step_1544": {
            "l2_loss": 99.25,
            "l1_loss": 136.9,
            "l0": 16.15416736602783,
            "frac_variance_explained": 0.33515625,
            "cossim": 0.723046875,
            "l2_ratio": 0.65546875,
            "relative_reconstruction_bias": 0.92265625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 7.244567346572876,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.5202153503894806,
            "frac_alive": 0.0591905377805233,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_1_step_48": {
            "l2_loss": 188.9,
            "l1_loss": 12384.0,
            "l0": 8454.1712890625,
            "frac_variance_explained": -0.6765625,
            "cossim": 0.08720703125,
            "l2_ratio": 0.75625,
            "relative_reconstruction_bias": 8.128125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 10.604339790344238,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.18471183478832245,
            "frac_alive": 0.9999457597732544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_5_step_4882": {
            "l2_loss": 91.45,
            "l1_loss": 141.15,
            "l0": 15.133333778381347,
            "frac_variance_explained": 0.3828125,
            "cossim": 0.755859375,
            "l2_ratio": 0.683984375,
            "relative_reconstruction_bias": 0.92109375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 6.110202693939209,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.6334960699081421,
            "frac_alive": 0.008626301772892475,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_4_step_15440": {
            "l2_loss": 79.25,
            "l1_loss": 188.4,
            "l0": 35.304167938232425,
            "frac_variance_explained": 0.52734375,
            "cossim": 0.825390625,
            "l2_ratio": 0.760546875,
            "relative_reconstruction_bias": 0.93046875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 4.10310423374176,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.8339592039585113,
            "frac_alive": 0.0388997383415699,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_0_step_488": {
            "l2_loss": 89.5,
            "l1_loss": 508.4,
            "l0": 306.70000915527345,
            "frac_variance_explained": 0.43046875,
            "cossim": 0.784375,
            "l2_ratio": 0.713671875,
            "relative_reconstruction_bias": 0.91953125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 5.207838249206543,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.7236662685871125,
            "frac_alive": 0.7305229902267456,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_1_step_488": {
            "l2_loss": 98.15,
            "l1_loss": 381.2,
            "l0": 213.7291748046875,
            "frac_variance_explained": 0.3546875,
            "cossim": 0.727734375,
            "l2_ratio": 0.65,
            "relative_reconstruction_bias": 0.910546875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 6.74614634513855,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.5700634002685547,
            "frac_alive": 0.7088758945465088,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_1_step_0": {
            "l2_loss": 230.8,
            "l1_loss": 13510.4,
            "l0": 9219.1044921875,
            "frac_variance_explained": -1.053125,
            "cossim": 0.0073699951171875,
            "l2_ratio": 1.15546875,
            "relative_reconstruction_bias": 181.7,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 19.563122940063476,
            "loss_zero": 12.452932643890382,
            "frac_recovered": -0.710543018579483,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_0_step_1544": {
            "l2_loss": 69.55,
            "l1_loss": 493.4,
            "l0": 255.4000045776367,
            "frac_variance_explained": 0.64609375,
            "cossim": 0.8765625,
            "l2_ratio": 0.824609375,
            "relative_reconstruction_bias": 0.947265625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 3.072607707977295,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9368688404560089,
            "frac_alive": 0.2028537392616272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_1_step_15440": {
            "l2_loss": 58.025,
            "l1_loss": 424.0,
            "l0": 212.88750610351562,
            "frac_variance_explained": 0.785546875,
            "cossim": 0.91328125,
            "l2_ratio": 0.867578125,
            "relative_reconstruction_bias": 0.959765625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.6162596464157106,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9825248777866363,
            "frac_alive": 0.3571506142616272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_3_step_4882": {
            "l2_loss": 79.45,
            "l1_loss": 212.9,
            "l0": 40.37083473205566,
            "frac_variance_explained": 0.619921875,
            "cossim": 0.82109375,
            "l2_ratio": 0.759375,
            "relative_reconstruction_bias": 0.948828125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 4.25244140625,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.8189941287040711,
            "frac_alive": 0.0354275181889534,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_3_step_0": {
            "l2_loss": 224.6,
            "l1_loss": 13132.8,
            "l0": 9213.05458984375,
            "frac_variance_explained": -1.03046875,
            "cossim": 0.007816314697265625,
            "l2_ratio": 1.15546875,
            "relative_reconstruction_bias": 195.5,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 19.563122940063476,
            "loss_zero": 12.452932643890382,
            "frac_recovered": -0.710543018579483,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_0_step_48": {
            "l2_loss": 174.1,
            "l1_loss": 11296.0,
            "l0": 8454.97939453125,
            "frac_variance_explained": -0.75546875,
            "cossim": 0.10068359375,
            "l2_ratio": 0.75859375,
            "relative_reconstruction_bias": 7.478125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 10.471371078491211,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.1980000004172325,
            "frac_alive": 0.9999457597732544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_0_step_154": {
            "l2_loss": 128.35,
            "l1_loss": 3496.0,
            "l0": 3833.566796875,
            "frac_variance_explained": -0.017578125,
            "cossim": 0.4515625,
            "l2_ratio": 0.462890625,
            "relative_reconstruction_bias": 1.023046875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 8.181695604324341,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.4267542868852615,
            "frac_alive": 0.9962565302848816,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_1_step_154": {
            "l2_loss": 138.4,
            "l1_loss": 3404.8,
            "l0": 3756.1584228515626,
            "frac_variance_explained": -0.034765625,
            "cossim": 0.35234375,
            "l2_ratio": 0.4197265625,
            "relative_reconstruction_bias": 1.165625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 9.118078804016113,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.33320634365081786,
            "frac_alive": 0.997178852558136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_4_step_4882": {
            "l2_loss": 87.2,
            "l1_loss": 171.1,
            "l0": 23.016667366027832,
            "frac_variance_explained": 0.5234375,
            "cossim": 0.78203125,
            "l2_ratio": 0.72421875,
            "relative_reconstruction_bias": 0.947265625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 5.1860432624816895,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.7257787346839905,
            "frac_alive": 0.01508246548473835,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_2_step_48": {
            "l2_loss": 176.7,
            "l1_loss": 11347.2,
            "l0": 8398.85029296875,
            "frac_variance_explained": -0.7203125,
            "cossim": 0.086279296875,
            "l2_ratio": 0.7546875,
            "relative_reconstruction_bias": 8.26875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 10.636037349700928,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.18154401183128357,
            "frac_alive": 0.9999457597732544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_1_step_1544": {
            "l2_loss": 80.25,
            "l1_loss": 283.6,
            "l0": 86.57500228881835,
            "frac_variance_explained": 0.50859375,
            "cossim": 0.832421875,
            "l2_ratio": 0.780859375,
            "relative_reconstruction_bias": 0.944140625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 4.01392765045166,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.8428499519824981,
            "frac_alive": 0.138671875,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_3_step_48": {
            "l2_loss": 178.8,
            "l1_loss": 11526.4,
            "l0": 8427.72529296875,
            "frac_variance_explained": -0.728125,
            "cossim": 0.0859375,
            "l2_ratio": 0.751953125,
            "relative_reconstruction_bias": 8.265625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 10.669744300842286,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.17817798852920533,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_2_step_4882": {
            "l2_loss": 72.2,
            "l1_loss": 301.6,
            "l0": 86.50000228881837,
            "frac_variance_explained": 0.73359375,
            "cossim": 0.8578125,
            "l2_ratio": 0.798828125,
            "relative_reconstruction_bias": 0.959375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 3.290687155723572,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9150846123695373,
            "frac_alive": 0.0876193568110466,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_3_step_15440": {
            "l2_loss": 72.05,
            "l1_loss": 252.3,
            "l0": 64.75000114440918,
            "frac_variance_explained": 0.631640625,
            "cossim": 0.861328125,
            "l2_ratio": 0.807421875,
            "relative_reconstruction_bias": 0.9453125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 3.132000136375427,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9310269713401794,
            "frac_alive": 0.099500872194767,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_5_step_0": {
            "l2_loss": 229.1,
            "l1_loss": 13427.2,
            "l0": 9219.6294921875,
            "frac_variance_explained": -1.03515625,
            "cossim": 0.0065277099609375,
            "l2_ratio": 1.1546875,
            "relative_reconstruction_bias": 1310.4,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 19.563122940063476,
            "loss_zero": 12.452932643890382,
            "frac_recovered": -0.710543018579483,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_0_step_0": {
            "l2_loss": 125.7,
            "l1_loss": 7436.8,
            "l0": 9314.20029296875,
            "frac_variance_explained": -1.015625,
            "cossim": 0.0109375,
            "l2_ratio": 1.16015625,
            "relative_reconstruction_bias": 119.65,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 11.83780632019043,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.06137360595166683,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_0_step_15440": {
            "l2_loss": 24.9625,
            "l1_loss": 291.6,
            "l0": 355.1000091552734,
            "frac_variance_explained": 0.8484375,
            "cossim": 0.95078125,
            "l2_ratio": 0.926953125,
            "relative_reconstruction_bias": 0.973046875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.5234706163406373,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9917698383331299,
            "frac_alive": 0.8058268427848816,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_3_step_154": {
            "l2_loss": 79.85,
            "l1_loss": 1197.6,
            "l0": 2669.2417236328124,
            "frac_variance_explained": -0.05625,
            "cossim": 0.2978515625,
            "l2_ratio": 0.3412109375,
            "relative_reconstruction_bias": 1.2796875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 9.308492755889892,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.31416334211826324,
            "frac_alive": 0.9962565302848816,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_2_step_154": {
            "l2_loss": 77.75,
            "l1_loss": 1216.0,
            "l0": 2727.2584228515625,
            "frac_variance_explained": -0.05078125,
            "cossim": 0.312890625,
            "l2_ratio": 0.35234375,
            "relative_reconstruction_bias": 1.2609375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 9.135836124420166,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.3314054012298584,
            "frac_alive": 0.99755859375,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_2_step_1544": {
            "l2_loss": 44.2,
            "l1_loss": 145.3,
            "l0": 62.200001907348636,
            "frac_variance_explained": 0.524609375,
            "cossim": 0.83125,
            "l2_ratio": 0.778515625,
            "relative_reconstruction_bias": 0.9359375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 3.927385950088501,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.8515277445316315,
            "frac_alive": 0.103895403444767,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_1_step_4882": {
            "l2_loss": 35.5625,
            "l1_loss": 197.7,
            "l0": 124.70417098999023,
            "frac_variance_explained": 0.69453125,
            "cossim": 0.89375,
            "l2_ratio": 0.848828125,
            "relative_reconstruction_bias": 0.948828125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.741474914550781,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9700230419635772,
            "frac_alive": 0.2506510317325592,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_3_step_488": {
            "l2_loss": 65.075,
            "l1_loss": 116.4,
            "l0": 120.4708381652832,
            "frac_variance_explained": 0.123828125,
            "cossim": 0.6140625,
            "l2_ratio": 0.51796875,
            "relative_reconstruction_bias": 0.84765625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 9.09445219039917,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.3355876266956329,
            "frac_alive": 0.6110568642616272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_2_step_488": {
            "l2_loss": 59.45,
            "l1_loss": 205.6,
            "l0": 163.7791732788086,
            "frac_variance_explained": 0.327734375,
            "cossim": 0.675390625,
            "l2_ratio": 0.589453125,
            "relative_reconstruction_bias": 0.89609375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 7.893911695480346,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.4554441511631012,
            "frac_alive": 0.6577690839767456,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_2_step_0": {
            "l2_loss": 125.5,
            "l1_loss": 7424.0,
            "l0": 9313.92958984375,
            "frac_variance_explained": -1.0140625,
            "cossim": 0.0107269287109375,
            "l2_ratio": 1.16015625,
            "relative_reconstruction_bias": 147.15,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 11.83780632019043,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.06137360595166683,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_5_step_15440": {
            "l2_loss": 47.15,
            "l1_loss": 88.15,
            "l0": 19.012500953674316,
            "frac_variance_explained": 0.474609375,
            "cossim": 0.80625,
            "l2_ratio": 0.746484375,
            "relative_reconstruction_bias": 0.92734375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 4.166976833343506,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.8276787519454956,
            "frac_alive": 0.0343967005610466,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_4_step_1544": {
            "l2_loss": 55.0,
            "l1_loss": 81.8,
            "l0": 19.595834159851073,
            "frac_variance_explained": 0.32421875,
            "cossim": 0.73984375,
            "l2_ratio": 0.6765625,
            "relative_reconstruction_bias": 0.913671875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 6.068083238601685,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.6377541959285736,
            "frac_alive": 0.0453559048473835,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_4_step_488": {
            "l2_loss": 68.6,
            "l1_loss": 82.75,
            "l0": 96.02500228881836,
            "frac_variance_explained": 0.0515625,
            "cossim": 0.544921875,
            "l2_ratio": 0.427734375,
            "relative_reconstruction_bias": 0.780078125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 10.85888614654541,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.15934529900550842,
            "frac_alive": 0.5725911259651184,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_5_step_488": {
            "l2_loss": 73.5,
            "l1_loss": 52.2,
            "l0": 84.69166946411133,
            "frac_variance_explained": 0.021875,
            "cossim": 0.4447265625,
            "l2_ratio": 0.2865234375,
            "relative_reconstruction_bias": 0.670703125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 10.837434673309327,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.16138963997364045,
            "frac_alive": 0.5611979365348816,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_5_step_48": {
            "l2_loss": 101.55,
            "l1_loss": 6374.4,
            "l0": 8310.27958984375,
            "frac_variance_explained": -0.7375,
            "cossim": 0.102978515625,
            "l2_ratio": 0.776953125,
            "relative_reconstruction_bias": 8.00625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 9.89528980255127,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.2555403396487236,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_2_step_15440": {
            "l2_loss": 31.5875,
            "l1_loss": 166.8,
            "l0": 92.54166946411132,
            "frac_variance_explained": 0.783203125,
            "cossim": 0.917578125,
            "l2_ratio": 0.880078125,
            "relative_reconstruction_bias": 0.9609375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.635545754432678,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9805962979793549,
            "frac_alive": 0.3427191972732544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_3_step_1544": {
            "l2_loss": 48.3,
            "l1_loss": 110.1,
            "l0": 37.441668319702146,
            "frac_variance_explained": 0.44140625,
            "cossim": 0.797265625,
            "l2_ratio": 0.7421875,
            "relative_reconstruction_bias": 0.930859375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 4.812506294250488,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.7631361186504364,
            "frac_alive": 0.0867513045668602,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_0_step_4882": {
            "l2_loss": 28.275,
            "l1_loss": 311.6,
            "l0": 347.51250915527345,
            "frac_variance_explained": 0.800390625,
            "cossim": 0.93359375,
            "l2_ratio": 0.900390625,
            "relative_reconstruction_bias": 0.959765625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.5743848085403442,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9866903483867645,
            "frac_alive": 0.42919921875,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_4_step_154": {
            "l2_loss": 81.25,
            "l1_loss": 1140.0,
            "l0": 2571.616748046875,
            "frac_variance_explained": -0.06171875,
            "cossim": 0.27763671875,
            "l2_ratio": 0.3271484375,
            "relative_reconstruction_bias": 1.29296875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 9.41802282333374,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.3032310396432877,
            "frac_alive": 0.9944118857383728,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_5_step_154": {
            "l2_loss": 78.75,
            "l1_loss": 1153.2,
            "l0": 2625.962548828125,
            "frac_variance_explained": -0.059375,
            "cossim": 0.276171875,
            "l2_ratio": 0.3359375,
            "relative_reconstruction_bias": 1.346875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 9.482363605499268,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.2968075037002563,
            "frac_alive": 0.9965277910232544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_4_step_0": {
            "l2_loss": 126.5,
            "l1_loss": 7500.8,
            "l0": 9319.98779296875,
            "frac_variance_explained": -1.0171875,
            "cossim": 0.011639404296875,
            "l2_ratio": 1.15859375,
            "relative_reconstruction_bias": 133.8,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 11.83780632019043,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.06137360595166683,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_4_step_48": {
            "l2_loss": 98.55,
            "l1_loss": 6134.4,
            "l0": 8311.712890625,
            "frac_variance_explained": -0.76953125,
            "cossim": 0.104541015625,
            "l2_ratio": 0.779296875,
            "relative_reconstruction_bias": 8.1625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 9.888659572601318,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.25620109885931014,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_5_step_1544": {
            "l2_loss": 59.25,
            "l1_loss": 68.225,
            "l0": 12.900000381469727,
            "frac_variance_explained": 0.28828125,
            "cossim": 0.687890625,
            "l2_ratio": 0.614453125,
            "relative_reconstruction_bias": 0.906640625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 7.193751859664917,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.525319117307663,
            "frac_alive": 0.0420464426279068,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_1_step_48": {
            "l2_loss": 100.5,
            "l1_loss": 6284.8,
            "l0": 8338.02119140625,
            "frac_variance_explained": -0.7625,
            "cossim": 0.1099609375,
            "l2_ratio": 0.781640625,
            "relative_reconstruction_bias": 7.709375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 9.845651054382325,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.2604978531599045,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_5_step_4882": {
            "l2_loss": 51.85,
            "l1_loss": 76.65,
            "l0": 13.975000286102295,
            "frac_variance_explained": 0.3515625,
            "cossim": 0.76015625,
            "l2_ratio": 0.6984375,
            "relative_reconstruction_bias": 0.92109375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 5.676401519775391,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.6768557488918304,
            "frac_alive": 0.01513671875,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_4_step_15440": {
            "l2_loss": 39.5,
            "l1_loss": 111.95,
            "l0": 31.587500762939452,
            "frac_variance_explained": 0.622265625,
            "cossim": 0.869140625,
            "l2_ratio": 0.8140625,
            "relative_reconstruction_bias": 0.934765625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 3.200065755844116,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9242486178874969,
            "frac_alive": 0.0857204869389534,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_0_step_488": {
            "l2_loss": 51.575,
            "l1_loss": 241.0,
            "l0": 266.0958419799805,
            "frac_variance_explained": 0.359765625,
            "cossim": 0.758203125,
            "l2_ratio": 0.688671875,
            "relative_reconstruction_bias": 0.908203125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 6.005924892425537,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.6439538896083832,
            "frac_alive": 0.7278103232383728,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_1_step_488": {
            "l2_loss": 58.8,
            "l1_loss": 164.2,
            "l0": 156.95000457763672,
            "frac_variance_explained": 0.22265625,
            "cossim": 0.691796875,
            "l2_ratio": 0.60859375,
            "relative_reconstruction_bias": 0.879296875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 7.364314270019531,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.5083250373601913,
            "frac_alive": 0.6274956464767456,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_1_step_0": {
            "l2_loss": 126.65,
            "l1_loss": 7497.6,
            "l0": 9318.3044921875,
            "frac_variance_explained": -1.0125,
            "cossim": 0.012921142578125,
            "l2_ratio": 1.16015625,
            "relative_reconstruction_bias": 100.1,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 11.83780632019043,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.06137360595166683,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_0_step_1544": {
            "l2_loss": 35.375,
            "l1_loss": 277.6,
            "l0": 236.23333587646485,
            "frac_variance_explained": 0.68359375,
            "cossim": 0.89375,
            "l2_ratio": 0.841796875,
            "relative_reconstruction_bias": 0.93828125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.9637906551361084,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9477954745292664,
            "frac_alive": 0.2267252653837204,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_1_step_15440": {
            "l2_loss": 27.8,
            "l1_loss": 190.6,
            "l0": 132.23333816528321,
            "frac_variance_explained": 0.810546875,
            "cossim": 0.9375,
            "l2_ratio": 0.91015625,
            "relative_reconstruction_bias": 0.97109375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.590347933769226,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9851083040237427,
            "frac_alive": 0.4578993022441864,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_3_step_4882": {
            "l2_loss": 40.875,
            "l1_loss": 129.15,
            "l0": 43.89166793823242,
            "frac_variance_explained": 0.599609375,
            "cossim": 0.860546875,
            "l2_ratio": 0.811328125,
            "relative_reconstruction_bias": 0.94140625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 3.269835376739502,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9172515153884888,
            "frac_alive": 0.0827907994389534,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_3_step_0": {
            "l2_loss": 127.8,
            "l1_loss": 7564.8,
            "l0": 9314.02529296875,
            "frac_variance_explained": -1.0171875,
            "cossim": 0.01275634765625,
            "l2_ratio": 1.16015625,
            "relative_reconstruction_bias": 122.45,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 11.83780632019043,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.06137360595166683,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_0_step_48": {
            "l2_loss": 100.4,
            "l1_loss": 6348.8,
            "l0": 8365.72119140625,
            "frac_variance_explained": -0.7578125,
            "cossim": 0.117138671875,
            "l2_ratio": 0.78125,
            "relative_reconstruction_bias": 7.171875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 9.779939556121827,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.26706644892692566,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_0_step_154": {
            "l2_loss": 74.35,
            "l1_loss": 1423.2,
            "l0": 3034.9625732421873,
            "frac_variance_explained": -0.0203125,
            "cossim": 0.425,
            "l2_ratio": 0.4044921875,
            "relative_reconstruction_bias": 1.062890625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 8.541642379760741,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.39075923562049864,
            "frac_alive": 0.9972330927848816,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_1_step_154": {
            "l2_loss": 78.45,
            "l1_loss": 1267.2,
            "l0": 2796.7500732421877,
            "frac_variance_explained": -0.04296875,
            "cossim": 0.3470703125,
            "l2_ratio": 0.3572265625,
            "relative_reconstruction_bias": 1.16328125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 9.005312633514404,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.3444338977336884,
            "frac_alive": 0.9959309697151184,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_4_step_4882": {
            "l2_loss": 47.825,
            "l1_loss": 101.25,
            "l0": 24.93750057220459,
            "frac_variance_explained": 0.47265625,
            "cossim": 0.80390625,
            "l2_ratio": 0.744921875,
            "relative_reconstruction_bias": 0.927734375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 4.213635277748108,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.8229243338108063,
            "frac_alive": 0.0367838554084301,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_2_step_48": {
            "l2_loss": 99.35,
            "l1_loss": 6192.0,
            "l0": 8333.63779296875,
            "frac_variance_explained": -0.76484375,
            "cossim": 0.10498046875,
            "l2_ratio": 0.7796875,
            "relative_reconstruction_bias": 8.059375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 9.861291313171387,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.2589359924197197,
            "frac_alive": 0.9999457597732544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_1_step_1544": {
            "l2_loss": 40.35,
            "l1_loss": 175.7,
            "l0": 88.10416946411132,
            "frac_variance_explained": 0.61796875,
            "cossim": 0.86015625,
            "l2_ratio": 0.808203125,
            "relative_reconstruction_bias": 0.94453125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 3.556185221672058,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.88861163854599,
            "frac_alive": 0.1337348073720932,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_3_step_48": {
            "l2_loss": 101.35,
            "l1_loss": 6284.8,
            "l0": 8309.35869140625,
            "frac_variance_explained": -0.7703125,
            "cossim": 0.10263671875,
            "l2_ratio": 0.784375,
            "relative_reconstruction_bias": 8.259375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 9.877824306488037,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.25728367567062377,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_2_step_4882": {
            "l2_loss": 37.2,
            "l1_loss": 173.3,
            "l0": 87.1208366394043,
            "frac_variance_explained": 0.666015625,
            "cossim": 0.886328125,
            "l2_ratio": 0.842578125,
            "relative_reconstruction_bias": 0.94921875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.8570242881774903,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9584941565990448,
            "frac_alive": 0.1792534738779068,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_3_step_15440": {
            "l2_loss": 35.425,
            "l1_loss": 137.65,
            "l0": 55.01666831970215,
            "frac_variance_explained": 0.6875,
            "cossim": 0.894921875,
            "l2_ratio": 0.85546875,
            "relative_reconstruction_bias": 0.95546875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.7959484815597535,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.964591920375824,
            "frac_alive": 0.1822916716337204,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_5_step_0": {
            "l2_loss": 129.15,
            "l1_loss": 7664.0,
            "l0": 9313.76279296875,
            "frac_variance_explained": -1.0265625,
            "cossim": 0.012237548828125,
            "l2_ratio": 1.1609375,
            "relative_reconstruction_bias": 115.35,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 11.83780632019043,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.06137360595166683,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15/trainer_4": {
            "l2_loss": 100.62484130859374,
            "l1_loss": 293.18482360839846,
            "l0": 36.97916793823242,
            "frac_variance_explained": 0.6519956588745117,
            "cossim": 0.8504042506217957,
            "l2_ratio": 0.7920243203639984,
            "relative_reconstruction_bias": 0.9472394466400147,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 3.856266975402832,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.8594030737876892,
            "frac_alive": 0.0527886301279068,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15/trainer_3": {
            "l2_loss": 86.71902770996094,
            "l1_loss": 364.9580352783203,
            "l0": 71.50417022705078,
            "frac_variance_explained": 0.6865922451019287,
            "cossim": 0.8930394947528839,
            "l2_ratio": 0.8478472054004669,
            "relative_reconstruction_bias": 0.9547323644161224,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 3.048255777359009,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9401768267154693,
            "frac_alive": 0.1317816823720932,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15/trainer_2": {
            "l2_loss": 74.8343132019043,
            "l1_loss": 518.3208557128906,
            "l0": 142.83750610351564,
            "frac_variance_explained": 0.8427973449230194,
            "cossim": 0.9188935577869415,
            "l2_ratio": 0.8754505813121796,
            "relative_reconstruction_bias": 0.9714335024356842,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 2.7009095668792726,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9748838484287262,
            "frac_alive": 0.29736328125,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15/trainer_5": {
            "l2_loss": 116.31973800659179,
            "l1_loss": 210.37218780517577,
            "l0": 21.50833396911621,
            "frac_variance_explained": 0.46255811452865603,
            "cossim": 0.8006493985652924,
            "l2_ratio": 0.7345048308372497,
            "relative_reconstruction_bias": 0.9271275222301483,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 5.067263555526734,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.738304591178894,
            "frac_alive": 0.0166015625,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15/trainer_0": {
            "l2_loss": 55.63053817749024,
            "l1_loss": 868.72734375,
            "l0": 563.5500183105469,
            "frac_variance_explained": 0.8843899667263031,
            "cossim": 0.9587938010692596,
            "l2_ratio": 0.9266170263290405,
            "relative_reconstruction_bias": 0.9712898671627045,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 2.5277384996414183,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9921594679355621,
            "frac_alive": 0.717881977558136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15/trainer_1": {
            "l2_loss": 71.06571426391602,
            "l1_loss": 582.3175720214844,
            "l0": 211.7916717529297,
            "frac_variance_explained": 0.8105550169944763,
            "cossim": 0.9292273700237275,
            "l2_ratio": 0.893325787782669,
            "relative_reconstruction_bias": 0.9668030560016632,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 2.6204474687576296,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9829143047332763,
            "frac_alive": 0.4157443642616272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3/trainer_4": {
            "l2_loss": 42.25794639587402,
            "l1_loss": 115.70429000854492,
            "l0": 32.9708345413208,
            "frac_variance_explained": 0.6629013299942017,
            "cossim": 0.8515677750110626,
            "l2_ratio": 0.8004781782627106,
            "relative_reconstruction_bias": 0.9513620138168335,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 3.185274624824524,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9264948964118958,
            "frac_alive": 0.093153215944767,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3/trainer_3": {
            "l2_loss": 34.156801795959474,
            "l1_loss": 130.57741775512696,
            "l0": 53.18750190734863,
            "frac_variance_explained": 0.7166793942451477,
            "cossim": 0.8976885914802551,
            "l2_ratio": 0.857718962430954,
            "relative_reconstruction_bias": 0.9572011172771454,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 2.7937287092208862,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9656153500080109,
            "frac_alive": 0.189724400639534,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3/trainer_2": {
            "l2_loss": 30.10821990966797,
            "l1_loss": 162.0966369628906,
            "l0": 92.37917022705078,
            "frac_variance_explained": 0.7919197320938111,
            "cossim": 0.9215337336063385,
            "l2_ratio": 0.8894334852695465,
            "relative_reconstruction_bias": 0.967528659105301,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 2.6364114046096803,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.981322419643402,
            "frac_alive": 0.3464626669883728,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3/trainer_5": {
            "l2_loss": 47.68552360534668,
            "l1_loss": 81.06160049438476,
            "l0": 18.433334159851075,
            "frac_variance_explained": 0.4669169783592224,
            "cossim": 0.8034469485282898,
            "l2_ratio": 0.7498004794120788,
            "relative_reconstruction_bias": 0.9302173733711243,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 4.220582270622254,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.8229339301586152,
            "frac_alive": 0.0354275181889534,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3/trainer_0": {
            "l2_loss": 23.335896301269532,
            "l1_loss": 270.1961273193359,
            "l0": 320.6666748046875,
            "frac_variance_explained": 0.8943248569965363,
            "cossim": 0.9556451797485351,
            "l2_ratio": 0.9313349306583405,
            "relative_reconstruction_bias": 0.9799374282360077,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 2.5290406227111815,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9920366525650024,
            "frac_alive": 0.7665473222732544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_3/trainer_1": {
            "l2_loss": 27.491335487365724,
            "l1_loss": 188.43201599121093,
            "l0": 129.9791717529297,
            "frac_variance_explained": 0.8262831807136536,
            "cossim": 0.93378546833992,
            "l2_ratio": 0.906765204668045,
            "relative_reconstruction_bias": 0.9746900081634522,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 2.5945015430450438,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9855089008808136,
            "frac_alive": 0.4690755307674408,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_0_step_0": {
            "l2_loss": 298.4,
            "l1_loss": 17523.2,
            "l0": 9199.8087890625,
            "frac_variance_explained": -1.0109375,
            "cossim": 0.0119964599609375,
            "l2_ratio": 1.14921875,
            "relative_reconstruction_bias": 106.025,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 19.979672050476076,
            "loss_zero": 12.452932643890382,
            "frac_recovered": -0.7520080089569092,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_0_step_15440": {
            "l2_loss": 57.575,
            "l1_loss": 872.0,
            "l0": 579.3583557128907,
            "frac_variance_explained": 0.858203125,
            "cossim": 0.955078125,
            "l2_ratio": 0.91875,
            "relative_reconstruction_bias": 0.965625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.526445484161377,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9914665818214417,
            "frac_alive": 0.6834852695465088,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_3_step_154": {
            "l2_loss": 193.1,
            "l1_loss": 4678.4,
            "l0": 3734.7125732421873,
            "frac_variance_explained": -0.078515625,
            "cossim": 0.315234375,
            "l2_ratio": 0.4,
            "relative_reconstruction_bias": 1.27109375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 9.022181034088135,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.34281357526779177,
            "frac_alive": 0.99560546875,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_2_step_154": {
            "l2_loss": 192.6,
            "l1_loss": 4803.2,
            "l0": 3740.0417236328126,
            "frac_variance_explained": -0.023046875,
            "cossim": 0.346875,
            "l2_ratio": 0.405859375,
            "relative_reconstruction_bias": 1.128515625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 8.6781081199646,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.3772002398967743,
            "frac_alive": 0.9958224892616272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_2_step_1544": {
            "l2_loss": 107.85,
            "l1_loss": 341.2,
            "l0": 60.12916870117188,
            "frac_variance_explained": 0.5296875,
            "cossim": 0.830859375,
            "l2_ratio": 0.77890625,
            "relative_reconstruction_bias": 0.94765625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 4.502575922012329,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.7940543353557586,
            "frac_alive": 0.0950520858168602,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_1_step_4882": {
            "l2_loss": 84.55,
            "l1_loss": 500.2,
            "l0": 145.20417175292968,
            "frac_variance_explained": 0.723046875,
            "cossim": 0.89296875,
            "l2_ratio": 0.845703125,
            "relative_reconstruction_bias": 0.95625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.915688180923462,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9526396453380584,
            "frac_alive": 0.184353306889534,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_3_step_488": {
            "l2_loss": 143.8,
            "l1_loss": 381.6,
            "l0": 195.20000610351562,
            "frac_variance_explained": 0.195703125,
            "cossim": 0.67421875,
            "l2_ratio": 0.575,
            "relative_reconstruction_bias": 0.869140625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 7.941213989257813,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.45088631212711333,
            "frac_alive": 0.72998046875,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_2_step_488": {
            "l2_loss": 133.6,
            "l1_loss": 482.6,
            "l0": 236.40001068115234,
            "frac_variance_explained": 0.30390625,
            "cossim": 0.7203125,
            "l2_ratio": 0.6375,
            "relative_reconstruction_bias": 0.89921875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 6.817232656478882,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.5630136430263519,
            "frac_alive": 0.74267578125,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_2_step_0": {
            "l2_loss": 303.4,
            "l1_loss": 17740.8,
            "l0": 9200.38779296875,
            "frac_variance_explained": -1.0109375,
            "cossim": 0.0105377197265625,
            "l2_ratio": 1.15,
            "relative_reconstruction_bias": 108.45,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 19.979672050476076,
            "loss_zero": 12.452932643890382,
            "frac_recovered": -0.7520080089569092,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_5_step_15440": {
            "l2_loss": 116.45,
            "l1_loss": 223.4,
            "l0": 21.112500381469726,
            "frac_variance_explained": 0.496484375,
            "cossim": 0.799609375,
            "l2_ratio": 0.736328125,
            "relative_reconstruction_bias": 0.93671875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 5.163997936248779,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.7280074059963226,
            "frac_alive": 0.01513671875,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_4_step_1544": {
            "l2_loss": 123.85,
            "l1_loss": 215.0,
            "l0": 25.329167556762695,
            "frac_variance_explained": 0.397265625,
            "cossim": 0.75234375,
            "l2_ratio": 0.691796875,
            "relative_reconstruction_bias": 0.937109375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 6.16484842300415,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.6280666649341583,
            "frac_alive": 0.0861545130610466,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_4_step_488": {
            "l2_loss": 155.7,
            "l1_loss": 330.2,
            "l0": 198.4083396911621,
            "frac_variance_explained": 0.145703125,
            "cossim": 0.624609375,
            "l2_ratio": 0.5013671875,
            "relative_reconstruction_bias": 0.824609375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 9.115774059295655,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.33352536559104917,
            "frac_alive": 0.7464192509651184,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_5_step_488": {
            "l2_loss": 172.3,
            "l1_loss": 180.2,
            "l0": 180.89167327880858,
            "frac_variance_explained": 0.0265625,
            "cossim": 0.5267578125,
            "l2_ratio": 0.2748046875,
            "relative_reconstruction_bias": 0.54453125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 10.057819747924805,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.23940212279558182,
            "frac_alive": 0.7567816972732544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_5_step_48": {
            "l2_loss": 241.9,
            "l1_loss": 15590.4,
            "l0": 8443.78798828125,
            "frac_variance_explained": -0.75390625,
            "cossim": 0.08896484375,
            "l2_ratio": 0.76171875,
            "relative_reconstruction_bias": 8.365625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 10.843234443664551,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.16092031002044677,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_2_step_15440": {
            "l2_loss": 77.3,
            "l1_loss": 487.6,
            "l0": 137.42917175292968,
            "frac_variance_explained": 0.770703125,
            "cossim": 0.917578125,
            "l2_ratio": 0.875390625,
            "relative_reconstruction_bias": 0.957421875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.736348795890808,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9705508470535278,
            "frac_alive": 0.2677951455116272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_3_step_1544": {
            "l2_loss": 117.95,
            "l1_loss": 266.0,
            "l0": 40.29166831970215,
            "frac_variance_explained": 0.43046875,
            "cossim": 0.7953125,
            "l2_ratio": 0.739453125,
            "relative_reconstruction_bias": 0.937890625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 5.293327379226684,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.715108186006546,
            "frac_alive": 0.1028645858168602,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_0_step_4882": {
            "l2_loss": 67.425,
            "l1_loss": 873.2,
            "l0": 466.35418090820315,
            "frac_variance_explained": 0.8203125,
            "cossim": 0.93515625,
            "l2_ratio": 0.895703125,
            "relative_reconstruction_bias": 0.964453125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.608068060874939,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9833413660526276,
            "frac_alive": 0.3128255307674408,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_4_step_154": {
            "l2_loss": 193.4,
            "l1_loss": 4726.4,
            "l0": 3796.5126220703123,
            "frac_variance_explained": -0.0984375,
            "cossim": 0.2982421875,
            "l2_ratio": 0.4029296875,
            "relative_reconstruction_bias": 1.34921875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 9.211329936981201,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.32391943633556364,
            "frac_alive": 0.9954969882965088,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_5_step_154": {
            "l2_loss": 192.4,
            "l1_loss": 4328.0,
            "l0": 3605.087548828125,
            "frac_variance_explained": -0.092578125,
            "cossim": 0.2828125,
            "l2_ratio": 0.387890625,
            "relative_reconstruction_bias": 1.35859375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 9.340449142456055,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.31101674735546114,
            "frac_alive": 0.9951714277267456,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_4_step_0": {
            "l2_loss": 301.6,
            "l1_loss": 17689.6,
            "l0": 9208.08369140625,
            "frac_variance_explained": -1.01328125,
            "cossim": 0.013214111328125,
            "l2_ratio": 1.1515625,
            "relative_reconstruction_bias": 84.4,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 19.979672050476076,
            "loss_zero": 12.452932643890382,
            "frac_recovered": -0.7520080089569092,
            "frac_alive": 0.9999457597732544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_4_step_48": {
            "l2_loss": 255.0,
            "l1_loss": 16787.2,
            "l0": 8465.43369140625,
            "frac_variance_explained": -0.715625,
            "cossim": 0.093994140625,
            "l2_ratio": 0.753515625,
            "relative_reconstruction_bias": 7.95,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 10.824813652038575,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.16276027262210846,
            "frac_alive": 0.9999457597732544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_5_step_1544": {
            "l2_loss": 131.3,
            "l1_loss": 186.2,
            "l0": 16.7916672706604,
            "frac_variance_explained": 0.282421875,
            "cossim": 0.738671875,
            "l2_ratio": 0.6703125,
            "relative_reconstruction_bias": 0.918359375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 7.088256406784057,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.5358434379100799,
            "frac_alive": 0.0676540806889534,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_1_step_48": {
            "l2_loss": 236.3,
            "l1_loss": 15417.6,
            "l0": 8462.312890625,
            "frac_variance_explained": -0.75859375,
            "cossim": 0.096337890625,
            "l2_ratio": 0.75078125,
            "relative_reconstruction_bias": 7.54375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 10.713249492645264,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.17390942722558975,
            "frac_alive": 0.9998915195465088,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_5_step_4882": {
            "l2_loss": 128.45,
            "l1_loss": 191.4,
            "l0": 14.500000286102296,
            "frac_variance_explained": 0.336328125,
            "cossim": 0.7484375,
            "l2_ratio": 0.681640625,
            "relative_reconstruction_bias": 0.920703125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 6.227117872238159,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.6218695878982544,
            "frac_alive": 0.009006076492369175,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_4_step_15440": {
            "l2_loss": 104.85,
            "l1_loss": 291.8,
            "l0": 37.57083435058594,
            "frac_variance_explained": 0.597265625,
            "cossim": 0.839453125,
            "l2_ratio": 0.781640625,
            "relative_reconstruction_bias": 0.9453125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 3.941355586051941,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.8501846313476562,
            "frac_alive": 0.0476345494389534,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_0_step_488": {
            "l2_loss": 121.25,
            "l1_loss": 727.2,
            "l0": 390.58751220703124,
            "frac_variance_explained": 0.439453125,
            "cossim": 0.77421875,
            "l2_ratio": 0.70546875,
            "relative_reconstruction_bias": 0.923046875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 5.248047256469727,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.7196589469909668,
            "frac_alive": 0.8287760615348816,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_1_step_488": {
            "l2_loss": 130.5,
            "l1_loss": 524.4,
            "l0": 264.0416717529297,
            "frac_variance_explained": 0.33515625,
            "cossim": 0.73359375,
            "l2_ratio": 0.651953125,
            "relative_reconstruction_bias": 0.903125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 6.326344060897827,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.6120063900947571,
            "frac_alive": 0.763780415058136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_1_step_0": {
            "l2_loss": 303.8,
            "l1_loss": 17772.8,
            "l0": 9207.08798828125,
            "frac_variance_explained": -1.01796875,
            "cossim": 0.0111541748046875,
            "l2_ratio": 1.1515625,
            "relative_reconstruction_bias": 110.975,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 19.979672050476076,
            "loss_zero": 12.452932643890382,
            "frac_recovered": -0.7520080089569092,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_0_step_1544": {
            "l2_loss": 88.45,
            "l1_loss": 678.0,
            "l0": 257.46667633056643,
            "frac_variance_explained": 0.694921875,
            "cossim": 0.889453125,
            "l2_ratio": 0.843359375,
            "relative_reconstruction_bias": 0.95546875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 3.161420702934265,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.928012239933014,
            "frac_alive": 0.2344835102558136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_1_step_15440": {
            "l2_loss": 72.2,
            "l1_loss": 592.0,
            "l0": 210.61667175292968,
            "frac_variance_explained": 0.82109375,
            "cossim": 0.93046875,
            "l2_ratio": 0.887109375,
            "relative_reconstruction_bias": 0.966796875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.6363804817199705,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9805110156536102,
            "frac_alive": 0.3841688334941864,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_3_step_4882": {
            "l2_loss": 106.15,
            "l1_loss": 306.8,
            "l0": 45.35833511352539,
            "frac_variance_explained": 0.541796875,
            "cossim": 0.837109375,
            "l2_ratio": 0.782421875,
            "relative_reconstruction_bias": 0.94140625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 4.1498006820678714,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.8292764723300934,
            "frac_alive": 0.0440538190305233,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_3_step_0": {
            "l2_loss": 322.4,
            "l1_loss": 18944.0,
            "l0": 9201.4171875,
            "frac_variance_explained": -1.05390625,
            "cossim": 0.0118377685546875,
            "l2_ratio": 1.15,
            "relative_reconstruction_bias": 148.85,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 19.979672050476076,
            "loss_zero": 12.452932643890382,
            "frac_recovered": -0.7520080089569092,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_0_step_48": {
            "l2_loss": 233.0,
            "l1_loss": 15436.8,
            "l0": 8506.6794921875,
            "frac_variance_explained": -0.73125,
            "cossim": 0.1138671875,
            "l2_ratio": 0.755859375,
            "relative_reconstruction_bias": 6.384375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 10.566972827911377,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.18852877020835876,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_0_step_154": {
            "l2_loss": 178.5,
            "l1_loss": 5555.2,
            "l0": 4155.38759765625,
            "frac_variance_explained": 0.012890625,
            "cossim": 0.4712890625,
            "l2_ratio": 0.4849609375,
            "relative_reconstruction_bias": 1.014453125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 7.340534353256226,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.510846272110939,
            "frac_alive": 0.9973415732383728,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_1_step_154": {
            "l2_loss": 189.9,
            "l1_loss": 5363.2,
            "l0": 3789.4833984375,
            "frac_variance_explained": 0.009375,
            "cossim": 0.371875,
            "l2_ratio": 0.4171875,
            "relative_reconstruction_bias": 1.08203125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 8.38591194152832,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.4064041078090668,
            "frac_alive": 0.9968532919883728,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_4_step_4882": {
            "l2_loss": 116.55,
            "l1_loss": 250.6,
            "l0": 26.537500381469727,
            "frac_variance_explained": 0.5171875,
            "cossim": 0.7984375,
            "l2_ratio": 0.7390625,
            "relative_reconstruction_bias": 0.94375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 5.107259798049927,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.73365877866745,
            "frac_alive": 0.03043619729578495,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_2_step_48": {
            "l2_loss": 239.2,
            "l1_loss": 15539.2,
            "l0": 8454.14189453125,
            "frac_variance_explained": -0.75859375,
            "cossim": 0.09560546875,
            "l2_ratio": 0.755859375,
            "relative_reconstruction_bias": 7.709375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 10.751816177368164,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.17005544751882554,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_1_step_1544": {
            "l2_loss": 101.15,
            "l1_loss": 418.6,
            "l0": 86.38333587646484,
            "frac_variance_explained": 0.61640625,
            "cossim": 0.852734375,
            "l2_ratio": 0.8046875,
            "relative_reconstruction_bias": 0.95234375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 4.054786968231201,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.838770842552185,
            "frac_alive": 0.1159396693110466,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_3_step_48": {
            "l2_loss": 239.7,
            "l1_loss": 15488.0,
            "l0": 8441.42529296875,
            "frac_variance_explained": -0.75859375,
            "cossim": 0.093603515625,
            "l2_ratio": 0.7578125,
            "relative_reconstruction_bias": 7.978125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 10.79729642868042,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.16551105678081512,
            "frac_alive": 0.9999457597732544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_2_step_4882": {
            "l2_loss": 91.3,
            "l1_loss": 416.8,
            "l0": 97.5583366394043,
            "frac_variance_explained": 0.651953125,
            "cossim": 0.882421875,
            "l2_ratio": 0.830859375,
            "relative_reconstruction_bias": 0.948828125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 3.217394709587097,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9225192904472351,
            "frac_alive": 0.1559787392616272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_3_step_15440": {
            "l2_loss": 92.55,
            "l1_loss": 368.2,
            "l0": 69.7333366394043,
            "frac_variance_explained": 0.673046875,
            "cossim": 0.875390625,
            "l2_ratio": 0.82265625,
            "relative_reconstruction_bias": 0.948046875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 3.124556040763855,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9317654490470886,
            "frac_alive": 0.1222330704331398,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_5_step_0": {
            "l2_loss": 303.2,
            "l1_loss": 17728.0,
            "l0": 9204.1169921875,
            "frac_variance_explained": -1.025,
            "cossim": 0.0110626220703125,
            "l2_ratio": 1.15078125,
            "relative_reconstruction_bias": 117.5,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 19.979672050476076,
            "loss_zero": 12.452932643890382,
            "frac_recovered": -0.7520080089569092,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_0_step_0": {
            "l2_loss": 156.2,
            "l1_loss": 9100.8,
            "l0": 9204.91708984375,
            "frac_variance_explained": -1.0046875,
            "cossim": 0.009985601902008057,
            "l2_ratio": 1.15546875,
            "relative_reconstruction_bias": -817.8,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 14.571032238006591,
            "loss_zero": 12.452932643890382,
            "frac_recovered": -0.21182486265897751,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_0_step_15440": {
            "l2_loss": 31.7875,
            "l1_loss": 436.4,
            "l0": 480.0208465576172,
            "frac_variance_explained": 0.852734375,
            "cossim": 0.951953125,
            "l2_ratio": 0.915234375,
            "relative_reconstruction_bias": 0.96328125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.500810742378235,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9940264821052551,
            "frac_alive": 0.6815863847732544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_3_step_154": {
            "l2_loss": 101.55,
            "l1_loss": 1732.8,
            "l0": 2908.891748046875,
            "frac_variance_explained": -0.06796875,
            "cossim": 0.2841796875,
            "l2_ratio": 0.3509765625,
            "relative_reconstruction_bias": 1.30859375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 9.223418617248536,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.3226252317428589,
            "frac_alive": 0.9947916865348816,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_2_step_154": {
            "l2_loss": 99.2,
            "l1_loss": 1861.6,
            "l0": 3093.6417724609373,
            "frac_variance_explained": -0.06953125,
            "cossim": 0.3095703125,
            "l2_ratio": 0.3720703125,
            "relative_reconstruction_bias": 1.27578125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 9.071795177459716,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.3377668857574463,
            "frac_alive": 0.9960395097732544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_2_step_1544": {
            "l2_loss": 60.15,
            "l1_loss": 184.8,
            "l0": 60.16666831970215,
            "frac_variance_explained": 0.49140625,
            "cossim": 0.81484375,
            "l2_ratio": 0.758203125,
            "relative_reconstruction_bias": 0.933984375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 4.2475543975830075,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.8195143282413483,
            "frac_alive": 0.0748697891831398,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_1_step_4882": {
            "l2_loss": 46.25,
            "l1_loss": 269.4,
            "l0": 138.33333740234374,
            "frac_variance_explained": 0.685546875,
            "cossim": 0.891796875,
            "l2_ratio": 0.840234375,
            "relative_reconstruction_bias": 0.94296875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.7839150190353394,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9657946586608886,
            "frac_alive": 0.14453125,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_3_step_488": {
            "l2_loss": 83.65,
            "l1_loss": 156.1,
            "l0": 130.44166946411133,
            "frac_variance_explained": 0.10234375,
            "cossim": 0.6140625,
            "l2_ratio": 0.511328125,
            "relative_reconstruction_bias": 0.83515625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 8.593794536590575,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.38564318120479585,
            "frac_alive": 0.6356879472732544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_2_step_488": {
            "l2_loss": 74.5,
            "l1_loss": 217.1,
            "l0": 177.02916870117187,
            "frac_variance_explained": 0.218359375,
            "cossim": 0.69765625,
            "l2_ratio": 0.60625,
            "relative_reconstruction_bias": 0.872265625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 7.28716459274292,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.5160931020975112,
            "frac_alive": 0.6647678017616272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_2_step_0": {
            "l2_loss": 157.7,
            "l1_loss": 9177.6,
            "l0": 9206.95458984375,
            "frac_variance_explained": -1.0140625,
            "cossim": 0.00892791748046875,
            "l2_ratio": 1.1546875,
            "relative_reconstruction_bias": 278.1,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 14.571032238006591,
            "loss_zero": 12.452932643890382,
            "frac_recovered": -0.21182486265897751,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_5_step_15440": {
            "l2_loss": 61.8,
            "l1_loss": 110.2,
            "l0": 20.550000381469726,
            "frac_variance_explained": 0.4359375,
            "cossim": 0.790234375,
            "l2_ratio": 0.719921875,
            "relative_reconstruction_bias": 0.912890625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 4.692216539382935,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.7752011001110077,
            "frac_alive": 0.0178493931889534,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_4_step_1544": {
            "l2_loss": 71.0,
            "l1_loss": 105.7,
            "l0": 18.870833778381346,
            "frac_variance_explained": 0.3015625,
            "cossim": 0.730078125,
            "l2_ratio": 0.6671875,
            "relative_reconstruction_bias": 0.92265625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 6.353987121582032,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.6091614365577698,
            "frac_alive": 0.05322265625,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_4_step_488": {
            "l2_loss": 87.2,
            "l1_loss": 122.55,
            "l0": 144.45000305175782,
            "frac_variance_explained": 0.03203125,
            "cossim": 0.559375,
            "l2_ratio": 0.4369140625,
            "relative_reconstruction_bias": 0.787109375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 9.534128379821777,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.2917644441127777,
            "frac_alive": 0.6735568642616272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_5_step_488": {
            "l2_loss": 103.5,
            "l1_loss": 49.0625,
            "l0": 136.8000045776367,
            "frac_variance_explained": 0.018359375,
            "cossim": 0.21806640625,
            "l2_ratio": 0.0637939453125,
            "relative_reconstruction_bias": 0.39658203125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 10.39458122253418,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.205659119784832,
            "frac_alive": 0.662109375,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_5_step_48": {
            "l2_loss": 127.05,
            "l1_loss": 7900.8,
            "l0": 8297.4294921875,
            "frac_variance_explained": -0.775,
            "cossim": 0.090673828125,
            "l2_ratio": 0.768359375,
            "relative_reconstruction_bias": 8.70625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 10.02195405960083,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.24295330047607422,
            "frac_alive": 0.9999457597732544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_2_step_15440": {
            "l2_loss": 42.6,
            "l1_loss": 255.2,
            "l0": 123.80416946411133,
            "frac_variance_explained": 0.74453125,
            "cossim": 0.910546875,
            "l2_ratio": 0.865625,
            "relative_reconstruction_bias": 0.95234375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.6330320835113525,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9808517336845398,
            "frac_alive": 0.2724066972732544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_3_step_1544": {
            "l2_loss": 64.8,
            "l1_loss": 130.85,
            "l0": 31.262500953674316,
            "frac_variance_explained": 0.38984375,
            "cossim": 0.775390625,
            "l2_ratio": 0.713671875,
            "relative_reconstruction_bias": 0.921484375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 5.239665079116821,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.7204530894756317,
            "frac_alive": 0.0592990443110466,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_0_step_4882": {
            "l2_loss": 37.275,
            "l1_loss": 442.8,
            "l0": 412.65000915527344,
            "frac_variance_explained": 0.794921875,
            "cossim": 0.93046875,
            "l2_ratio": 0.890625,
            "relative_reconstruction_bias": 0.957421875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.5505842685699465,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9890749871730804,
            "frac_alive": 0.2987196147441864,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_4_step_154": {
            "l2_loss": 103.95,
            "l1_loss": 1843.2,
            "l0": 3018.029248046875,
            "frac_variance_explained": -0.090625,
            "cossim": 0.2638671875,
            "l2_ratio": 0.3619140625,
            "relative_reconstruction_bias": 1.475,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 9.312376308441163,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.3137417733669281,
            "frac_alive": 0.9969618320465088,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_5_step_154": {
            "l2_loss": 101.0,
            "l1_loss": 1752.8,
            "l0": 2944.745947265625,
            "frac_variance_explained": -0.0921875,
            "cossim": 0.26025390625,
            "l2_ratio": 0.35078125,
            "relative_reconstruction_bias": 1.4578125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 9.352425670623779,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.30973615646362307,
            "frac_alive": 0.9954426884651184,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_4_step_0": {
            "l2_loss": 156.7,
            "l1_loss": 9132.8,
            "l0": 9200.85439453125,
            "frac_variance_explained": -1.00859375,
            "cossim": 0.01195831298828125,
            "l2_ratio": 1.1546875,
            "relative_reconstruction_bias": 116.4,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 14.571032238006591,
            "loss_zero": 12.452932643890382,
            "frac_recovered": -0.21182486265897751,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_4_step_48": {
            "l2_loss": 133.4,
            "l1_loss": 8348.8,
            "l0": 8286.41708984375,
            "frac_variance_explained": -0.734375,
            "cossim": 0.08974609375,
            "l2_ratio": 0.76796875,
            "relative_reconstruction_bias": 8.73125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 10.01290521621704,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.2438603311777115,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_5_step_1544": {
            "l2_loss": 76.4,
            "l1_loss": 89.05,
            "l0": 12.591667079925537,
            "frac_variance_explained": 0.2296875,
            "cossim": 0.690234375,
            "l2_ratio": 0.62109375,
            "relative_reconstruction_bias": 0.9078125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 7.287093782424927,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.5160394996404648,
            "frac_alive": 0.0379231758415699,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_1_step_48": {
            "l2_loss": 126.95,
            "l1_loss": 7913.6,
            "l0": 8299.075390625,
            "frac_variance_explained": -0.759375,
            "cossim": 0.096142578125,
            "l2_ratio": 0.766796875,
            "relative_reconstruction_bias": 8.090625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 9.946970176696777,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.25044662654399874,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_5_step_4882": {
            "l2_loss": 66.8,
            "l1_loss": 95.9,
            "l0": 14.125000286102296,
            "frac_variance_explained": 0.337890625,
            "cossim": 0.7375,
            "l2_ratio": 0.669140625,
            "relative_reconstruction_bias": 0.91484375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 5.975473880767822,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.6469856142997742,
            "frac_alive": 0.014377170242369175,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_4_step_15440": {
            "l2_loss": 56.475,
            "l1_loss": 152.2,
            "l0": 37.69583435058594,
            "frac_variance_explained": 0.537109375,
            "cossim": 0.840625,
            "l2_ratio": 0.782421875,
            "relative_reconstruction_bias": 0.934375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 3.5936453342437744,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.8849301040172577,
            "frac_alive": 0.0482313372194767,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_0_step_488": {
            "l2_loss": 65.225,
            "l1_loss": 397.8,
            "l0": 295.57500915527345,
            "frac_variance_explained": 0.43515625,
            "cossim": 0.769921875,
            "l2_ratio": 0.696875,
            "relative_reconstruction_bias": 0.915234375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 5.345195007324219,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.7099828541278839,
            "frac_alive": 0.7333984375,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_1_step_488": {
            "l2_loss": 73.05,
            "l1_loss": 233.5,
            "l0": 181.07917022705078,
            "frac_variance_explained": 0.26015625,
            "cossim": 0.707421875,
            "l2_ratio": 0.620703125,
            "relative_reconstruction_bias": 0.880859375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 6.592868709564209,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.5854110896587372,
            "frac_alive": 0.653917133808136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_1_step_0": {
            "l2_loss": 166.6,
            "l1_loss": 9728.0,
            "l0": 9209.291796875,
            "frac_variance_explained": -1.0359375,
            "cossim": 0.0111297607421875,
            "l2_ratio": 1.15546875,
            "relative_reconstruction_bias": 126.65,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 14.571032238006591,
            "loss_zero": 12.452932643890382,
            "frac_recovered": -0.21182486265897751,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_0_step_1544": {
            "l2_loss": 48.025,
            "l1_loss": 379.8,
            "l0": 254.94584045410156,
            "frac_variance_explained": 0.660546875,
            "cossim": 0.88671875,
            "l2_ratio": 0.83359375,
            "relative_reconstruction_bias": 0.940234375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 3.0283466815948485,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9413172245025635,
            "frac_alive": 0.1541341096162796,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_1_step_15440": {
            "l2_loss": 38.125,
            "l1_loss": 292.4,
            "l0": 180.3541732788086,
            "frac_variance_explained": 0.79296875,
            "cossim": 0.928515625,
            "l2_ratio": 0.891796875,
            "relative_reconstruction_bias": 0.96484375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.5693552017211916,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.987200129032135,
            "frac_alive": 0.3882921040058136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_3_step_4882": {
            "l2_loss": 56.275,
            "l1_loss": 177.5,
            "l0": 46.90416831970215,
            "frac_variance_explained": 0.623046875,
            "cossim": 0.8375,
            "l2_ratio": 0.78125,
            "relative_reconstruction_bias": 0.944140625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 3.767059564590454,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.8675203025341034,
            "frac_alive": 0.0457899309694767,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_3_step_0": {
            "l2_loss": 159.1,
            "l1_loss": 9286.4,
            "l0": 9211.675390625,
            "frac_variance_explained": -1.00859375,
            "cossim": 0.010518646240234375,
            "l2_ratio": 1.15546875,
            "relative_reconstruction_bias": 39.65,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 14.571032238006591,
            "loss_zero": 12.452932643890382,
            "frac_recovered": -0.21182486265897751,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_0_step_48": {
            "l2_loss": 126.3,
            "l1_loss": 7971.2,
            "l0": 8312.05859375,
            "frac_variance_explained": -0.75859375,
            "cossim": 0.10849609375,
            "l2_ratio": 0.763671875,
            "relative_reconstruction_bias": 7.278125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 9.854583644866944,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.25967336595058443,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_0_step_154": {
            "l2_loss": 96.5,
            "l1_loss": 2459.2,
            "l0": 3289.9584228515623,
            "frac_variance_explained": 0.05859375,
            "cossim": 0.4255859375,
            "l2_ratio": 0.4216796875,
            "relative_reconstruction_bias": 0.98984375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 8.404415035247803,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.4044595301151276,
            "frac_alive": 0.9961479902267456,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_1_step_154": {
            "l2_loss": 99.65,
            "l1_loss": 2208.8,
            "l0": 3060.0959228515626,
            "frac_variance_explained": 0.019921875,
            "cossim": 0.3361328125,
            "l2_ratio": 0.371875,
            "relative_reconstruction_bias": 1.13671875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 8.953547191619872,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.3495545297861099,
            "frac_alive": 0.9943576455116272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_4_step_4882": {
            "l2_loss": 65.225,
            "l1_loss": 126.75,
            "l0": 24.633334159851074,
            "frac_variance_explained": 0.41171875,
            "cossim": 0.786328125,
            "l2_ratio": 0.723046875,
            "relative_reconstruction_bias": 0.9265625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 4.907446241378784,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.7536444127559662,
            "frac_alive": 0.0179578997194767,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_2_step_48": {
            "l2_loss": 127.0,
            "l1_loss": 7939.2,
            "l0": 8307.60029296875,
            "frac_variance_explained": -0.7765625,
            "cossim": 0.097900390625,
            "l2_ratio": 0.767578125,
            "relative_reconstruction_bias": 8.23125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 9.970696353912354,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.24807583093643187,
            "frac_alive": 0.9999457597732544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_1_step_1544": {
            "l2_loss": 55.525,
            "l1_loss": 228.8,
            "l0": 92.31250228881837,
            "frac_variance_explained": 0.5546875,
            "cossim": 0.842578125,
            "l2_ratio": 0.791796875,
            "relative_reconstruction_bias": 0.941015625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 3.7567901372909547,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.8685382425785064,
            "frac_alive": 0.099989153444767,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_3_step_48": {
            "l2_loss": 125.75,
            "l1_loss": 7833.6,
            "l0": 8293.233642578125,
            "frac_variance_explained": -0.76875,
            "cossim": 0.094921875,
            "l2_ratio": 0.768359375,
            "relative_reconstruction_bias": 8.31875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 9.998102855682372,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.245339997112751,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_2_step_4882": {
            "l2_loss": 49.65,
            "l1_loss": 235.6,
            "l0": 95.78333587646485,
            "frac_variance_explained": 0.653125,
            "cossim": 0.87890625,
            "l2_ratio": 0.8265625,
            "relative_reconstruction_bias": 0.94296875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.977662134170532,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9464470505714416,
            "frac_alive": 0.1045464426279068,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_3_step_15440": {
            "l2_loss": 50.35,
            "l1_loss": 202.0,
            "l0": 67.2666690826416,
            "frac_variance_explained": 0.671875,
            "cossim": 0.875,
            "l2_ratio": 0.81640625,
            "relative_reconstruction_bias": 0.940234375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.9362952709198,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9505707383155823,
            "frac_alive": 0.1246744766831398,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_5_step_0": {
            "l2_loss": 156.6,
            "l1_loss": 9120.0,
            "l0": 9217.45029296875,
            "frac_variance_explained": -1.0078125,
            "cossim": 0.00892333984375,
            "l2_ratio": 1.15546875,
            "relative_reconstruction_bias": 153.9,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 14.571032238006591,
            "loss_zero": 12.452932643890382,
            "frac_recovered": -0.21182486265897751,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_0_step_0": {
            "l2_loss": 456.8,
            "l1_loss": 26739.2,
            "l0": 9200.98369140625,
            "frac_variance_explained": -0.99375,
            "cossim": 0.01264495849609375,
            "l2_ratio": 1.15,
            "relative_reconstruction_bias": 118.875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 21.83314037322998,
            "loss_zero": 12.452932643890382,
            "frac_recovered": -0.9372808158397674,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_0_step_15440": {
            "l2_loss": 93.15,
            "l1_loss": 1247.2,
            "l0": 439.21251525878904,
            "frac_variance_explained": 0.848828125,
            "cossim": 0.9484375,
            "l2_ratio": 0.909765625,
            "relative_reconstruction_bias": 0.963671875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.574883985519409,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9866514384746552,
            "frac_alive": 0.689561665058136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_3_step_154": {
            "l2_loss": 294.6,
            "l1_loss": 3740.8,
            "l0": 2362.9333984375,
            "frac_variance_explained": -0.0828125,
            "cossim": 0.22666015625,
            "l2_ratio": 0.3154296875,
            "relative_reconstruction_bias": 1.46328125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 13.42322359085083,
            "loss_zero": 12.452932643890382,
            "frac_recovered": -0.09688852950930596,
            "frac_alive": 0.9954969882965088,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_2_step_154": {
            "l2_loss": 297.2,
            "l1_loss": 3924.8,
            "l0": 2422.7375732421874,
            "frac_variance_explained": -0.07578125,
            "cossim": 0.25576171875,
            "l2_ratio": 0.323828125,
            "relative_reconstruction_bias": 1.32890625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 13.276070308685302,
            "loss_zero": 12.452932643890382,
            "frac_recovered": -0.08219222165644169,
            "frac_alive": 0.9962565302848816,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_2_step_1544": {
            "l2_loss": 184.3,
            "l1_loss": 441.0,
            "l0": 45.12500076293945,
            "frac_variance_explained": 0.42109375,
            "cossim": 0.778515625,
            "l2_ratio": 0.730078125,
            "relative_reconstruction_bias": 0.944140625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 4.669199419021607,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.7774573624134063,
            "frac_alive": 0.0773654505610466,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_1_step_4882": {
            "l2_loss": 138.1,
            "l1_loss": 720.8,
            "l0": 117.22916870117187,
            "frac_variance_explained": 0.654296875,
            "cossim": 0.874609375,
            "l2_ratio": 0.82578125,
            "relative_reconstruction_bias": 0.949609375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 3.0530463218688966,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9389393389225006,
            "frac_alive": 0.1564127653837204,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_3_step_488": {
            "l2_loss": 232.6,
            "l1_loss": 414.6,
            "l0": 121.14583587646484,
            "frac_variance_explained": 0.0875,
            "cossim": 0.603515625,
            "l2_ratio": 0.5189453125,
            "relative_reconstruction_bias": 0.8609375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 9.284746646881104,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.316985610127449,
            "frac_alive": 0.6366102695465088,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_2_step_488": {
            "l2_loss": 223.9,
            "l1_loss": 669.4,
            "l0": 151.6916702270508,
            "frac_variance_explained": 0.216796875,
            "cossim": 0.648828125,
            "l2_ratio": 0.569921875,
            "relative_reconstruction_bias": 0.89375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 8.074299097061157,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.43777204751968385,
            "frac_alive": 0.6750759482383728,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_2_step_0": {
            "l2_loss": 471.2,
            "l1_loss": 27635.2,
            "l0": 9202.92529296875,
            "frac_variance_explained": -1.02890625,
            "cossim": 0.013226318359375,
            "l2_ratio": 1.15,
            "relative_reconstruction_bias": 108.975,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 21.83314037322998,
            "loss_zero": 12.452932643890382,
            "frac_recovered": -0.9372808158397674,
            "frac_alive": 0.9999457597732544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_5_step_15440": {
            "l2_loss": 189.1,
            "l1_loss": 314.8,
            "l0": 18.09166736602783,
            "frac_variance_explained": 0.400390625,
            "cossim": 0.765234375,
            "l2_ratio": 0.70234375,
            "relative_reconstruction_bias": 0.92578125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 4.85347580909729,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.759119176864624,
            "frac_alive": 0.0201280377805233,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_4_step_1544": {
            "l2_loss": 207.0,
            "l1_loss": 265.2,
            "l0": 16.579166984558107,
            "frac_variance_explained": 0.265234375,
            "cossim": 0.701171875,
            "l2_ratio": 0.635546875,
            "relative_reconstruction_bias": 0.91484375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 6.506928968429565,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.5939813435077668,
            "frac_alive": 0.0509982630610466,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_4_step_488": {
            "l2_loss": 253.3,
            "l1_loss": 465.8,
            "l0": 116.95000228881835,
            "frac_variance_explained": 0.110546875,
            "cossim": 0.56640625,
            "l2_ratio": 0.4189453125,
            "relative_reconstruction_bias": 0.761328125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 9.601817798614501,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.28501268923282624,
            "frac_alive": 0.6189778447151184,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_5_step_488": {
            "l2_loss": 291.0,
            "l1_loss": 155.9,
            "l0": 107.54167022705079,
            "frac_variance_explained": 0.00546875,
            "cossim": 0.305859375,
            "l2_ratio": 0.2009765625,
            "relative_reconstruction_bias": 0.669140625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 17.138036727905273,
            "loss_zero": 12.452932643890382,
            "frac_recovered": -0.46756131052970884,
            "frac_alive": 0.6649848222732544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_5_step_48": {
            "l2_loss": 359.4,
            "l1_loss": 21632.0,
            "l0": 8069.337744140625,
            "frac_variance_explained": -0.76328125,
            "cossim": 0.09365234375,
            "l2_ratio": 0.7609375,
            "relative_reconstruction_bias": 8.084375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 11.344709587097167,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.11084590703248978,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_2_step_15440": {
            "l2_loss": 123.55,
            "l1_loss": 733.2,
            "l0": 121.07083587646484,
            "frac_variance_explained": 0.729296875,
            "cossim": 0.90234375,
            "l2_ratio": 0.8515625,
            "relative_reconstruction_bias": 0.947265625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.783217740058899,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9658669233322144,
            "frac_alive": 0.3011067807674408,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_3_step_1544": {
            "l2_loss": 196.6,
            "l1_loss": 331.8,
            "l0": 23.65000057220459,
            "frac_variance_explained": 0.341015625,
            "cossim": 0.7390625,
            "l2_ratio": 0.68203125,
            "relative_reconstruction_bias": 0.93125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 5.629452657699585,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.6815829992294311,
            "frac_alive": 0.0403103306889534,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_0_step_4882": {
            "l2_loss": 111.2,
            "l1_loss": 1262.4,
            "l0": 390.74168090820314,
            "frac_variance_explained": 0.776171875,
            "cossim": 0.918359375,
            "l2_ratio": 0.87109375,
            "relative_reconstruction_bias": 0.953125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.674443221092224,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9767174541950225,
            "frac_alive": 0.298828125,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_4_step_154": {
            "l2_loss": 306.0,
            "l1_loss": 4676.8,
            "l0": 2369.533447265625,
            "frac_variance_explained": -0.033203125,
            "cossim": 0.223046875,
            "l2_ratio": 0.310546875,
            "relative_reconstruction_bias": 1.38125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 13.474344730377197,
            "loss_zero": 12.452932643890382,
            "frac_recovered": -0.10197329260408879,
            "frac_alive": 0.9935438632965088,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_5_step_154": {
            "l2_loss": 300.0,
            "l1_loss": 4672.0,
            "l0": 2403.2584228515625,
            "frac_variance_explained": -0.040234375,
            "cossim": 0.21103515625,
            "l2_ratio": 0.3154296875,
            "relative_reconstruction_bias": 1.47265625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 13.505611896514893,
            "loss_zero": 12.452932643890382,
            "frac_recovered": -0.10507980175316334,
            "frac_alive": 0.9969618320465088,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_4_step_0": {
            "l2_loss": 455.2,
            "l1_loss": 26636.8,
            "l0": 9201.50048828125,
            "frac_variance_explained": -1.003125,
            "cossim": 0.0144805908203125,
            "l2_ratio": 1.153125,
            "relative_reconstruction_bias": 85.825,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 21.83314037322998,
            "loss_zero": 12.452932643890382,
            "frac_recovered": -0.9372808158397674,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_4_step_48": {
            "l2_loss": 355.4,
            "l1_loss": 21427.2,
            "l0": 8079.012646484375,
            "frac_variance_explained": -0.765625,
            "cossim": 0.093310546875,
            "l2_ratio": 0.76015625,
            "relative_reconstruction_bias": 8.040625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 11.328641510009765,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.11245149970054627,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_5_step_1544": {
            "l2_loss": 215.6,
            "l1_loss": 233.1,
            "l0": 13.266666984558105,
            "frac_variance_explained": 0.1921875,
            "cossim": 0.67265625,
            "l2_ratio": 0.60390625,
            "relative_reconstruction_bias": 0.905859375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 7.342954540252686,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.510615000128746,
            "frac_alive": 0.0594075508415699,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_1_step_48": {
            "l2_loss": 373.0,
            "l1_loss": 22899.2,
            "l0": 8096.754345703125,
            "frac_variance_explained": -0.721875,
            "cossim": 0.09970703125,
            "l2_ratio": 0.7578125,
            "relative_reconstruction_bias": 7.8,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 11.22905330657959,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.12240497246384621,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_5_step_4882": {
            "l2_loss": 205.4,
            "l1_loss": 269.6,
            "l0": 12.545833587646484,
            "frac_variance_explained": 0.34140625,
            "cossim": 0.711328125,
            "l2_ratio": 0.649609375,
            "relative_reconstruction_bias": 0.9296875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 6.169500207901001,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.6276720285415649,
            "frac_alive": 0.014431423507630825,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_4_step_15440": {
            "l2_loss": 166.3,
            "l1_loss": 409.6,
            "l0": 33.14166774749756,
            "frac_variance_explained": 0.5109375,
            "cossim": 0.820703125,
            "l2_ratio": 0.75703125,
            "relative_reconstruction_bias": 0.92734375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 3.8747305154800413,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.8568949043750763,
            "frac_alive": 0.0560438372194767,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_0_step_488": {
            "l2_loss": 205.7,
            "l1_loss": 823.6,
            "l0": 219.75834045410156,
            "frac_variance_explained": 0.278515625,
            "cossim": 0.7140625,
            "l2_ratio": 0.648046875,
            "relative_reconstruction_bias": 0.912890625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 5.884131956100464,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.656288456916809,
            "frac_alive": 0.687608540058136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_1_step_488": {
            "l2_loss": 214.9,
            "l1_loss": 610.8,
            "l0": 154.8208381652832,
            "frac_variance_explained": 0.208203125,
            "cossim": 0.66796875,
            "l2_ratio": 0.594140625,
            "relative_reconstruction_bias": 0.897265625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 7.198544979095459,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.5251240968704224,
            "frac_alive": 0.6703016757965088,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_1_step_0": {
            "l2_loss": 459.4,
            "l1_loss": 26841.6,
            "l0": 9198.6794921875,
            "frac_variance_explained": -1.00390625,
            "cossim": 0.0110626220703125,
            "l2_ratio": 1.1546875,
            "relative_reconstruction_bias": 106.475,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 21.83314037322998,
            "loss_zero": 12.452932643890382,
            "frac_recovered": -0.9372808158397674,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_0_step_1544": {
            "l2_loss": 150.0,
            "l1_loss": 912.8,
            "l0": 193.70833587646484,
            "frac_variance_explained": 0.600390625,
            "cossim": 0.85625,
            "l2_ratio": 0.8078125,
            "relative_reconstruction_bias": 0.948046875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 3.452366757392883,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.8989889085292816,
            "frac_alive": 0.157497838139534,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_1_step_15440": {
            "l2_loss": 114.05,
            "l1_loss": 835.6,
            "l0": 168.62083740234374,
            "frac_variance_explained": 0.773828125,
            "cossim": 0.91796875,
            "l2_ratio": 0.870703125,
            "relative_reconstruction_bias": 0.9515625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.6944114208221435,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9747312247753144,
            "frac_alive": 0.4045138955116272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_3_step_4882": {
            "l2_loss": 172.8,
            "l1_loss": 424.2,
            "l0": 37.96250114440918,
            "frac_variance_explained": 0.470703125,
            "cossim": 0.80234375,
            "l2_ratio": 0.744140625,
            "relative_reconstruction_bias": 0.93515625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 4.1068400859832765,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.8336953580379486,
            "frac_alive": 0.0579969622194767,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_3_step_0": {
            "l2_loss": 492.0,
            "l1_loss": 28902.4,
            "l0": 9206.10029296875,
            "frac_variance_explained": -1.05859375,
            "cossim": 0.0141143798828125,
            "l2_ratio": 1.15234375,
            "relative_reconstruction_bias": 135.975,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 21.83314037322998,
            "loss_zero": 12.452932643890382,
            "frac_recovered": -0.9372808158397674,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_0_step_48": {
            "l2_loss": 360.6,
            "l1_loss": 22272.0,
            "l0": 8138.291748046875,
            "frac_variance_explained": -0.7515625,
            "cossim": 0.11416015625,
            "l2_ratio": 0.75859375,
            "relative_reconstruction_bias": 6.46875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 11.07071237564087,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.13822999522089957,
            "frac_alive": 0.9999457597732544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_0_step_154": {
            "l2_loss": 282.8,
            "l1_loss": 5516.8,
            "l0": 2661.129248046875,
            "frac_variance_explained": 0.019921875,
            "cossim": 0.4046875,
            "l2_ratio": 0.3876953125,
            "relative_reconstruction_bias": 0.926171875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 10.32450180053711,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.21272739246487618,
            "frac_alive": 0.9959309697151184,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_1_step_154": {
            "l2_loss": 291.0,
            "l1_loss": 3848.0,
            "l0": 2397.4667724609376,
            "frac_variance_explained": -0.06171875,
            "cossim": 0.2849609375,
            "l2_ratio": 0.324609375,
            "relative_reconstruction_bias": 1.17890625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 13.03815517425537,
            "loss_zero": 12.452932643890382,
            "frac_recovered": -0.05841167252510786,
            "frac_alive": 0.9943034052848816,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_4_step_4882": {
            "l2_loss": 190.2,
            "l1_loss": 321.6,
            "l0": 19.60833396911621,
            "frac_variance_explained": 0.374609375,
            "cossim": 0.761328125,
            "l2_ratio": 0.702734375,
            "relative_reconstruction_bias": 0.93046875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 5.200517892837524,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.7243833899497986,
            "frac_alive": 0.0176866315305233,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_2_step_48": {
            "l2_loss": 354.4,
            "l1_loss": 21363.2,
            "l0": 8065.021044921875,
            "frac_variance_explained": -0.75078125,
            "cossim": 0.100146484375,
            "l2_ratio": 0.76015625,
            "relative_reconstruction_bias": 7.503125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 11.266265773773194,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.11868658438324928,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_1_step_1544": {
            "l2_loss": 175.5,
            "l1_loss": 518.2,
            "l0": 64.67916831970214,
            "frac_variance_explained": 0.458203125,
            "cossim": 0.79609375,
            "l2_ratio": 0.7453125,
            "relative_reconstruction_bias": 0.941796875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 4.30438346862793,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.8138806521892548,
            "frac_alive": 0.1017252579331398,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_3_step_48": {
            "l2_loss": 361.8,
            "l1_loss": 21772.8,
            "l0": 8057.366748046875,
            "frac_variance_explained": -0.76953125,
            "cossim": 0.096533203125,
            "l2_ratio": 0.75703125,
            "relative_reconstruction_bias": 7.746875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 11.305345058441162,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.11478075385093689,
            "frac_alive": 0.9998915195465088,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_2_step_4882": {
            "l2_loss": 149.1,
            "l1_loss": 603.6,
            "l0": 74.62916946411133,
            "frac_variance_explained": 0.609375,
            "cossim": 0.85546875,
            "l2_ratio": 0.80078125,
            "relative_reconstruction_bias": 0.941796875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 3.3274339199066163,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9115424156188965,
            "frac_alive": 0.104871965944767,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_3_step_15440": {
            "l2_loss": 143.5,
            "l1_loss": 539.4,
            "l0": 59.45833473205566,
            "frac_variance_explained": 0.636328125,
            "cossim": 0.86328125,
            "l2_ratio": 0.80703125,
            "relative_reconstruction_bias": 0.93984375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 3.1445400953292846,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9298228561878205,
            "frac_alive": 0.1376410573720932,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_5_step_0": {
            "l2_loss": 462.8,
            "l1_loss": 27148.8,
            "l0": 9207.91279296875,
            "frac_variance_explained": -1.00546875,
            "cossim": 0.0137664794921875,
            "l2_ratio": 1.1484375,
            "relative_reconstruction_bias": 96.0,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 21.83314037322998,
            "loss_zero": 12.452932643890382,
            "frac_recovered": -0.9372808158397674,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        }
    }
}