{
    "sae_config_dictionary_learning": {
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19/trainer_4": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19/trainer_3": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19/trainer_2": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19/trainer_5": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19/trainer_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19/trainer_1": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11/trainer_4": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11/trainer_3": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11/trainer_2": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11/trainer_5": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11/trainer_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11/trainer_1": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7/trainer_4": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7/trainer_3": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7/trainer_2": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7/trainer_5": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7/trainer_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7/trainer_1": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_0_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_3_step_29292": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "29292"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_1_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_1_step_9764": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "9764"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_3_step_19528": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "19528"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_2_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_1_step_29292": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "29292"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_4_step_19528": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "19528"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_4_step_29292": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "29292"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_0_step_9764": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "9764"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_1_step_19528": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "19528"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_0_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_4_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_5_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_5_step_9764": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "9764"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_2_step_19528": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "19528"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_1_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_3_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_3_step_9764": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "9764"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_3_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_2_step_29292": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "29292"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_4_step_9764": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "9764"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_5_step_29292": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "29292"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_4_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_0_step_19528": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "19528"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_2_step_9764": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "9764"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_2_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_0_step_29292": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "29292"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_5_step_19528": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "19528"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_5_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_0_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_3_step_29292": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "29292"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_1_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_1_step_9764": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "9764"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_3_step_19528": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "19528"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_2_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_1_step_29292": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "29292"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_4_step_19528": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "19528"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_4_step_29292": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "29292"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_0_step_9764": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "9764"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_1_step_19528": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "19528"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_0_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_4_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_5_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_5_step_9764": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "9764"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_2_step_19528": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "19528"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_1_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_3_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_3_step_9764": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "9764"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_3_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_2_step_29292": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "29292"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_4_step_9764": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "9764"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_5_step_29292": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "29292"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_4_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_0_step_19528": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "19528"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_2_step_9764": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "9764"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_2_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_0_step_29292": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "29292"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_5_step_19528": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "19528"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_5_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15/trainer_4": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15/trainer_3": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15/trainer_2": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15/trainer_5": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15/trainer_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15/trainer_1": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3/trainer_4": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3/trainer_3": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3/trainer_2": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3/trainer_5": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3/trainer_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3/trainer_1": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_0_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_3_step_29292": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "29292"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_1_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_1_step_9764": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "9764"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_3_step_19528": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "19528"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_2_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_1_step_29292": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "29292"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_4_step_19528": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "19528"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_4_step_29292": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "29292"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_0_step_9764": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "9764"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_1_step_19528": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "19528"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_0_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_4_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_5_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_5_step_9764": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "9764"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_2_step_19528": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "19528"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_1_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_3_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_3_step_9764": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "9764"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_3_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_2_step_29292": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "29292"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_4_step_9764": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "9764"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_5_step_29292": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "29292"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_4_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_0_step_19528": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "19528"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_2_step_9764": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "9764"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_2_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_0_step_29292": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "29292"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_5_step_19528": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "19528"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_5_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_0_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_3_step_29292": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "29292"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_1_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_1_step_9764": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "9764"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_3_step_19528": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "19528"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_2_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_1_step_29292": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "29292"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_4_step_19528": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "19528"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_4_step_29292": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "29292"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_0_step_9764": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "9764"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_1_step_19528": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "19528"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_0_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_4_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_5_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_5_step_9764": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "9764"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_2_step_19528": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "19528"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_1_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_3_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_3_step_9764": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "9764"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_3_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_2_step_29292": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "29292"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_4_step_9764": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "9764"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_5_step_29292": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "29292"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_4_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_0_step_19528": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "19528"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_2_step_9764": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "9764"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_2_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_0_step_29292": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "29292"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_5_step_19528": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "19528"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_5_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_0_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_3_step_29292": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "29292"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_1_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_1_step_9764": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "9764"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_3_step_19528": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "19528"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_2_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_1_step_29292": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "29292"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_4_step_19528": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "19528"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_4_step_29292": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "29292"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_0_step_9764": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "9764"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_1_step_19528": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "19528"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_0_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_4_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_5_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_5_step_9764": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "9764"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_2_step_19528": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "19528"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_1_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.035,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_3_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_3_step_9764": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "9764"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_3_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.05,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_2_step_29292": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "29292"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_4_step_9764": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "9764"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_5_step_29292": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "29292"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_4_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.06,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_0_step_19528": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "19528"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_2_step_9764": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "9764"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_2_step_4882": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.04,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "4882"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_0_step_29292": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.025,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "29292"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_5_step_19528": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "19528"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_5_step_0": {
            "trainer": {
                "dict_class": "AutoEncoder",
                "trainer_class": "StandardTrainer",
                "activation_dim": 2304,
                "dict_size": 4608,
                "lr": 0.0003,
                "l1_penalty": 0.07,
                "warmup_steps": 1000,
                "resample_steps": null,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "StandardTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19",
                "steps": "0"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        }
    },
    "basic_eval_results": {
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19/trainer_4": {
            "l2_loss": 172.2027587890625,
            "l1_loss": 378.89093017578125,
            "l0": 26.375,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.4999767541885376,
            "cossim": 0.8046790957450867,
            "l2_ratio": 0.7567692995071411,
            "relative_reconstruction_bias": 0.9440925717353821,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 4.2550530433654785,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.8181435465812683,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19/trainer_3": {
            "l2_loss": 137.07015991210938,
            "l1_loss": 492.3275146484375,
            "l0": 47.625,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.6509363651275635,
            "cossim": 0.8788695335388184,
            "l2_ratio": 0.8358728289604187,
            "relative_reconstruction_bias": 0.9559028148651123,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 3.4993462562561035,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.8935626745223999,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19/trainer_2": {
            "l2_loss": 138.222412109375,
            "l1_loss": 699.607177734375,
            "l0": 101.20833587646484,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.6692577600479126,
            "cossim": 0.8803514242172241,
            "l2_ratio": 0.8353444337844849,
            "relative_reconstruction_bias": 0.9566325545310974,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 2.9808387756347656,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.9453093409538269,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19/trainer_5": {
            "l2_loss": 183.8949432373047,
            "l1_loss": 414.8774108886719,
            "l0": 16.45833396911621,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.9011355042457581,
            "cossim": 0.7961454391479492,
            "l2_ratio": 0.735839307308197,
            "relative_reconstruction_bias": 0.9862031936645508,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 5.163734436035156,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.7274577021598816,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19/trainer_0": {
            "l2_loss": 112.91493225097656,
            "l1_loss": 1199.4901123046875,
            "l0": 342.79168701171875,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.780493974685669,
            "cossim": 0.9188852310180664,
            "l2_ratio": 0.8741456270217896,
            "relative_reconstruction_bias": 0.9599893093109131,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 2.641941785812378,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.9791310429573059,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19/trainer_1": {
            "l2_loss": 124.78413391113281,
            "l1_loss": 737.858154296875,
            "l0": 125.95833587646484,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.7003772854804993,
            "cossim": 0.8921140432357788,
            "l2_ratio": 0.8452373743057251,
            "relative_reconstruction_bias": 0.9525349140167236,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 2.82914137840271,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.9604486227035522,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11/trainer_4": {
            "l2_loss": 74.44535827636719,
            "l1_loss": 236.12059020996094,
            "l0": 24.83333396911621,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.9570982456207275,
            "cossim": 0.8187623023986816,
            "l2_ratio": 0.7615946531295776,
            "relative_reconstruction_bias": 0.9943456649780273,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 4.803515434265137,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.763407289981842,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11/trainer_3": {
            "l2_loss": 78.22975158691406,
            "l1_loss": 218.60513305664062,
            "l0": 50.833335876464844,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.5495132207870483,
            "cossim": 0.8355358839035034,
            "l2_ratio": 0.7730690836906433,
            "relative_reconstruction_bias": 0.9281772375106812,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 3.467956066131592,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.8966952562332153,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11/trainer_2": {
            "l2_loss": 61.01639938354492,
            "l1_loss": 368.2674560546875,
            "l0": 97.91667175292969,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.9684154987335205,
            "cossim": 0.9024285078048706,
            "l2_ratio": 0.8613905310630798,
            "relative_reconstruction_bias": 0.9948885440826416,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 2.804324150085449,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.962925374507904,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11/trainer_5": {
            "l2_loss": 91.40856170654297,
            "l1_loss": 147.08984375,
            "l0": 17.45833396911621,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.39455533027648926,
            "cossim": 0.783570408821106,
            "l2_ratio": 0.7340455055236816,
            "relative_reconstruction_bias": 0.9417886734008789,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 5.698957920074463,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.6740427017211914,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11/trainer_0": {
            "l2_loss": 51.09783172607422,
            "l1_loss": 696.4310302734375,
            "l0": 427.0833435058594,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.9793744087219238,
            "cossim": 0.9331231117248535,
            "l2_ratio": 0.8912414312362671,
            "relative_reconstruction_bias": 0.9950931072235107,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 2.5339653491973877,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.9899070262908936,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11/trainer_1": {
            "l2_loss": 61.166587829589844,
            "l1_loss": 347.56976318359375,
            "l0": 153.0,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.6767814755439758,
            "cossim": 0.8976640105247498,
            "l2_ratio": 0.8425207138061523,
            "relative_reconstruction_bias": 0.9373458623886108,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 2.690847396850586,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.974250316619873,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7/trainer_4": {
            "l2_loss": 56.788917541503906,
            "l1_loss": 128.7012176513672,
            "l0": 26.45833396911621,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.5274004936218262,
            "cossim": 0.8188132047653198,
            "l2_ratio": 0.7696134448051453,
            "relative_reconstruction_bias": 0.9434435367584229,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 4.155254364013672,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.8281033635139465,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7/trainer_3": {
            "l2_loss": 48.603675842285156,
            "l1_loss": 161.50294494628906,
            "l0": 51.458335876464844,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.627206563949585,
            "cossim": 0.8698184490203857,
            "l2_ratio": 0.8159449100494385,
            "relative_reconstruction_bias": 0.9397726655006409,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 3.2568042278289795,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.917768120765686,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7/trainer_2": {
            "l2_loss": 44.51411056518555,
            "l1_loss": 238.32273864746094,
            "l0": 103.20833587646484,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.7222574949264526,
            "cossim": 0.903212308883667,
            "l2_ratio": 0.8568978309631348,
            "relative_reconstruction_bias": 0.9483732581138611,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 2.789001703262329,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.9644545912742615,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7/trainer_5": {
            "l2_loss": 59.417564392089844,
            "l1_loss": 141.91970825195312,
            "l0": 15.25,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.9396851658821106,
            "cossim": 0.7904552221298218,
            "l2_ratio": 0.7311250567436218,
            "relative_reconstruction_bias": 0.9937106370925903,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 5.454887866973877,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.6984007358551025,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7/trainer_0": {
            "l2_loss": 38.15830993652344,
            "l1_loss": 473.236083984375,
            "l0": 342.5833435058594,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.9756736159324646,
            "cossim": 0.935890793800354,
            "l2_ratio": 0.8935689926147461,
            "relative_reconstruction_bias": 0.9935206770896912,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 2.52405047416687,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.9908965229988098,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7/trainer_1": {
            "l2_loss": 40.16155242919922,
            "l1_loss": 249.21615600585938,
            "l0": 136.375,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.7419581413269043,
            "cossim": 0.9066556692123413,
            "l2_ratio": 0.863865315914154,
            "relative_reconstruction_bias": 0.9576562643051147,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 2.653069019317627,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.9780206084251404,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_0_step_0": {
            "l2_loss": 167.1028854370117,
            "l1_loss": 3259.6132568359376,
            "l0": 2315.0375732421876,
            "frac_variance_explained": -0.26188645362854,
            "cossim": 0.004149633987981361,
            "l2_ratio": 0.5866222858428956,
            "relative_reconstruction_bias": -41.212248992919925,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 17.234307861328126,
            "loss_zero": 12.452933025360107,
            "frac_recovered": -0.47787620425224303,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_3_step_29292": {
            "l2_loss": 76.18771362304688,
            "l1_loss": 255.9460250854492,
            "l0": 52.45833511352539,
            "frac_variance_explained": 0.6778663635253906,
            "cossim": 0.8498216152191163,
            "l2_ratio": 0.7965605080127716,
            "relative_reconstruction_bias": 0.9575334250926971,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 3.4450852394104006,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9004538714885711,
            "frac_alive": 0.2339409738779068,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_1_step_4882": {
            "l2_loss": 73.07725524902344,
            "l1_loss": 347.9136077880859,
            "l0": 103.04583511352538,
            "frac_variance_explained": 0.7512376010417938,
            "cossim": 0.8572899758815765,
            "l2_ratio": 0.8055591583251953,
            "relative_reconstruction_bias": 0.966018682718277,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 3.2463842153549196,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9202560782432556,
            "frac_alive": 0.2736545205116272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_1_step_9764": {
            "l2_loss": 66.39950981140137,
            "l1_loss": 364.6046905517578,
            "l0": 141.72083892822266,
            "frac_variance_explained": 0.6755688190460205,
            "cossim": 0.8846192836761475,
            "l2_ratio": 0.8318478167057037,
            "relative_reconstruction_bias": 0.9467559456825256,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.855544424057007,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9593764483928681,
            "frac_alive": 0.5112847089767456,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_3_step_19528": {
            "l2_loss": 77.14197463989258,
            "l1_loss": 235.12530212402345,
            "l0": 53.12083435058594,
            "frac_variance_explained": 0.5905035436153412,
            "cossim": 0.8462147235870361,
            "l2_ratio": 0.7892249882221222,
            "relative_reconstruction_bias": 0.9432871699333191,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 3.4568325519561767,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.8992862164974212,
            "frac_alive": 0.2272135466337204,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_2_step_0": {
            "l2_loss": 181.15716705322265,
            "l1_loss": 3541.5387939453126,
            "l0": 2315.5917236328123,
            "frac_variance_explained": -0.26421393156051637,
            "cossim": 0.0038624161388725042,
            "l2_ratio": 0.5871053040027618,
            "relative_reconstruction_bias": 253.51730365753173,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 17.234307861328126,
            "loss_zero": 12.452933025360107,
            "frac_recovered": -0.47787620425224303,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_1_step_29292": {
            "l2_loss": 62.6892448425293,
            "l1_loss": 391.03612365722654,
            "l0": 158.2791717529297,
            "frac_variance_explained": 0.7394937157630921,
            "cossim": 0.901382839679718,
            "l2_ratio": 0.8549536645412446,
            "relative_reconstruction_bias": 0.9570579826831818,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.71214439868927,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9737131774425507,
            "frac_alive": 0.7230902910232544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_4_step_19528": {
            "l2_loss": 80.97531509399414,
            "l1_loss": 203.99747619628906,
            "l0": 28.870833969116212,
            "frac_variance_explained": 0.6225350856781006,
            "cossim": 0.8195537269115448,
            "l2_ratio": 0.7644230604171753,
            "relative_reconstruction_bias": 0.9532136499881745,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 4.49549036026001,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.7954253554344177,
            "frac_alive": 0.0952690988779068,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_4_step_29292": {
            "l2_loss": 82.565869140625,
            "l1_loss": 204.0656707763672,
            "l0": 28.929167366027833,
            "frac_variance_explained": 0.6831600666046143,
            "cossim": 0.8141621708869934,
            "l2_ratio": 0.7572230458259582,
            "relative_reconstruction_bias": 0.9622293531894683,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 4.500353240966797,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.7949270486831665,
            "frac_alive": 0.0959201380610466,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_0_step_9764": {
            "l2_loss": 53.42113838195801,
            "l1_loss": 660.417529296875,
            "l0": 428.55418090820314,
            "frac_variance_explained": 0.8469472169876099,
            "cossim": 0.9262736797332763,
            "l2_ratio": 0.8801985681056976,
            "relative_reconstruction_bias": 0.966783630847931,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.58748140335083,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9861565232276917,
            "frac_alive": 0.9040798544883728,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_1_step_19528": {
            "l2_loss": 62.69771194458008,
            "l1_loss": 424.6473724365234,
            "l0": 157.85000457763672,
            "frac_variance_explained": 0.8613891124725341,
            "cossim": 0.9007849872112275,
            "l2_ratio": 0.8550859570503235,
            "relative_reconstruction_bias": 0.9797493934631347,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.720248818397522,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9728983402252197,
            "frac_alive": 0.7018229365348816,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_0_step_4882": {
            "l2_loss": 60.687442016601565,
            "l1_loss": 625.6324584960937,
            "l0": 339.5833465576172,
            "frac_variance_explained": 0.8289074659347534,
            "cossim": 0.9064209163188934,
            "l2_ratio": 0.8561354637145996,
            "relative_reconstruction_bias": 0.9688756346702576,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.676463174819946,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9772705137729645,
            "frac_alive": 0.5711805820465088,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_4_step_0": {
            "l2_loss": 177.50206756591797,
            "l1_loss": 3467.0141845703124,
            "l0": 2316.5375732421876,
            "frac_variance_explained": -0.2660099983215332,
            "cossim": 0.00037744739092886447,
            "l2_ratio": 0.5889869451522827,
            "relative_reconstruction_bias": -87.3330467224121,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 17.234307861328126,
            "loss_zero": 12.452933025360107,
            "frac_recovered": -0.47787620425224303,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_5_step_4882": {
            "l2_loss": 95.3068458557129,
            "l1_loss": 137.96974334716796,
            "l0": 12.187500190734863,
            "frac_variance_explained": 0.35865994691848757,
            "cossim": 0.7354879975318909,
            "l2_ratio": 0.6701618194580078,
            "relative_reconstruction_bias": 0.9283835768699646,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 6.6612160205841064,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.5789398133754731,
            "frac_alive": 0.0186631940305233,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_5_step_9764": {
            "l2_loss": 91.78717575073242,
            "l1_loss": 193.42849578857422,
            "l0": 13.883333778381347,
            "frac_variance_explained": 0.7547805488109589,
            "cossim": 0.7555270314216613,
            "l2_ratio": 0.6917408168315887,
            "relative_reconstruction_bias": 0.9740480184555054,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 6.205630826950073,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.6244904577732087,
            "frac_alive": 0.02604166604578495,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_2_step_19528": {
            "l2_loss": 66.58076782226563,
            "l1_loss": 328.31048889160155,
            "l0": 106.94583511352539,
            "frac_variance_explained": 0.7433943271636962,
            "cossim": 0.8820024907588959,
            "l2_ratio": 0.8306972801685333,
            "relative_reconstruction_bias": 0.9615555524826049,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.8518619537353516,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9597464501857758,
            "frac_alive": 0.520616352558136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_1_step_0": {
            "l2_loss": 175.92864990234375,
            "l1_loss": 3441.5954345703126,
            "l0": 2317.941748046875,
            "frac_variance_explained": -0.26664564609527586,
            "cossim": 0.003556889179162681,
            "l2_ratio": 0.5888823807239533,
            "relative_reconstruction_bias": -136.97222518920898,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 17.234307861328126,
            "loss_zero": 12.452933025360107,
            "frac_recovered": -0.47787620425224303,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_3_step_4882": {
            "l2_loss": 84.26045532226563,
            "l1_loss": 249.6063430786133,
            "l0": 33.29166870117187,
            "frac_variance_explained": 0.7691865682601928,
            "cossim": 0.8126502275466919,
            "l2_ratio": 0.7616233944892883,
            "relative_reconstruction_bias": 0.974912142753601,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 4.663404083251953,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.7786067068576813,
            "frac_alive": 0.0811631977558136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_3_step_9764": {
            "l2_loss": 78.5355323791504,
            "l1_loss": 235.28256378173828,
            "l0": 42.74583473205566,
            "frac_variance_explained": 0.6486250162124634,
            "cossim": 0.8315837979316711,
            "l2_ratio": 0.7795684158802032,
            "relative_reconstruction_bias": 0.957790631055832,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 4.117746615409851,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.833147120475769,
            "frac_alive": 0.1419270783662796,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_3_step_0": {
            "l2_loss": 183.43079528808593,
            "l1_loss": 3597.597607421875,
            "l0": 2317.0917236328123,
            "frac_variance_explained": -0.2702042102813721,
            "cossim": 0.002261517510669364,
            "l2_ratio": 0.5886249899864197,
            "relative_reconstruction_bias": 137.84570941925048,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 17.234307861328126,
            "loss_zero": 12.452933025360107,
            "frac_recovered": -0.47787620425224303,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_2_step_29292": {
            "l2_loss": 65.96138725280761,
            "l1_loss": 322.90857849121096,
            "l0": 105.56250228881837,
            "frac_variance_explained": 0.737971442937851,
            "cossim": 0.8827623844146728,
            "l2_ratio": 0.8367438435554504,
            "relative_reconstruction_bias": 0.962006437778473,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.844821882247925,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9604501485824585,
            "frac_alive": 0.5375434160232544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_4_step_9764": {
            "l2_loss": 88.62311248779297,
            "l1_loss": 178.995849609375,
            "l0": 23.012500953674316,
            "frac_variance_explained": 0.5413392722606659,
            "cossim": 0.7825228929519653,
            "l2_ratio": 0.7205288052558899,
            "relative_reconstruction_bias": 0.9440314710140228,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 5.081115484237671,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.7368615865707397,
            "frac_alive": 0.0564236119389534,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_5_step_29292": {
            "l2_loss": 90.18620681762695,
            "l1_loss": 155.02587890625,
            "l0": 16.454167366027832,
            "frac_variance_explained": 0.5195838034152984,
            "cossim": 0.7715076208114624,
            "l2_ratio": 0.7105317950248718,
            "relative_reconstruction_bias": 0.9432308793067932,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 5.447306346893311,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.7003275513648987,
            "frac_alive": 0.0340711809694767,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_4_step_4882": {
            "l2_loss": 91.68890991210938,
            "l1_loss": 156.91791076660155,
            "l0": 19.77083377838135,
            "frac_variance_explained": 0.38370746970176695,
            "cossim": 0.7646835744380951,
            "l2_ratio": 0.7062984049320221,
            "relative_reconstruction_bias": 0.934094226360321,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 5.699097537994385,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.6751221716403961,
            "frac_alive": 0.0347222238779068,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_0_step_19528": {
            "l2_loss": 52.390929794311525,
            "l1_loss": 664.6068298339844,
            "l0": 430.4250122070313,
            "frac_variance_explained": 0.8581684529781342,
            "cossim": 0.929267168045044,
            "l2_ratio": 0.8806805431842804,
            "relative_reconstruction_bias": 0.9670958697795868,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.5743808269500734,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9874637722969055,
            "frac_alive": 0.9769965410232544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_2_step_9764": {
            "l2_loss": 68.89453926086426,
            "l1_loss": 319.3510986328125,
            "l0": 88.00000228881837,
            "frac_variance_explained": 0.7581918418407441,
            "cossim": 0.8709462106227874,
            "l2_ratio": 0.8219931125640869,
            "relative_reconstruction_bias": 0.9659412860870361,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 3.0802129745483398,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9369422435760498,
            "frac_alive": 0.3461371660232544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_2_step_4882": {
            "l2_loss": 76.43938751220703,
            "l1_loss": 271.9685623168945,
            "l0": 66.20416870117188,
            "frac_variance_explained": 0.6253657639026642,
            "cossim": 0.8402850031852722,
            "l2_ratio": 0.7904062867164612,
            "relative_reconstruction_bias": 0.9573860943317414,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 3.730401539802551,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.8718636512756348,
            "frac_alive": 0.1896701455116272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_0_step_29292": {
            "l2_loss": 52.17484703063965,
            "l1_loss": 653.6545166015625,
            "l0": 428.90000915527344,
            "frac_variance_explained": 0.842798912525177,
            "cossim": 0.9301473379135132,
            "l2_ratio": 0.8885334372520447,
            "relative_reconstruction_bias": 0.9680565476417542,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.5747411012649537,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9874280393123627,
            "frac_alive": 0.9793837070465088,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_5_step_19528": {
            "l2_loss": 90.77151031494141,
            "l1_loss": 151.9171127319336,
            "l0": 17.17083396911621,
            "frac_variance_explained": 0.4744776964187622,
            "cossim": 0.7733555793762207,
            "l2_ratio": 0.7134072065353394,
            "relative_reconstruction_bias": 0.9385466396808624,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 5.523503303527832,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.6926957190036773,
            "frac_alive": 0.0329861119389534,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_11_checkpoints/trainer_5_step_0": {
            "l2_loss": 194.8869140625,
            "l1_loss": 3829.1082763671875,
            "l0": 2315.2208984375,
            "frac_variance_explained": -0.27573217153549195,
            "cossim": 0.004133332593482919,
            "l2_ratio": 0.5873487651348114,
            "relative_reconstruction_bias": 31.508137702941895,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 17.234307861328126,
            "loss_zero": 12.452933025360107,
            "frac_recovered": -0.47787620425224303,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_0_step_0": {
            "l2_loss": 96.96646881103516,
            "l1_loss": 1890.6870483398438,
            "l0": 2323.9042724609376,
            "frac_variance_explained": -0.2535995841026306,
            "cossim": 0.008978705317713321,
            "l2_ratio": 0.5830205321311951,
            "relative_reconstruction_bias": 397.01532859802245,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 12.80709753036499,
            "loss_zero": 12.452933025360107,
            "frac_recovered": -0.03542877063155174,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_3_step_29292": {
            "l2_loss": 39.86751251220703,
            "l1_loss": 124.51265716552734,
            "l0": 43.20000114440918,
            "frac_variance_explained": 0.6627713203430176,
            "cossim": 0.8601418316364289,
            "l2_ratio": 0.8098874092102051,
            "relative_reconstruction_bias": 0.9512298345565796,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 3.071376371383667,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9378356456756591,
            "frac_alive": 0.4084201455116272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_1_step_4882": {
            "l2_loss": 37.27631950378418,
            "l1_loss": 193.84073638916016,
            "l0": 103.69583663940429,
            "frac_variance_explained": 0.7270532846450806,
            "cossim": 0.882554006576538,
            "l2_ratio": 0.8370764434337616,
            "relative_reconstruction_bias": 0.9585930049419403,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.9088775634765627,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9540540874004364,
            "frac_alive": 0.5286458134651184,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_1_step_9764": {
            "l2_loss": 33.186956787109374,
            "l1_loss": 192.84514923095702,
            "l0": 112.25833435058594,
            "frac_variance_explained": 0.7693347811698914,
            "cossim": 0.9099490761756897,
            "l2_ratio": 0.8721567213535308,
            "relative_reconstruction_bias": 0.9631216704845429,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.748357081413269,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.970092648267746,
            "frac_alive": 0.7903645634651184,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_3_step_19528": {
            "l2_loss": 39.417463302612305,
            "l1_loss": 125.42989654541016,
            "l0": 44.83333511352539,
            "frac_variance_explained": 0.6184942305088044,
            "cossim": 0.8682468354701995,
            "l2_ratio": 0.8233285427093506,
            "relative_reconstruction_bias": 0.9460755288600922,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 3.0616552114486693,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9388050854206085,
            "frac_alive": 0.40625,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_2_step_0": {
            "l2_loss": 93.50741424560547,
            "l1_loss": 1820.068505859375,
            "l0": 2329.5958984375,
            "frac_variance_explained": -0.2526684045791626,
            "cossim": 0.0068833273988275325,
            "l2_ratio": 0.5836836040019989,
            "relative_reconstruction_bias": 37.93134307861328,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 12.80709753036499,
            "loss_zero": 12.452933025360107,
            "frac_recovered": -0.03542877063155174,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_1_step_29292": {
            "l2_loss": 36.031103897094724,
            "l1_loss": 191.65158233642578,
            "l0": 106.24583435058594,
            "frac_variance_explained": 0.7553999841213226,
            "cossim": 0.8938485026359558,
            "l2_ratio": 0.8535469114780426,
            "relative_reconstruction_bias": 0.9638433694839478,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.7300129890441895,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9719305992126465,
            "frac_alive": 0.8645833134651184,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_4_step_19528": {
            "l2_loss": 44.61357383728027,
            "l1_loss": 115.03380889892578,
            "l0": 27.237500381469726,
            "frac_variance_explained": 0.6734775364398956,
            "cossim": 0.8286475241184235,
            "l2_ratio": 0.7734521687030792,
            "relative_reconstruction_bias": 0.9532543838024139,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 3.6791075229644776,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.8770896613597869,
            "frac_alive": 0.1955295205116272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_4_step_29292": {
            "l2_loss": 47.30447692871094,
            "l1_loss": 104.45862655639648,
            "l0": 27.150000762939452,
            "frac_variance_explained": 0.5056313574314117,
            "cossim": 0.8219953894615173,
            "l2_ratio": 0.7687196016311646,
            "relative_reconstruction_bias": 0.9347477614879608,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 3.68615038394928,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.8763883292675019,
            "frac_alive": 0.1974826455116272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_0_step_9764": {
            "l2_loss": 30.942561149597168,
            "l1_loss": 300.46973571777346,
            "l0": 281.1291763305664,
            "frac_variance_explained": 0.786206203699112,
            "cossim": 0.9229247152805329,
            "l2_ratio": 0.881724762916565,
            "relative_reconstruction_bias": 0.9558957874774933,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.6176010608673095,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9831490397453309,
            "frac_alive": 0.9904513955116272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_1_step_19528": {
            "l2_loss": 32.552747917175296,
            "l1_loss": 187.24918670654296,
            "l0": 106.17500305175781,
            "frac_variance_explained": 0.7666861474514007,
            "cossim": 0.9101104855537414,
            "l2_ratio": 0.8703899025917053,
            "relative_reconstruction_bias": 0.9624879658222198,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.728234648704529,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9721090435981751,
            "frac_alive": 0.8541666865348816,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_0_step_4882": {
            "l2_loss": 31.805814743041992,
            "l1_loss": 305.6560302734375,
            "l0": 285.62501220703126,
            "frac_variance_explained": 0.7714446663856507,
            "cossim": 0.9192848563194275,
            "l2_ratio": 0.8782061815261841,
            "relative_reconstruction_bias": 0.9566191375255585,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.668708896636963,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9780443429946899,
            "frac_alive": 0.8352864384651184,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_4_step_0": {
            "l2_loss": 103.02190170288085,
            "l1_loss": 2014.8979370117188,
            "l0": 2327.68759765625,
            "frac_variance_explained": -0.25953688621521,
            "cossim": 0.006688350019976497,
            "l2_ratio": 0.5839165568351745,
            "relative_reconstruction_bias": 84.69213409423828,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 12.80709753036499,
            "loss_zero": 12.452933025360107,
            "frac_recovered": -0.03542877063155174,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_5_step_4882": {
            "l2_loss": 56.08508834838867,
            "l1_loss": 77.34494705200196,
            "l0": 11.391666984558105,
            "frac_variance_explained": 0.3604785978794098,
            "cossim": 0.7287530541419983,
            "l2_ratio": 0.66373011469841,
            "relative_reconstruction_bias": 0.9186806499958038,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 6.407469940185547,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.6043701231479645,
            "frac_alive": 0.0301649309694767,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_5_step_9764": {
            "l2_loss": 51.33238067626953,
            "l1_loss": 75.24948577880859,
            "l0": 14.887500381469726,
            "frac_variance_explained": 0.37563390135765073,
            "cossim": 0.7656529724597931,
            "l2_ratio": 0.7018151044845581,
            "relative_reconstruction_bias": 0.9155072212219239,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 5.384303092956543,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.7065934836864471,
            "frac_alive": 0.0572916679084301,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_2_step_19528": {
            "l2_loss": 33.86196365356445,
            "l1_loss": 159.50118103027344,
            "l0": 78.4625030517578,
            "frac_variance_explained": 0.7501055717468261,
            "cossim": 0.8987978816032409,
            "l2_ratio": 0.8547202706336975,
            "relative_reconstruction_bias": 0.9585883259773255,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.8012768745422365,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9648082673549652,
            "frac_alive": 0.69140625,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_1_step_0": {
            "l2_loss": 100.73842163085938,
            "l1_loss": 1970.5752807617187,
            "l0": 2325.3917236328125,
            "frac_variance_explained": -0.2585247039794922,
            "cossim": 0.009383015270577744,
            "l2_ratio": 0.5849062263965606,
            "relative_reconstruction_bias": 24.026488876342775,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 12.80709753036499,
            "loss_zero": 12.452933025360107,
            "frac_recovered": -0.03542877063155174,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_3_step_4882": {
            "l2_loss": 45.246136856079104,
            "l1_loss": 118.29470367431641,
            "l0": 36.29166793823242,
            "frac_variance_explained": 0.5123350441455841,
            "cossim": 0.825749933719635,
            "l2_ratio": 0.7703978657722473,
            "relative_reconstruction_bias": 0.9318237245082855,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 3.800469160079956,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.8649569272994995,
            "frac_alive": 0.1781684011220932,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_3_step_9764": {
            "l2_loss": 40.23619613647461,
            "l1_loss": 131.072745513916,
            "l0": 43.379167556762695,
            "frac_variance_explained": 0.6291361927986145,
            "cossim": 0.8610006928443908,
            "l2_ratio": 0.810754531621933,
            "relative_reconstruction_bias": 0.9459395587444306,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 3.191999912261963,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9257730364799499,
            "frac_alive": 0.3266059160232544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_3_step_0": {
            "l2_loss": 100.21906433105468,
            "l1_loss": 1965.5150268554687,
            "l0": 2329.3625732421874,
            "frac_variance_explained": -0.26318155527114867,
            "cossim": 0.008277474564965814,
            "l2_ratio": 0.5830273687839508,
            "relative_reconstruction_bias": -11.753353500366211,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 12.80709753036499,
            "loss_zero": 12.452933025360107,
            "frac_recovered": -0.03542877063155174,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_2_step_29292": {
            "l2_loss": 33.69046421051026,
            "l1_loss": 162.30036010742188,
            "l0": 76.94166946411133,
            "frac_variance_explained": 0.7659732937812805,
            "cossim": 0.900548928976059,
            "l2_ratio": 0.8617783546447754,
            "relative_reconstruction_bias": 0.9651949822902679,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.8043951749801637,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9644941091537476,
            "frac_alive": 0.7018229365348816,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_4_step_9764": {
            "l2_loss": 44.85728797912598,
            "l1_loss": 100.88921737670898,
            "l0": 25.47083396911621,
            "frac_variance_explained": 0.5337760984897614,
            "cossim": 0.8230823695659637,
            "l2_ratio": 0.7673629343509674,
            "relative_reconstruction_bias": 0.9354431629180908,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 3.988373875617981,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.8461506485939025,
            "frac_alive": 0.1493055522441864,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_5_step_29292": {
            "l2_loss": 48.183726119995114,
            "l1_loss": 85.12452239990235,
            "l0": 15.925000476837159,
            "frac_variance_explained": 0.5721767365932464,
            "cossim": 0.798095703125,
            "l2_ratio": 0.7409277737140656,
            "relative_reconstruction_bias": 0.9431174993515015,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 4.85986328125,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.7590186119079589,
            "frac_alive": 0.0844184011220932,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_4_step_4882": {
            "l2_loss": 48.85814094543457,
            "l1_loss": 100.89445190429687,
            "l0": 20.02500057220459,
            "frac_variance_explained": 0.6375593423843384,
            "cossim": 0.7864218056201935,
            "l2_ratio": 0.7307790338993072,
            "relative_reconstruction_bias": 0.9553527414798737,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 5.088751125335693,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.7361311614513397,
            "frac_alive": 0.0737847238779068,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_0_step_19528": {
            "l2_loss": 31.616424369812012,
            "l1_loss": 297.32994384765624,
            "l0": 265.2166717529297,
            "frac_variance_explained": 0.822843599319458,
            "cossim": 0.920684015750885,
            "l2_ratio": 0.8821186721324921,
            "relative_reconstruction_bias": 0.9672155797481536,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.6213953733444213,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9827760517597198,
            "frac_alive": 0.994140625,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_2_step_9764": {
            "l2_loss": 34.75586013793945,
            "l1_loss": 166.6844512939453,
            "l0": 78.68750305175782,
            "frac_variance_explained": 0.7706755995750427,
            "cossim": 0.8955578327178955,
            "l2_ratio": 0.856864070892334,
            "relative_reconstruction_bias": 0.9668993175029754,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.8373636484146116,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9612018406391144,
            "frac_alive": 0.6187065839767456,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_2_step_4882": {
            "l2_loss": 40.372269821166995,
            "l1_loss": 165.58629302978517,
            "l0": 69.99166831970214,
            "frac_variance_explained": 0.672182834148407,
            "cossim": 0.8626249969005585,
            "l2_ratio": 0.8161740064620971,
            "relative_reconstruction_bias": 0.9536840617656708,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 3.171216297149658,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9277920424938202,
            "frac_alive": 0.3878038227558136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_0_step_29292": {
            "l2_loss": 28.124167442321777,
            "l1_loss": 274.0728698730469,
            "l0": 249.5666748046875,
            "frac_variance_explained": 0.8547991394996644,
            "cossim": 0.9329928457736969,
            "l2_ratio": 0.8992174088954925,
            "relative_reconstruction_bias": 0.9726329684257508,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.6217980861663817,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9827354609966278,
            "frac_alive": 0.9943576455116272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_5_step_19528": {
            "l2_loss": 49.39628715515137,
            "l1_loss": 80.58980865478516,
            "l0": 15.937500381469727,
            "frac_variance_explained": 0.46403754949569703,
            "cossim": 0.7859353661537171,
            "l2_ratio": 0.7260790169239044,
            "relative_reconstruction_bias": 0.9277416288852691,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 4.776177310943604,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.767445731163025,
            "frac_alive": 0.0833333358168602,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3_checkpoints/trainer_5_step_0": {
            "l2_loss": 100.14542007446289,
            "l1_loss": 1958.4419677734375,
            "l0": 2328.8834228515625,
            "frac_variance_explained": -0.2620940566062927,
            "cossim": 0.00850881328806281,
            "l2_ratio": 0.584683483839035,
            "relative_reconstruction_bias": 72.32083702087402,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 12.80709753036499,
            "loss_zero": 12.452933025360107,
            "frac_recovered": -0.03542877063155174,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15/trainer_4": {
            "l2_loss": 113.48960876464844,
            "l1_loss": 235.19944763183594,
            "l0": 28.33333396911621,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.46572601795196533,
            "cossim": 0.8103770017623901,
            "l2_ratio": 0.747602641582489,
            "relative_reconstruction_bias": 0.9216409921646118,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 4.823451995849609,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.7614176869392395,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15/trainer_3": {
            "l2_loss": 98.79634094238281,
            "l1_loss": 320.187744140625,
            "l0": 53.333335876464844,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.6045359373092651,
            "cossim": 0.8554718494415283,
            "l2_ratio": 0.7977315783500671,
            "relative_reconstruction_bias": 0.9442704916000366,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 3.52919864654541,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.890583336353302,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15/trainer_2": {
            "l2_loss": 81.72660064697266,
            "l1_loss": 402.90167236328125,
            "l0": 95.83333587646484,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.7162007689476013,
            "cossim": 0.8996478915214539,
            "l2_ratio": 0.8465620279312134,
            "relative_reconstruction_bias": 0.9469172954559326,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 2.8805606365203857,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.9553170204162598,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15/trainer_5": {
            "l2_loss": 121.58502197265625,
            "l1_loss": 182.6582489013672,
            "l0": 15.583333969116211,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.39303523302078247,
            "cossim": 0.7566882967948914,
            "l2_ratio": 0.7061890363693237,
            "relative_reconstruction_bias": 0.9442209601402283,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 5.822423934936523,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.661720871925354,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15/trainer_0": {
            "l2_loss": 67.09832000732422,
            "l1_loss": 814.4411010742188,
            "l0": 391.625,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.7999122142791748,
            "cossim": 0.9367318153381348,
            "l2_ratio": 0.899833619594574,
            "relative_reconstruction_bias": 0.9647839665412903,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 2.5446908473968506,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.9888365864753723,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15/trainer_1": {
            "l2_loss": 77.660888671875,
            "l1_loss": 528.8723754882812,
            "l0": 159.45834350585938,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.7398154139518738,
            "cossim": 0.918077826499939,
            "l2_ratio": 0.8793054819107056,
            "relative_reconstruction_bias": 0.9619632363319397,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 2.7192554473876953,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.9714151620864868,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3/trainer_4": {
            "l2_loss": 44.24767303466797,
            "l1_loss": 101.79017639160156,
            "l0": 27.70833396911621,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.5561050176620483,
            "cossim": 0.8321421146392822,
            "l2_ratio": 0.7901780009269714,
            "relative_reconstruction_bias": 0.9499068260192871,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 3.825042247772217,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.8610582947731018,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3/trainer_3": {
            "l2_loss": 46.75660705566406,
            "l1_loss": 125.97972106933594,
            "l0": 44.208335876464844,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.5533230304718018,
            "cossim": 0.827975869178772,
            "l2_ratio": 0.7754380702972412,
            "relative_reconstruction_bias": 0.9375730156898499,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 3.1723814010620117,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.9261934757232666,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3/trainer_2": {
            "l2_loss": 31.35845947265625,
            "l1_loss": 163.89193725585938,
            "l0": 71.91667175292969,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.9396606683731079,
            "cossim": 0.8993327617645264,
            "l2_ratio": 0.8697091341018677,
            "relative_reconstruction_bias": 0.9925031065940857,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 2.780257225036621,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.965327262878418,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3/trainer_5": {
            "l2_loss": 46.883331298828125,
            "l1_loss": 71.56719970703125,
            "l0": 15.083333969116211,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.44323229789733887,
            "cossim": 0.8029685020446777,
            "l2_ratio": 0.7514569163322449,
            "relative_reconstruction_bias": 0.9383984804153442,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 5.1525115966796875,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.728577733039856,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3/trainer_0": {
            "l2_loss": 26.14411163330078,
            "l1_loss": 292.2464599609375,
            "l0": 238.58334350585938,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.9645083546638489,
            "cossim": 0.9470429420471191,
            "l2_ratio": 0.9205843806266785,
            "relative_reconstruction_bias": 0.9918585419654846,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 2.5706419944763184,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.986246645450592,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_3/trainer_1": {
            "l2_loss": 29.303680419921875,
            "l1_loss": 158.7293701171875,
            "l0": 106.04167175292969,
            "frac_alive": 0.00021701389050576836,
            "frac_variance_explained": 0.7315359115600586,
            "cossim": 0.9166043996810913,
            "l2_ratio": 0.8759163618087769,
            "relative_reconstruction_bias": 0.9496256113052368,
            "loss_original": 2.432832717895508,
            "loss_reconstructed": 2.693039655685425,
            "loss_zero": 12.452934265136719,
            "frac_recovered": 0.9740315079689026,
            "hyperparameters": {
                "n_inputs": 24,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_0_step_0": {
            "l2_loss": 281.14896392822266,
            "l1_loss": 5542.925390625,
            "l0": 2321.6958984375,
            "frac_variance_explained": -0.28056758642196655,
            "cossim": 0.0009591022564563901,
            "l2_ratio": 0.5846971690654754,
            "relative_reconstruction_bias": 187.9291549682617,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 19.237961959838866,
            "loss_zero": 12.452933025360107,
            "frac_recovered": -0.6785549759864807,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_3_step_29292": {
            "l2_loss": 95.68815002441406,
            "l1_loss": 350.5757720947266,
            "l0": 52.51666793823242,
            "frac_variance_explained": 0.7078488886356353,
            "cossim": 0.864339393377304,
            "l2_ratio": 0.8135575890541077,
            "relative_reconstruction_bias": 0.9590371608734131,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 3.4994309902191163,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.8950362622737884,
            "frac_alive": 0.2643229067325592,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_1_step_4882": {
            "l2_loss": 92.45786590576172,
            "l1_loss": 480.0212677001953,
            "l0": 106.83750228881836,
            "frac_variance_explained": 0.6875084578990937,
            "cossim": 0.8796217143535614,
            "l2_ratio": 0.8372020542621612,
            "relative_reconstruction_bias": 0.9604873180389404,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 3.298441982269287,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9150556921958923,
            "frac_alive": 0.3361545205116272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_1_step_9764": {
            "l2_loss": 82.11445007324218,
            "l1_loss": 538.5575531005859,
            "l0": 141.65417022705077,
            "frac_variance_explained": 0.8093721151351929,
            "cossim": 0.902193546295166,
            "l2_ratio": 0.8577107489109039,
            "relative_reconstruction_bias": 0.969897985458374,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.8549718856811523,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9594338417053223,
            "frac_alive": 0.5926649570465088,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_3_step_19528": {
            "l2_loss": 96.7630241394043,
            "l1_loss": 350.6046630859375,
            "l0": 54.10416793823242,
            "frac_variance_explained": 0.6776085197925568,
            "cossim": 0.8649233460426331,
            "l2_ratio": 0.8139210224151612,
            "relative_reconstruction_bias": 0.9555837571620941,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 3.5664635181427,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.8883341014385223,
            "frac_alive": 0.2571614682674408,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_2_step_0": {
            "l2_loss": 257.5129623413086,
            "l1_loss": 5042.993701171875,
            "l0": 2317.4084228515626,
            "frac_variance_explained": -0.2708507299423218,
            "cossim": 0.001211711612995714,
            "l2_ratio": 0.5848201394081116,
            "relative_reconstruction_bias": -724.1851900100708,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 19.237961959838866,
            "loss_zero": 12.452933025360107,
            "frac_recovered": -0.6785549759864807,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_1_step_29292": {
            "l2_loss": 77.74995651245118,
            "l1_loss": 520.8725372314453,
            "l0": 149.07500305175782,
            "frac_variance_explained": 0.7870622098445892,
            "cossim": 0.9131448984146118,
            "l2_ratio": 0.8694581031799317,
            "relative_reconstruction_bias": 0.9637641608715057,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.7555546045303343,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.969380009174347,
            "frac_alive": 0.7523871660232544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_4_step_19528": {
            "l2_loss": 111.51310577392579,
            "l1_loss": 262.04630279541016,
            "l0": 30.10833396911621,
            "frac_variance_explained": 0.5429197430610657,
            "cossim": 0.8170331001281739,
            "l2_ratio": 0.7559491753578186,
            "relative_reconstruction_bias": 0.9379147231578827,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 4.450649976730347,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.7999720096588134,
            "frac_alive": 0.1032986119389534,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_4_step_29292": {
            "l2_loss": 107.81969451904297,
            "l1_loss": 273.0679046630859,
            "l0": 29.08750057220459,
            "frac_variance_explained": 0.6212798178195953,
            "cossim": 0.8268159866333008,
            "l2_ratio": 0.7729612231254578,
            "relative_reconstruction_bias": 0.9568374216556549,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 4.432188177108765,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.8018101155757904,
            "frac_alive": 0.1046006977558136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_0_step_9764": {
            "l2_loss": 66.92919654846192,
            "l1_loss": 861.7191101074219,
            "l0": 393.6625091552734,
            "frac_variance_explained": 0.8920291244983674,
            "cossim": 0.9353313446044922,
            "l2_ratio": 0.8954817891120911,
            "relative_reconstruction_bias": 0.9776853740215301,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.6149063110351562,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9834166169166565,
            "frac_alive": 0.9487847089767456,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_1_step_19528": {
            "l2_loss": 81.70073318481445,
            "l1_loss": 535.0343322753906,
            "l0": 156.51667327880858,
            "frac_variance_explained": 0.748112553358078,
            "cossim": 0.9095678985118866,
            "l2_ratio": 0.8660460412502289,
            "relative_reconstruction_bias": 0.9589416205883026,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.761977958679199,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9687412917613983,
            "frac_alive": 0.7404513955116272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_0_step_4882": {
            "l2_loss": 75.69735565185547,
            "l1_loss": 832.57255859375,
            "l0": 347.8250030517578,
            "frac_variance_explained": 0.809298312664032,
            "cossim": 0.9201035678386689,
            "l2_ratio": 0.8765853643417358,
            "relative_reconstruction_bias": 0.9645294606685638,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.7052160263061524,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9743991613388061,
            "frac_alive": 0.6555989384651184,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_4_step_0": {
            "l2_loss": 256.4511154174805,
            "l1_loss": 5020.840576171875,
            "l0": 2317.0292724609376,
            "frac_variance_explained": -0.2691319823265076,
            "cossim": -0.00028005308122374116,
            "l2_ratio": 0.5865442752838135,
            "relative_reconstruction_bias": 43.550068855285645,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 19.237961959838866,
            "loss_zero": 12.452933025360107,
            "frac_recovered": -0.6785549759864807,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_5_step_4882": {
            "l2_loss": 127.97390289306641,
            "l1_loss": 206.5591262817383,
            "l0": 11.925000190734863,
            "frac_variance_explained": 0.4065431773662567,
            "cossim": 0.7479360342025757,
            "l2_ratio": 0.6860776424407959,
            "relative_reconstruction_bias": 0.9359339118003845,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 6.722159051895142,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.5729072570800782,
            "frac_alive": 0.01692708395421505,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_5_step_9764": {
            "l2_loss": 121.93324279785156,
            "l1_loss": 220.63497314453124,
            "l0": 14.341667079925537,
            "frac_variance_explained": 0.5575282990932464,
            "cossim": 0.76461421251297,
            "l2_ratio": 0.6991876542568207,
            "relative_reconstruction_bias": 0.9467950761318207,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 6.127291107177735,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.6323469340801239,
            "frac_alive": 0.0329861119389534,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_2_step_19528": {
            "l2_loss": 84.05611038208008,
            "l1_loss": 469.1122619628906,
            "l0": 106.85416946411132,
            "frac_variance_explained": 0.7695406615734101,
            "cossim": 0.9014839112758637,
            "l2_ratio": 0.8607052445411683,
            "relative_reconstruction_bias": 0.9667794346809387,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.9218042135238647,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9527686178684235,
            "frac_alive": 0.5551215410232544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_1_step_0": {
            "l2_loss": 256.17513580322264,
            "l1_loss": 5014.985400390625,
            "l0": 2316.9209228515624,
            "frac_variance_explained": -0.2697333931922913,
            "cossim": 0.0011479882363346406,
            "l2_ratio": 0.5839214861392975,
            "relative_reconstruction_bias": -215.6730899810791,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 19.237961959838866,
            "loss_zero": 12.452933025360107,
            "frac_recovered": -0.6785549759864807,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_3_step_4882": {
            "l2_loss": 110.45609130859376,
            "l1_loss": 298.7429962158203,
            "l0": 34.612501335144046,
            "frac_variance_explained": 0.6015409231185913,
            "cossim": 0.8189373135566711,
            "l2_ratio": 0.7701087653636932,
            "relative_reconstruction_bias": 0.958368855714798,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 4.774560260772705,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.7674971878528595,
            "frac_alive": 0.1000434011220932,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_3_step_9764": {
            "l2_loss": 99.56384735107422,
            "l1_loss": 339.0820037841797,
            "l0": 44.820834732055665,
            "frac_variance_explained": 0.711234039068222,
            "cossim": 0.8532631695270538,
            "l2_ratio": 0.7980346500873565,
            "relative_reconstruction_bias": 0.9607606291770935,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 4.031507468223571,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.8417571783065796,
            "frac_alive": 0.1740451455116272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_3_step_0": {
            "l2_loss": 231.15552368164063,
            "l1_loss": 4489.24658203125,
            "l0": 2316.329248046875,
            "frac_variance_explained": -0.26047190427780154,
            "cossim": 8.40582069940865e-05,
            "l2_ratio": 0.5850227475166321,
            "relative_reconstruction_bias": 195.60233993530272,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 19.237961959838866,
            "loss_zero": 12.452933025360107,
            "frac_recovered": -0.6785549759864807,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_2_step_29292": {
            "l2_loss": 85.17279663085938,
            "l1_loss": 447.0196990966797,
            "l0": 103.88333587646484,
            "frac_variance_explained": 0.7250771164894104,
            "cossim": 0.8943696618080139,
            "l2_ratio": 0.8461162567138671,
            "relative_reconstruction_bias": 0.9539723515510559,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.911734127998352,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9537715792655945,
            "frac_alive": 0.5692274570465088,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_4_step_9764": {
            "l2_loss": 113.5843116760254,
            "l1_loss": 252.77923889160155,
            "l0": 25.245834159851075,
            "frac_variance_explained": 0.5485736966133118,
            "cossim": 0.7993731915950775,
            "l2_ratio": 0.7412838041782379,
            "relative_reconstruction_bias": 0.946537721157074,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 5.042220592498779,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.740761137008667,
            "frac_alive": 0.065321184694767,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_5_step_29292": {
            "l2_loss": 120.05647201538086,
            "l1_loss": 202.17495727539062,
            "l0": 17.42083387374878,
            "frac_variance_explained": 0.4464818716049194,
            "cossim": 0.7806535840034485,
            "l2_ratio": 0.7235223412513733,
            "relative_reconstruction_bias": 0.9385318279266357,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 5.541814994812012,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.6908769071102142,
            "frac_alive": 0.0377604179084301,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_4_step_4882": {
            "l2_loss": 121.34070663452148,
            "l1_loss": 262.25079956054685,
            "l0": 19.487500762939455,
            "frac_variance_explained": 0.5703380644321442,
            "cossim": 0.7837790310382843,
            "l2_ratio": 0.7280552625656128,
            "relative_reconstruction_bias": 0.955090606212616,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 5.772414875030518,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.6677946805953979,
            "frac_alive": 0.0368923619389534,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_0_step_19528": {
            "l2_loss": 69.83187561035156,
            "l1_loss": 847.4075866699219,
            "l0": 398.4583435058594,
            "frac_variance_explained": 0.8012268245220184,
            "cossim": 0.9330742597579956,
            "l2_ratio": 0.8880240499973298,
            "relative_reconstruction_bias": 0.9544644832611084,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.600884199142456,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9848233103752136,
            "frac_alive": 0.9845920205116272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_2_step_9764": {
            "l2_loss": 89.52805938720704,
            "l1_loss": 439.7564239501953,
            "l0": 91.19583587646484,
            "frac_variance_explained": 0.7367781817913055,
            "cossim": 0.8870235443115234,
            "l2_ratio": 0.8377370297908783,
            "relative_reconstruction_bias": 0.9590561985969543,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 3.084984612464905,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9364551603794098,
            "frac_alive": 0.4086371660232544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_2_step_4882": {
            "l2_loss": 98.73006210327148,
            "l1_loss": 384.65655822753905,
            "l0": 68.21667022705078,
            "frac_variance_explained": 0.6368264198303223,
            "cossim": 0.8576289415359497,
            "l2_ratio": 0.8093531727790833,
            "relative_reconstruction_bias": 0.9528661787509918,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 3.738444471359253,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.8710575520992279,
            "frac_alive": 0.2222222238779068,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_0_step_29292": {
            "l2_loss": 67.27419967651367,
            "l1_loss": 845.8086608886719,
            "l0": 385.4791748046875,
            "frac_variance_explained": 0.8640030324459076,
            "cossim": 0.9385475635528564,
            "l2_ratio": 0.8994818031787872,
            "relative_reconstruction_bias": 0.9717325687408447,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.6003377437591553,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.984874302148819,
            "frac_alive": 0.9878472089767456,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_5_step_19528": {
            "l2_loss": 117.81037902832031,
            "l1_loss": 212.1170211791992,
            "l0": 17.48750057220459,
            "frac_variance_explained": 0.48393594622612,
            "cossim": 0.7916970670223236,
            "l2_ratio": 0.7271284759044647,
            "relative_reconstruction_bias": 0.9356465280056,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 5.550904703140259,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.6899532973766327,
            "frac_alive": 0.0373263880610466,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_15_checkpoints/trainer_5_step_0": {
            "l2_loss": 283.3918487548828,
            "l1_loss": 5590.122802734375,
            "l0": 2320.03759765625,
            "frac_variance_explained": -0.271913743019104,
            "cossim": 0.0016578406444750725,
            "l2_ratio": 0.5851598381996155,
            "relative_reconstruction_bias": 126.18049049377441,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 19.237961959838866,
            "loss_zero": 12.452933025360107,
            "frac_recovered": -0.6785549759864807,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_0_step_0": {
            "l2_loss": 127.63803405761719,
            "l1_loss": 2476.1285400390625,
            "l0": 2316.5792724609373,
            "frac_variance_explained": -0.256933856010437,
            "cossim": 0.0003572506597265601,
            "l2_ratio": 0.5852371990680695,
            "relative_reconstruction_bias": 123.43299598693848,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 16.358910942077635,
            "loss_zero": 12.452933025360107,
            "frac_recovered": -0.3904870688915253,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_3_step_29292": {
            "l2_loss": 51.53147583007812,
            "l1_loss": 191.88319549560546,
            "l0": 52.77083473205566,
            "frac_variance_explained": 0.7044060885906219,
            "cossim": 0.859742957353592,
            "l2_ratio": 0.8055006265640259,
            "relative_reconstruction_bias": 0.9523079752922058,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 3.1933653116226197,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9256390810012818,
            "frac_alive": 0.2775607705116272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_1_step_4882": {
            "l2_loss": 48.07004089355469,
            "l1_loss": 253.8027130126953,
            "l0": 106.95416946411133,
            "frac_variance_explained": 0.71333047747612,
            "cossim": 0.8780210435390472,
            "l2_ratio": 0.8307399213314056,
            "relative_reconstruction_bias": 0.9596150875091553,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 3.01373291015625,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9435934662818909,
            "frac_alive": 0.314453125,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_1_step_9764": {
            "l2_loss": 45.82279167175293,
            "l1_loss": 283.51268005371094,
            "l0": 140.68333892822267,
            "frac_variance_explained": 0.706933343410492,
            "cossim": 0.899019193649292,
            "l2_ratio": 0.8532056450843811,
            "relative_reconstruction_bias": 0.9520143628120422,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.7451914072036745,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9704126238822937,
            "frac_alive": 0.581163227558136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_3_step_19528": {
            "l2_loss": 52.38095817565918,
            "l1_loss": 186.5856704711914,
            "l0": 54.029167556762694,
            "frac_variance_explained": 0.648041570186615,
            "cossim": 0.8631792008876801,
            "l2_ratio": 0.8132404029369354,
            "relative_reconstruction_bias": 0.9476512670516968,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 3.203889012336731,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9245846688747406,
            "frac_alive": 0.2721354067325592,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_2_step_0": {
            "l2_loss": 132.15108108520508,
            "l1_loss": 2567.571533203125,
            "l0": 2317.2667724609373,
            "frac_variance_explained": -0.25881229639053344,
            "cossim": -0.0013772994920145721,
            "l2_ratio": 0.5856556534767151,
            "relative_reconstruction_bias": -45.01684970855713,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 16.358910942077635,
            "loss_zero": 12.452933025360107,
            "frac_recovered": -0.3904870688915253,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_1_step_29292": {
            "l2_loss": 43.638262557983396,
            "l1_loss": 279.28123779296874,
            "l0": 143.31250457763673,
            "frac_variance_explained": 0.7456384658813476,
            "cossim": 0.9042900800704956,
            "l2_ratio": 0.8594461619853974,
            "relative_reconstruction_bias": 0.9541392803192139,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.6683804988861084,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9780857622623443,
            "frac_alive": 0.7439236044883728,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_4_step_19528": {
            "l2_loss": 58.37063331604004,
            "l1_loss": 135.51132202148438,
            "l0": 30.95000057220459,
            "frac_variance_explained": 0.493176794052124,
            "cossim": 0.8242928624153137,
            "l2_ratio": 0.765826153755188,
            "relative_reconstruction_bias": 0.9297281742095947,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 4.046674132347107,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.8403484761714936,
            "frac_alive": 0.1143663227558136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_4_step_29292": {
            "l2_loss": 58.68501281738281,
            "l1_loss": 143.0679718017578,
            "l0": 29.120833969116212,
            "frac_variance_explained": 0.5908918797969818,
            "cossim": 0.8210247695446015,
            "l2_ratio": 0.7625429391860962,
            "relative_reconstruction_bias": 0.9429949820041656,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 4.027128434181213,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.8423065185546875,
            "frac_alive": 0.1174045130610466,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_0_step_9764": {
            "l2_loss": 35.9807804107666,
            "l1_loss": 419.61554565429685,
            "l0": 361.3625122070313,
            "frac_variance_explained": 0.8184772491455078,
            "cossim": 0.9344189941883088,
            "l2_ratio": 0.8945362329483032,
            "relative_reconstruction_bias": 0.9616890132427216,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.5635795116424562,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9885444223880768,
            "frac_alive": 0.921875,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_1_step_19528": {
            "l2_loss": 42.89727935791016,
            "l1_loss": 283.138850402832,
            "l0": 141.7375045776367,
            "frac_variance_explained": 0.7606079995632171,
            "cossim": 0.9110740959644318,
            "l2_ratio": 0.8712258517742157,
            "relative_reconstruction_bias": 0.960601943731308,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.6724072456359864,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9776863336563111,
            "frac_alive": 0.7371962070465088,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_0_step_4882": {
            "l2_loss": 40.78137092590332,
            "l1_loss": 436.5119995117187,
            "l0": 315.7291717529297,
            "frac_variance_explained": 0.8216859638690949,
            "cossim": 0.9173788249492645,
            "l2_ratio": 0.8723874926567078,
            "relative_reconstruction_bias": 0.9640501797199249,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.648338508605957,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9800862550735474,
            "frac_alive": 0.6082899570465088,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_4_step_0": {
            "l2_loss": 131.02298278808593,
            "l1_loss": 2549.5763427734373,
            "l0": 2312.7958984375,
            "frac_variance_explained": -0.2592296838760376,
            "cossim": 0.0013972906279377639,
            "l2_ratio": 0.5847895681858063,
            "relative_reconstruction_bias": 68.87722301483154,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 16.358910942077635,
            "loss_zero": 12.452933025360107,
            "frac_recovered": -0.3904870688915253,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_5_step_4882": {
            "l2_loss": 69.97581558227539,
            "l1_loss": 117.33395385742188,
            "l0": 11.412500381469727,
            "frac_variance_explained": 0.4838683843612671,
            "cossim": 0.7333641767501831,
            "l2_ratio": 0.6730525672435761,
            "relative_reconstruction_bias": 0.9416388988494873,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 6.504792022705078,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.5945926964282989,
            "frac_alive": 0.0225694440305233,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_5_step_9764": {
            "l2_loss": 67.60840759277343,
            "l1_loss": 110.05257949829101,
            "l0": 14.258333778381347,
            "frac_variance_explained": 0.5035609662532806,
            "cossim": 0.7498954892158508,
            "l2_ratio": 0.683852881193161,
            "relative_reconstruction_bias": 0.9370332419872284,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 5.775146007537842,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.6675476551055908,
            "frac_alive": 0.029296875,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_2_step_19528": {
            "l2_loss": 45.7825740814209,
            "l1_loss": 236.97366638183593,
            "l0": 99.21666946411133,
            "frac_variance_explained": 0.7160657107830047,
            "cossim": 0.8954527616500855,
            "l2_ratio": 0.8490359067916871,
            "relative_reconstruction_bias": 0.9527168869972229,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.7924960136413572,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9656895935535431,
            "frac_alive": 0.5583767294883728,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_1_step_0": {
            "l2_loss": 125.25699462890626,
            "l1_loss": 2430.6418212890626,
            "l0": 2316.9959716796875,
            "frac_variance_explained": -0.2564337730407715,
            "cossim": -0.003045231505529955,
            "l2_ratio": 0.5844420671463013,
            "relative_reconstruction_bias": -124.71590557098389,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 16.358910942077635,
            "loss_zero": 12.452933025360107,
            "frac_recovered": -0.3904870688915253,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_3_step_4882": {
            "l2_loss": 58.394795989990236,
            "l1_loss": 156.49520416259764,
            "l0": 35.43333511352539,
            "frac_variance_explained": 0.5727852582931519,
            "cossim": 0.8161571085453033,
            "l2_ratio": 0.762641555070877,
            "relative_reconstruction_bias": 0.9479292750358581,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 4.445304346084595,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.8004228711128235,
            "frac_alive": 0.0913628488779068,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_3_step_9764": {
            "l2_loss": 55.26373023986817,
            "l1_loss": 177.75314483642578,
            "l0": 46.24583473205566,
            "frac_variance_explained": 0.6405601739883423,
            "cossim": 0.8429579377174378,
            "l2_ratio": 0.7844432055950165,
            "relative_reconstruction_bias": 0.9461081862449646,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 3.561774468421936,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.8888198018074036,
            "frac_alive": 0.179470494389534,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_3_step_0": {
            "l2_loss": 127.41825942993164,
            "l1_loss": 2473.4224365234377,
            "l0": 2315.454248046875,
            "frac_variance_explained": -0.25454756021499636,
            "cossim": -0.0002398826094577089,
            "l2_ratio": 0.5860282599925994,
            "relative_reconstruction_bias": 45.16152172088623,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 16.358910942077635,
            "loss_zero": 12.452933025360107,
            "frac_recovered": -0.3904870688915253,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_2_step_29292": {
            "l2_loss": 45.79281425476074,
            "l1_loss": 243.82076873779297,
            "l0": 100.87916870117188,
            "frac_variance_explained": 0.7122628688812256,
            "cossim": 0.8953520834445954,
            "l2_ratio": 0.8436816751956939,
            "relative_reconstruction_bias": 0.9460070669651032,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.782563018798828,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9666838705539703,
            "frac_alive": 0.567491352558136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_4_step_9764": {
            "l2_loss": 62.29627952575684,
            "l1_loss": 131.05855560302734,
            "l0": 25.21250057220459,
            "frac_variance_explained": 0.4862762033939362,
            "cossim": 0.801862770318985,
            "l2_ratio": 0.7427639424800873,
            "relative_reconstruction_bias": 0.9335109114646911,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 4.772459077835083,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.7677631497383117,
            "frac_alive": 0.071180559694767,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_5_step_29292": {
            "l2_loss": 64.1264404296875,
            "l1_loss": 110.02379150390625,
            "l0": 17.07916717529297,
            "frac_variance_explained": 0.5028854191303254,
            "cossim": 0.7782177269458771,
            "l2_ratio": 0.7192116022109986,
            "relative_reconstruction_bias": 0.9414959251880646,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 5.178795099258423,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.7271834075450897,
            "frac_alive": 0.046875,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_4_step_4882": {
            "l2_loss": 67.15477981567383,
            "l1_loss": 125.10972900390625,
            "l0": 18.416667556762697,
            "frac_variance_explained": 0.4790739119052887,
            "cossim": 0.7583967983722687,
            "l2_ratio": 0.697561776638031,
            "relative_reconstruction_bias": 0.9389411687850953,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 5.5317529201507565,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.6918634057044983,
            "frac_alive": 0.0407986119389534,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_0_step_19528": {
            "l2_loss": 35.89302082061768,
            "l1_loss": 424.8230773925781,
            "l0": 346.3416748046875,
            "frac_variance_explained": 0.8397217273712159,
            "cossim": 0.937388414144516,
            "l2_ratio": 0.8963266789913178,
            "relative_reconstruction_bias": 0.9621351420879364,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.556091332435608,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9892906129360199,
            "frac_alive": 0.9767795205116272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_2_step_9764": {
            "l2_loss": 47.803291702270506,
            "l1_loss": 234.50020294189454,
            "l0": 93.80000228881836,
            "frac_variance_explained": 0.7072011530399323,
            "cossim": 0.8822123646736145,
            "l2_ratio": 0.8295261204242707,
            "relative_reconstruction_bias": 0.9486966550350189,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.915797543525696,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9533673524856567,
            "frac_alive": 0.407769113779068,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_2_step_4882": {
            "l2_loss": 54.03678512573242,
            "l1_loss": 217.74637298583986,
            "l0": 73.30833587646484,
            "frac_variance_explained": 0.619121640920639,
            "cossim": 0.8548075020313263,
            "l2_ratio": 0.8081589043140411,
            "relative_reconstruction_bias": 0.9515588343143463,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 3.442649817466736,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9006551563739776,
            "frac_alive": 0.2007378488779068,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_0_step_29292": {
            "l2_loss": 37.54052658081055,
            "l1_loss": 449.4192657470703,
            "l0": 352.9416778564453,
            "frac_variance_explained": 0.8342497229576111,
            "cossim": 0.9324738144874573,
            "l2_ratio": 0.8940540730953217,
            "relative_reconstruction_bias": 0.9653352200984955,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.552870011329651,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9896114051342011,
            "frac_alive": 0.9789496660232544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_5_step_19528": {
            "l2_loss": 64.3610336303711,
            "l1_loss": 111.13289260864258,
            "l0": 17.58333396911621,
            "frac_variance_explained": 0.4550139129161835,
            "cossim": 0.7846160709857941,
            "l2_ratio": 0.721789938211441,
            "relative_reconstruction_bias": 0.9306655168533325,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 5.2225535869598385,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.7228001356124878,
            "frac_alive": 0.0442708320915699,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_7_checkpoints/trainer_5_step_0": {
            "l2_loss": 127.07051162719726,
            "l1_loss": 2466.3863525390625,
            "l0": 2315.2709228515623,
            "frac_variance_explained": -0.25545125007629393,
            "cossim": -0.002103566180448979,
            "l2_ratio": 0.5858675241470337,
            "relative_reconstruction_bias": 4.240536880493164,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 16.358910942077635,
            "loss_zero": 12.452933025360107,
            "frac_recovered": -0.3904870688915253,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_0_step_0": {
            "l2_loss": 371.35711059570315,
            "l1_loss": 7279.427880859375,
            "l0": 2320.86259765625,
            "frac_variance_explained": -0.2634151816368103,
            "cossim": 0.007653782051056624,
            "l2_ratio": 0.583901333808899,
            "relative_reconstruction_bias": 107.74080448150634,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 17.467887687683106,
            "loss_zero": 12.452933025360107,
            "frac_recovered": -0.5014308452606201,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_3_step_29292": {
            "l2_loss": 155.16848449707032,
            "l1_loss": 506.4497955322266,
            "l0": 47.53750152587891,
            "frac_variance_explained": 0.6450257897377014,
            "cossim": 0.8370158791542053,
            "l2_ratio": 0.781826275587082,
            "relative_reconstruction_bias": 0.9496566534042359,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 3.4310434103012084,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9019276559352875,
            "frac_alive": 0.3415798544883728,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_1_step_4882": {
            "l2_loss": 152.29086303710938,
            "l1_loss": 657.916357421875,
            "l0": 89.1250015258789,
            "frac_variance_explained": 0.6185829639434814,
            "cossim": 0.8531668663024903,
            "l2_ratio": 0.805322140455246,
            "relative_reconstruction_bias": 0.9513052821159362,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 3.3578301429748536,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9091786682605744,
            "frac_alive": 0.3346354067325592,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_1_step_9764": {
            "l2_loss": 138.69766387939453,
            "l1_loss": 776.0849426269531,
            "l0": 123.02500381469727,
            "frac_variance_explained": 0.6951747298240661,
            "cossim": 0.8819191336631775,
            "l2_ratio": 0.8314236342906952,
            "relative_reconstruction_bias": 0.9493630766868592,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.9680344581604006,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9481630146503448,
            "frac_alive": 0.6069878339767456,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_3_step_19528": {
            "l2_loss": 158.53858489990233,
            "l1_loss": 507.2026702880859,
            "l0": 48.07500114440918,
            "frac_variance_explained": 0.608351856470108,
            "cossim": 0.8339714288711548,
            "l2_ratio": 0.7790485501289368,
            "relative_reconstruction_bias": 0.9447649359703064,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 3.4509163379669188,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.8999380648136139,
            "frac_alive": 0.3298611044883728,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_2_step_0": {
            "l2_loss": 370.62839660644534,
            "l1_loss": 7255.14267578125,
            "l0": 2319.7833740234373,
            "frac_variance_explained": -0.2650580644607544,
            "cossim": 0.003742779977619648,
            "l2_ratio": 0.5835524737834931,
            "relative_reconstruction_bias": 80.84558773040771,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 17.467887687683106,
            "loss_zero": 12.452933025360107,
            "frac_recovered": -0.5014308452606201,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_1_step_29292": {
            "l2_loss": 129.030419921875,
            "l1_loss": 789.661083984375,
            "l0": 132.35833740234375,
            "frac_variance_explained": 0.7087284028530121,
            "cossim": 0.8965775370597839,
            "l2_ratio": 0.8510726571083069,
            "relative_reconstruction_bias": 0.9525537729263306,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.8536326408386232,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9595907092094421,
            "frac_alive": 0.771484375,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_4_step_19528": {
            "l2_loss": 174.6298385620117,
            "l1_loss": 396.54876403808595,
            "l0": 26.808334350585938,
            "frac_variance_explained": 0.591366457939148,
            "cossim": 0.7941572189331054,
            "l2_ratio": 0.7313139140605927,
            "relative_reconstruction_bias": 0.9437447428703308,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 4.16132378578186,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.8289062082767487,
            "frac_alive": 0.1490885466337204,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_4_step_29292": {
            "l2_loss": 172.5397979736328,
            "l1_loss": 380.47484130859374,
            "l0": 27.15833396911621,
            "frac_variance_explained": 0.5243089616298675,
            "cossim": 0.7995267570018768,
            "l2_ratio": 0.7399701535701751,
            "relative_reconstruction_bias": 0.9357422709465026,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 4.138606762886047,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.8311761975288391,
            "frac_alive": 0.1516927033662796,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_0_step_9764": {
            "l2_loss": 111.94961318969726,
            "l1_loss": 1248.9859497070313,
            "l0": 349.90000915527344,
            "frac_variance_explained": 0.8134211480617524,
            "cossim": 0.9204918384552002,
            "l2_ratio": 0.8732710778713226,
            "relative_reconstruction_bias": 0.961563915014267,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.684865427017212,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.976431530714035,
            "frac_alive": 0.9225260615348816,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_1_step_19528": {
            "l2_loss": 127.00754928588867,
            "l1_loss": 803.1088134765625,
            "l0": 129.59583740234376,
            "frac_variance_explained": 0.781667423248291,
            "cossim": 0.891762238740921,
            "l2_ratio": 0.8464019656181335,
            "relative_reconstruction_bias": 0.9648607969284058,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.8610363006591797,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9588544428348541,
            "frac_alive": 0.7682291865348816,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_0_step_4882": {
            "l2_loss": 125.15795364379883,
            "l1_loss": 1198.84365234375,
            "l0": 294.72084350585936,
            "frac_variance_explained": 0.7881446778774261,
            "cossim": 0.8971912086009979,
            "l2_ratio": 0.8546759426593781,
            "relative_reconstruction_bias": 0.968045049905777,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.83357994556427,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.961580467224121,
            "frac_alive": 0.6197916865348816,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_4_step_0": {
            "l2_loss": 383.6473785400391,
            "l1_loss": 7526.182470703125,
            "l0": 2321.5458740234376,
            "frac_variance_explained": -0.26600065231323244,
            "cossim": 0.005822121375240385,
            "l2_ratio": 0.5849872529506683,
            "relative_reconstruction_bias": 119.72703323364257,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 17.467887687683106,
            "loss_zero": 12.452933025360107,
            "frac_recovered": -0.5014308452606201,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_5_step_4882": {
            "l2_loss": 208.76700744628906,
            "l1_loss": 254.40394592285156,
            "l0": 11.300000381469726,
            "frac_variance_explained": 0.3127666711807251,
            "cossim": 0.7023907721042633,
            "l2_ratio": 0.6329964935779572,
            "relative_reconstruction_bias": 0.9175472021102905,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 6.440131378173828,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.6011272072792053,
            "frac_alive": 0.0397135429084301,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_5_step_9764": {
            "l2_loss": 201.8096954345703,
            "l1_loss": 272.2518478393555,
            "l0": 13.154167079925537,
            "frac_variance_explained": 0.35985862612724306,
            "cossim": 0.7169819116592407,
            "l2_ratio": 0.6535629987716675,
            "relative_reconstruction_bias": 0.929140591621399,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 5.793548059463501,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.665748006105423,
            "frac_alive": 0.0355902798473835,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_2_step_19528": {
            "l2_loss": 131.90502471923827,
            "l1_loss": 736.9512817382813,
            "l0": 95.21666870117187,
            "frac_variance_explained": 0.8147355198860169,
            "cossim": 0.8877768754959107,
            "l2_ratio": 0.8465871453285218,
            "relative_reconstruction_bias": 0.9731051027774811,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.9973817110061645,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9452395141124725,
            "frac_alive": 0.604600727558136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_1_step_0": {
            "l2_loss": 360.82404174804685,
            "l1_loss": 7040.68017578125,
            "l0": 2318.3375732421873,
            "frac_variance_explained": -0.2559817314147949,
            "cossim": 0.007890741503797472,
            "l2_ratio": 0.5827587604522705,
            "relative_reconstruction_bias": 86.9328426361084,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 17.467887687683106,
            "loss_zero": 12.452933025360107,
            "frac_recovered": -0.5014308452606201,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_3_step_4882": {
            "l2_loss": 179.81192474365236,
            "l1_loss": 436.8461456298828,
            "l0": 29.366667556762696,
            "frac_variance_explained": 0.5799011051654815,
            "cossim": 0.7886780142784119,
            "l2_ratio": 0.7357843160629273,
            "relative_reconstruction_bias": 0.9547523438930512,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 4.721106767654419,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.7728629291057587,
            "frac_alive": 0.1076388880610466,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_3_step_9764": {
            "l2_loss": 167.65035858154297,
            "l1_loss": 464.6881866455078,
            "l0": 38.97500152587891,
            "frac_variance_explained": 0.587290495634079,
            "cossim": 0.816248744726181,
            "l2_ratio": 0.7580881595611573,
            "relative_reconstruction_bias": 0.9453555285930634,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 3.8909584522247314,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.8559192776679992,
            "frac_alive": 0.2035590261220932,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_3_step_0": {
            "l2_loss": 361.4767791748047,
            "l1_loss": 7056.44228515625,
            "l0": 2318.3583984375,
            "frac_variance_explained": -0.26226993799209597,
            "cossim": 0.006145763583481312,
            "l2_ratio": 0.5840395629405976,
            "relative_reconstruction_bias": 181.8343656539917,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 17.467887687683106,
            "loss_zero": 12.452933025360107,
            "frac_recovered": -0.5014308452606201,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_2_step_29292": {
            "l2_loss": 139.09943542480468,
            "l1_loss": 655.6513122558594,
            "l0": 91.28750228881836,
            "frac_variance_explained": 0.6637598216533661,
            "cossim": 0.8755292773246766,
            "l2_ratio": 0.8230892658233643,
            "relative_reconstruction_bias": 0.944346296787262,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.986932802200317,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9462803483009339,
            "frac_alive": 0.625,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_4_step_9764": {
            "l2_loss": 184.47832183837892,
            "l1_loss": 343.01512451171874,
            "l0": 22.27083396911621,
            "frac_variance_explained": 0.45010697841644287,
            "cossim": 0.7727274775505066,
            "l2_ratio": 0.7113068699836731,
            "relative_reconstruction_bias": 0.9318662643432617,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 4.856968593597412,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.7592635989189148,
            "frac_alive": 0.0872395858168602,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_5_step_29292": {
            "l2_loss": 192.05928802490234,
            "l1_loss": 298.58506774902344,
            "l0": 15.570833873748779,
            "frac_variance_explained": 0.4263908088207245,
            "cossim": 0.758286964893341,
            "l2_ratio": 0.6910069584846497,
            "relative_reconstruction_bias": 0.9257101714611053,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 5.091181135177612,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.7359705746173859,
            "frac_alive": 0.0607638880610466,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_4_step_4882": {
            "l2_loss": 197.7962188720703,
            "l1_loss": 304.8713806152344,
            "l0": 16.84583396911621,
            "frac_variance_explained": 0.39577420353889464,
            "cossim": 0.7337230682373047,
            "l2_ratio": 0.6741367459297181,
            "relative_reconstruction_bias": 0.9335340976715087,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 5.506568384170532,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.694397485256195,
            "frac_alive": 0.0635850727558136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_0_step_19528": {
            "l2_loss": 112.5473388671875,
            "l1_loss": 1243.8572998046875,
            "l0": 340.2250061035156,
            "frac_variance_explained": 0.8152908742427826,
            "cossim": 0.9223809123039246,
            "l2_ratio": 0.8755505979061127,
            "relative_reconstruction_bias": 0.9602122366428375,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.669814848899841,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9779346823692322,
            "frac_alive": 0.9826388955116272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_2_step_9764": {
            "l2_loss": 148.41188049316406,
            "l1_loss": 633.6824157714843,
            "l0": 80.97916793823242,
            "frac_variance_explained": 0.620763772726059,
            "cossim": 0.8645691692829132,
            "l2_ratio": 0.812127161026001,
            "relative_reconstruction_bias": 0.9445520520210267,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 3.1970449447631837,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9252795040607452,
            "frac_alive": 0.4361979067325592,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_2_step_4882": {
            "l2_loss": 163.94574890136718,
            "l1_loss": 540.0486846923828,
            "l0": 56.70000114440918,
            "frac_variance_explained": 0.606154328584671,
            "cossim": 0.8178614854812623,
            "l2_ratio": 0.7668595492839814,
            "relative_reconstruction_bias": 0.9527188301086426,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 3.737464094161987,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.871268343925476,
            "frac_alive": 0.234375,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_0_step_29292": {
            "l2_loss": 113.09485397338867,
            "l1_loss": 1276.8792724609375,
            "l0": 341.48333740234375,
            "frac_variance_explained": 0.8345544159412384,
            "cossim": 0.9237881600856781,
            "l2_ratio": 0.8762264668941497,
            "relative_reconstruction_bias": 0.9630283296108246,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 2.670884203910828,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9778282225131989,
            "frac_alive": 0.9828559160232544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_5_step_19528": {
            "l2_loss": 193.92217254638672,
            "l1_loss": 313.5412170410156,
            "l0": 16.55833387374878,
            "frac_variance_explained": 0.4600773870944977,
            "cossim": 0.7497961163520813,
            "l2_ratio": 0.686975759267807,
            "relative_reconstruction_bias": 0.9342592597007752,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 5.139773559570313,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.7311200618743896,
            "frac_alive": 0.0583767369389534,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_standard_ctx128_ef2_0824/resid_post_layer_19_checkpoints/trainer_5_step_0": {
            "l2_loss": 376.0127777099609,
            "l1_loss": 7370.91201171875,
            "l0": 2319.3083984375,
            "frac_variance_explained": -0.2640445590019226,
            "cossim": 0.006752515817061067,
            "l2_ratio": 0.5842531144618988,
            "relative_reconstruction_bias": 103.55522689819335,
            "loss_original": 2.4483999013900757,
            "loss_reconstructed": 17.467887687683106,
            "loss_zero": 12.452933025360107,
            "frac_recovered": -0.5014308452606201,
            "frac_alive": 1.0,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        }
    }
}