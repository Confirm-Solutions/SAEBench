{
    "sae_config_dictionary_learning": {
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19/trainer_4": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 320,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19/trainer_3": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 160,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19/trainer_2": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 80,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19/trainer_5": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 640,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19/trainer_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 20,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19/trainer_1": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 40,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11/trainer_4": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 320,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11/trainer_3": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 160,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11/trainer_2": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 80,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11/trainer_5": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 640,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11/trainer_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 20,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11/trainer_1": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 40,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7/trainer_4": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 320,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7/trainer_3": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 160,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7/trainer_2": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 80,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7/trainer_5": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 640,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7/trainer_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 20,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7/trainer_1": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 40,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_0_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 20,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_0_step_15440": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "15440",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 20,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_3_step_154": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "154",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 160,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_2_step_154": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "154",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 80,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_2_step_1544": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "1544",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 80,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_1_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 40,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_3_step_488": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "488",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 160,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_2_step_488": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "488",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 80,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_2_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 80,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_5_step_15440": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "15440",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 640,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_4_step_1544": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "1544",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 320,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_4_step_488": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "488",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 320,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_5_step_488": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "488",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 640,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_5_step_48": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "48",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 640,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_2_step_15440": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "15440",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 80,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_3_step_1544": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "1544",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 160,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_0_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 20,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_4_step_154": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "154",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 320,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_5_step_154": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "154",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 640,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_4_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 320,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_4_step_48": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "48",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 320,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_5_step_1544": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "1544",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 640,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_1_step_48": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "48",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 40,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_5_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 640,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_4_step_15440": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "15440",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 320,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_0_step_488": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "488",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 20,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_1_step_488": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "488",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 40,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_1_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 40,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_0_step_1544": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "1544",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 20,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_1_step_15440": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "15440",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 40,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_3_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 160,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_3_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 160,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_0_step_48": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "48",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 20,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_0_step_154": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "154",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 20,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_1_step_154": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "154",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 40,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_4_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 320,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_2_step_48": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "48",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 80,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_1_step_1544": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "1544",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 40,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_3_step_48": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "48",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 160,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_2_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 80,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_3_step_15440": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "15440",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 160,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_5_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 640,
                "device": "cuda:0",
                "layer": 11,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_11",
                "submodule_name": "resid_post_layer_11"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_0_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 20,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_0_step_15440": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "15440",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 20,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_3_step_154": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "154",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 160,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_2_step_154": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "154",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 80,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_2_step_1544": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "1544",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 80,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_1_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 40,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_3_step_488": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "488",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 160,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_2_step_488": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "488",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 80,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_2_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 80,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_5_step_15440": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "15440",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 640,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_4_step_1544": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "1544",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 320,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_4_step_488": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "488",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 320,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_5_step_488": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "488",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 640,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_5_step_48": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "48",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 640,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_2_step_15440": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "15440",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 80,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_3_step_1544": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "1544",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 160,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_0_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 20,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_4_step_154": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "154",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 320,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_5_step_154": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "154",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 640,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_4_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 320,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_4_step_48": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "48",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 320,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_5_step_1544": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "1544",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 640,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_1_step_48": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "48",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 40,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_5_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 640,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_4_step_15440": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "15440",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 320,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_0_step_488": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "488",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 20,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_1_step_488": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "488",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 40,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_1_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 40,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_0_step_1544": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "1544",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 20,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_1_step_15440": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "15440",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 40,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_3_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 160,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_3_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 160,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_0_step_48": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "48",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 20,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_0_step_154": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "154",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 20,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_1_step_154": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "154",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 40,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_4_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 320,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_2_step_48": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "48",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 80,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_1_step_1544": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "1544",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 40,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_3_step_48": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "48",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 160,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_2_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 80,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_3_step_15440": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "15440",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 160,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_5_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 640,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15/trainer_4": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 320,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15/trainer_3": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 160,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15/trainer_2": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 80,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15/trainer_5": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 640,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15/trainer_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 20,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15/trainer_1": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 40,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3/trainer_4": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 320,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3/trainer_3": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 160,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3/trainer_2": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 80,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3/trainer_5": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 640,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3/trainer_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 20,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3/trainer_1": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": 48828,
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 40,
                "device": "cuda:0",
                "layer": 3,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_3",
                "submodule_name": "resid_post_layer_3"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 32,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_0_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 20,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_0_step_15440": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "15440",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 20,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_3_step_154": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "154",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 160,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_2_step_154": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "154",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 80,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_2_step_1544": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "1544",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 80,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_1_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 40,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_3_step_488": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "488",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 160,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_2_step_488": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "488",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 80,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_2_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 80,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_5_step_15440": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "15440",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 640,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_4_step_1544": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "1544",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 320,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_4_step_488": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "488",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 320,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_5_step_488": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "488",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 640,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_5_step_48": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "48",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 640,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_2_step_15440": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "15440",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 80,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_3_step_1544": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "1544",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 160,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_0_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 20,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_4_step_154": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "154",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 320,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_5_step_154": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "154",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 640,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_4_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 320,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_4_step_48": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "48",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 320,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_5_step_1544": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "1544",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 640,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_1_step_48": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "48",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 40,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_5_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 640,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_4_step_15440": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "15440",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 320,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_0_step_488": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "488",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 20,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_1_step_488": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "488",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 40,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_1_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 40,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_0_step_1544": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "1544",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 20,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_1_step_15440": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "15440",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 40,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_3_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 160,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_3_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 160,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_0_step_48": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "48",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 20,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_0_step_154": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "154",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 20,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_1_step_154": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "154",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 40,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_4_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 320,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_2_step_48": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "48",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 80,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_1_step_1544": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "1544",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 40,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_3_step_48": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "48",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 160,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_2_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 80,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_3_step_15440": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "15440",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 160,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_5_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 640,
                "device": "cuda:0",
                "layer": 15,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_15",
                "submodule_name": "resid_post_layer_15"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_0_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 20,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_0_step_15440": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "15440",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 20,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_3_step_154": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "154",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 160,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_2_step_154": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "154",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 80,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_2_step_1544": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "1544",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 80,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_1_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 40,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_3_step_488": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "488",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 160,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_2_step_488": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "488",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 80,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_2_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 80,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_5_step_15440": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "15440",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 640,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_4_step_1544": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "1544",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 320,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_4_step_488": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "488",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 320,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_5_step_488": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "488",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 640,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_5_step_48": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "48",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 640,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_2_step_15440": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "15440",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 80,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_3_step_1544": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "1544",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 160,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_0_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 20,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_4_step_154": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "154",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 320,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_5_step_154": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "154",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 640,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_4_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 320,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_4_step_48": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "48",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 320,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_5_step_1544": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "1544",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 640,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_1_step_48": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "48",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 40,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_5_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 640,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_4_step_15440": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "15440",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 320,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_0_step_488": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "488",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 20,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_1_step_488": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "488",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 40,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_1_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 40,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_0_step_1544": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "1544",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 20,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_1_step_15440": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "15440",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 40,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_3_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 160,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_3_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 160,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_0_step_48": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "48",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 20,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_0_step_154": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "154",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 20,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_1_step_154": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "154",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 40,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_4_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 320,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_2_step_48": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "48",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 80,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_1_step_1544": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "1544",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 40,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_3_step_48": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "48",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 160,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_2_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 80,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_3_step_15440": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "15440",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 160,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_5_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 640,
                "device": "cuda:0",
                "layer": 7,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_7",
                "submodule_name": "resid_post_layer_7"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_0_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 20,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_0_step_15440": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "15440",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 20,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_3_step_154": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "154",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 160,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_2_step_154": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "154",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 80,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_2_step_1544": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "1544",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 80,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_1_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 40,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_3_step_488": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "488",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 160,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_2_step_488": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "488",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 80,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_2_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 80,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_5_step_15440": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "15440",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 640,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_4_step_1544": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "1544",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 320,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_4_step_488": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "488",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 320,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_5_step_488": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "488",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 640,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_5_step_48": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "48",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 640,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_2_step_15440": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "15440",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 80,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_3_step_1544": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "1544",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 160,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_0_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 20,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_4_step_154": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "154",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 320,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_5_step_154": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "154",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 640,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_4_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 320,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_4_step_48": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "48",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 320,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_5_step_1544": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "1544",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 640,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_1_step_48": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "48",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 40,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_5_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 640,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_4_step_15440": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "15440",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 320,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_0_step_488": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "488",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 20,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_1_step_488": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "488",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 40,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_1_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 40,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_0_step_1544": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "1544",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 20,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_1_step_15440": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "15440",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 40,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_3_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 160,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_3_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 160,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_0_step_48": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "48",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 20,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_0_step_154": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "154",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 20,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_1_step_154": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "154",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 40,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_4_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 320,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_2_step_48": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "48",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 80,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_1_step_1544": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "1544",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 40,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_3_step_48": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "48",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 160,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_2_step_4882": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "4882",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 80,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_3_step_15440": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "15440",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 160,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_5_step_0": {
            "trainer": {
                "trainer_class": "TrainerTopK",
                "dict_class": "AutoEncoderTopK",
                "lr": 0.0001885618083164127,
                "steps": "0",
                "seed": 0,
                "activation_dim": 2304,
                "dict_size": 18432,
                "k": 640,
                "device": "cuda:0",
                "layer": 19,
                "lm_name": "google/gemma-2-2b",
                "wandb_name": "TopKTrainer-google/gemma-2-2b-resid_post_layer_19",
                "submodule_name": "resid_post_layer_19"
            },
            "buffer": {
                "d_submodule": 2304,
                "io": "out",
                "n_ctxs": 2000,
                "ctx_len": 128,
                "refresh_batch_size": 24,
                "out_batch_size": 4096,
                "device": "cuda:0"
            }
        }
    },
    "basic_eval_results": {
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19/trainer_4": {
            "l2_loss": 78.99913330078125,
            "l1_loss": 2518.846826171875,
            "l0": 320.0,
            "frac_variance_explained": 0.8984488129615784,
            "cossim": 0.9610357165336609,
            "l2_ratio": 0.96125727891922,
            "relative_reconstruction_bias": 1.000020968914032,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 2.51603102684021,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9933296144008636,
            "frac_alive": 0.7503255009651184,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19/trainer_3": {
            "l2_loss": 90.80431671142578,
            "l1_loss": 1587.93564453125,
            "l0": 160.0,
            "frac_variance_explained": 0.8658691287040711,
            "cossim": 0.9485506474971771,
            "l2_ratio": 0.9495301187038422,
            "relative_reconstruction_bias": 1.0008091807365418,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 2.550182414054871,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9899285018444062,
            "frac_alive": 0.6395399570465088,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19/trainer_2": {
            "l2_loss": 98.38441390991211,
            "l1_loss": 1133.5070922851562,
            "l0": 80.0,
            "frac_variance_explained": 0.8572348475456237,
            "cossim": 0.9394023716449738,
            "l2_ratio": 0.9390686810016632,
            "relative_reconstruction_bias": 1.0001055598258972,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 2.5952465295791627,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9854330003261567,
            "frac_alive": 0.4769965410232544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19/trainer_5": {
            "l2_loss": 65.1626049041748,
            "l1_loss": 4910.604833984375,
            "l0": 640.0,
            "frac_variance_explained": 0.9424506366252899,
            "cossim": 0.9730470478534698,
            "l2_ratio": 0.9734025001525879,
            "relative_reconstruction_bias": 0.9997419714927673,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 2.4924126625061036,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9956821620464325,
            "frac_alive": 0.7953559160232544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19/trainer_0": {
            "l2_loss": 125.56976852416992,
            "l1_loss": 637.6160888671875,
            "l0": 20.0,
            "frac_variance_explained": 0.7849961221218109,
            "cossim": 0.8981874704360961,
            "l2_ratio": 0.8985657155513763,
            "relative_reconstruction_bias": 0.9984611392021179,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 2.8372591972351073,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9612571775913239,
            "frac_alive": 0.1710612028837204,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19/trainer_1": {
            "l2_loss": 110.1037582397461,
            "l1_loss": 789.6739196777344,
            "l0": 40.0,
            "frac_variance_explained": 0.7854969263076782,
            "cossim": 0.9232691109180451,
            "l2_ratio": 0.9242902994155884,
            "relative_reconstruction_bias": 1.0012201130390168,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 2.6683587312698362,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9781295597553253,
            "frac_alive": 0.3113064169883728,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11/trainer_4": {
            "l2_loss": 40.02006721496582,
            "l1_loss": 1198.095361328125,
            "l0": 319.93333435058594,
            "frac_variance_explained": 0.9105471670627594,
            "cossim": 0.9585575938224793,
            "l2_ratio": 0.9586278080940247,
            "relative_reconstruction_bias": 0.9996210753917694,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 2.486758494377136,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9962394773960114,
            "frac_alive": 0.6825087070465088,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11/trainer_3": {
            "l2_loss": 45.96233024597168,
            "l1_loss": 756.8620727539062,
            "l0": 160.0,
            "frac_variance_explained": 0.8569788098335266,
            "cossim": 0.9457451581954956,
            "l2_ratio": 0.9459684491157532,
            "relative_reconstruction_bias": 1.0003461122512818,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 2.510911059379578,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9938320398330689,
            "frac_alive": 0.6036784052848816,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11/trainer_2": {
            "l2_loss": 51.766046142578126,
            "l1_loss": 551.8687042236328,
            "l0": 79.95416717529297,
            "frac_variance_explained": 0.8506697595119477,
            "cossim": 0.9300514996051789,
            "l2_ratio": 0.9307749271392822,
            "relative_reconstruction_bias": 1.0002500534057617,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 2.546255683898926,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9903075456619262,
            "frac_alive": 0.4618598222732544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11/trainer_5": {
            "l2_loss": 32.957839012145996,
            "l1_loss": 2571.5229736328124,
            "l0": 640.0,
            "frac_variance_explained": 0.9456270158290863,
            "cossim": 0.9722206771373749,
            "l2_ratio": 0.9717293500900268,
            "relative_reconstruction_bias": 0.9989768981933593,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 2.4674513578414916,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.998158472776413,
            "frac_alive": 0.6299370527267456,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11/trainer_0": {
            "l2_loss": 64.61817817687988,
            "l1_loss": 282.2537475585938,
            "l0": 20.0,
            "frac_variance_explained": 0.737516725063324,
            "cossim": 0.8891037285327912,
            "l2_ratio": 0.8893811702728271,
            "relative_reconstruction_bias": 1.000152826309204,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 2.7688143968582155,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9680845320224762,
            "frac_alive": 0.1599934846162796,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11/trainer_1": {
            "l2_loss": 55.950561141967775,
            "l1_loss": 401.8522033691406,
            "l0": 40.0,
            "frac_variance_explained": 0.8127304315567017,
            "cossim": 0.9176948845386506,
            "l2_ratio": 0.9174629509449005,
            "relative_reconstruction_bias": 0.999979829788208,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 2.6059114217758177,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9843562066555023,
            "frac_alive": 0.3069118857383728,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7/trainer_4": {
            "l2_loss": 25.603483200073242,
            "l1_loss": 887.8896789550781,
            "l0": 320.0,
            "frac_variance_explained": 0.9075254380702973,
            "cossim": 0.9665767192840576,
            "l2_ratio": 0.966665506362915,
            "relative_reconstruction_bias": 1.000228750705719,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 2.477691173553467,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9971450984477996,
            "frac_alive": 0.6903212070465088,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7/trainer_3": {
            "l2_loss": 31.11774444580078,
            "l1_loss": 587.7058166503906,
            "l0": 160.0,
            "frac_variance_explained": 0.8864160597324371,
            "cossim": 0.9515470147132874,
            "l2_ratio": 0.9520631015300751,
            "relative_reconstruction_bias": 1.0004171848297119,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 2.4948626518249513,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9954373061656951,
            "frac_alive": 0.6174045205116272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7/trainer_2": {
            "l2_loss": 32.920125007629395,
            "l1_loss": 377.2314727783203,
            "l0": 80.0,
            "frac_variance_explained": 0.8427301347255707,
            "cossim": 0.9465734004974365,
            "l2_ratio": 0.9462980151176452,
            "relative_reconstruction_bias": 0.999693489074707,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 2.5190592050552367,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9930278241634369,
            "frac_alive": 0.4312608540058136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7/trainer_5": {
            "l2_loss": 21.750783348083495,
            "l1_loss": 2076.0646728515626,
            "l0": 640.0,
            "frac_variance_explained": 0.9398650825023651,
            "cossim": 0.9774176478385925,
            "l2_ratio": 0.9777889370918273,
            "relative_reconstruction_bias": 1.0005208492279052,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 2.461538004875183,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9987489283084869,
            "frac_alive": 0.7127278447151184,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7/trainer_0": {
            "l2_loss": 39.385193252563475,
            "l1_loss": 269.69310150146487,
            "l0": 20.0,
            "frac_variance_explained": 0.8598198533058167,
            "cossim": 0.9176318526268006,
            "l2_ratio": 0.9170765697956085,
            "relative_reconstruction_bias": 0.999529504776001,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 2.638276529312134,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9811272025108337,
            "frac_alive": 0.1595594584941864,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7/trainer_1": {
            "l2_loss": 35.6403621673584,
            "l1_loss": 266.82349090576173,
            "l0": 40.0,
            "frac_variance_explained": 0.8049931645393371,
            "cossim": 0.93520388007164,
            "l2_ratio": 0.9352702856063843,
            "relative_reconstruction_bias": 1.0001867175102235,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 2.551988196372986,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9897454440593719,
            "frac_alive": 0.284722238779068,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_0_step_0": {
            "l2_loss": 137.7,
            "l1_loss": 110.15,
            "l0": 20.0,
            "frac_variance_explained": 0.06328125,
            "cossim": 0.2876953125,
            "l2_ratio": 0.1814453125,
            "relative_reconstruction_bias": 0.630078125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 11.407014656066895,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.10465058535337449,
            "frac_alive": 0.138454869389534,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_0_step_15440": {
            "l2_loss": 65.425,
            "l1_loss": 311.0,
            "l0": 20.0,
            "frac_variance_explained": 0.758984375,
            "cossim": 0.8875,
            "l2_ratio": 0.890234375,
            "relative_reconstruction_bias": 1.00078125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.7933643102645873,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9648277342319489,
            "frac_alive": 0.157009556889534,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_3_step_154": {
            "l2_loss": 69.05,
            "l1_loss": 742.0,
            "l0": 160.0,
            "frac_variance_explained": 0.65234375,
            "cossim": 0.875390625,
            "l2_ratio": 0.885546875,
            "relative_reconstruction_bias": 1.0046875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.9694986820220945,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9471549808979034,
            "frac_alive": 0.7988823652267456,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_2_step_154": {
            "l2_loss": 78.3,
            "l1_loss": 554.4,
            "l0": 80.0,
            "frac_variance_explained": 0.56953125,
            "cossim": 0.839453125,
            "l2_ratio": 0.851953125,
            "relative_reconstruction_bias": 1.0046875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 3.426113796234131,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9015444159507752,
            "frac_alive": 0.5124782919883728,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_2_step_1544": {
            "l2_loss": 61.05,
            "l1_loss": 524.6,
            "l0": 80.0,
            "frac_variance_explained": 0.731640625,
            "cossim": 0.9046875,
            "l2_ratio": 0.9078125,
            "relative_reconstruction_bias": 1.0046875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.71366970539093,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9728043735027313,
            "frac_alive": 0.49365234375,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_1_step_4882": {
            "l2_loss": 61.075,
            "l1_loss": 350.0,
            "l0": 40.0,
            "frac_variance_explained": 0.703125,
            "cossim": 0.901171875,
            "l2_ratio": 0.901953125,
            "relative_reconstruction_bias": 1.000390625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.661836934089661,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9779623448848724,
            "frac_alive": 0.2948133647441864,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_3_step_488": {
            "l2_loss": 62.9,
            "l1_loss": 682.8,
            "l0": 160.0,
            "frac_variance_explained": 0.7109375,
            "cossim": 0.895703125,
            "l2_ratio": 0.90078125,
            "relative_reconstruction_bias": 1.00390625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.732248306274414,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9709289193153381,
            "frac_alive": 0.7855360507965088,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_2_step_488": {
            "l2_loss": 69.125,
            "l1_loss": 497.8,
            "l0": 80.0,
            "frac_variance_explained": 0.642578125,
            "cossim": 0.873046875,
            "l2_ratio": 0.87734375,
            "relative_reconstruction_bias": 1.004296875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 3.0880523681640626,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9353146016597748,
            "frac_alive": 0.5100911259651184,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_2_step_0": {
            "l2_loss": 133.8,
            "l1_loss": 406.6,
            "l0": 80.0,
            "frac_variance_explained": 0.173828125,
            "cossim": 0.4671875,
            "l2_ratio": 0.3470703125,
            "relative_reconstruction_bias": 0.741796875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 9.577101516723634,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.2874674767255783,
            "frac_alive": 0.314019113779068,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_5_step_15440": {
            "l2_loss": 35.1625,
            "l1_loss": 2229.6,
            "l0": 639.75,
            "frac_variance_explained": 0.9109375,
            "cossim": 0.968359375,
            "l2_ratio": 0.96875,
            "relative_reconstruction_bias": 1.00078125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.461870551109314,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9978919506072998,
            "frac_alive": 0.6906467080116272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_4_step_1544": {
            "l2_loss": 52.55,
            "l1_loss": 1030.4,
            "l0": 320.0,
            "frac_variance_explained": 0.819921875,
            "cossim": 0.93203125,
            "l2_ratio": 0.93359375,
            "relative_reconstruction_bias": 1.00234375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.532721424102783,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9908467590808868,
            "frac_alive": 0.9549153447151184,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_4_step_488": {
            "l2_loss": 57.4,
            "l1_loss": 1006.4,
            "l0": 320.0,
            "frac_variance_explained": 0.768359375,
            "cossim": 0.9140625,
            "l2_ratio": 0.9203125,
            "relative_reconstruction_bias": 1.005078125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.636249876022339,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.98048534989357,
            "frac_alive": 0.9611002802848816,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_5_step_488": {
            "l2_loss": 49.825,
            "l1_loss": 1537.6,
            "l0": 640.0,
            "frac_variance_explained": 0.8578125,
            "cossim": 0.9359375,
            "l2_ratio": 0.941015625,
            "relative_reconstruction_bias": 1.00390625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.5238553285598755,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9917183816432953,
            "frac_alive": 0.9885525107383728,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_5_step_48": {
            "l2_loss": 63.85,
            "l1_loss": 1591.2,
            "l0": 640.0,
            "frac_variance_explained": 0.71484375,
            "cossim": 0.903125,
            "l2_ratio": 0.9171875,
            "relative_reconstruction_bias": 1.00625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.5837015867233277,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9857530713081359,
            "frac_alive": 0.9968532919883728,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_2_step_15440": {
            "l2_loss": 54.2,
            "l1_loss": 536.8,
            "l0": 80.0,
            "frac_variance_explained": 0.803125,
            "cossim": 0.925390625,
            "l2_ratio": 0.926171875,
            "relative_reconstruction_bias": 1.003125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.552223062515259,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9888993203639984,
            "frac_alive": 0.4521484375,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_3_step_1544": {
            "l2_loss": 59.575,
            "l1_loss": 769.6,
            "l0": 160.0,
            "frac_variance_explained": 0.788671875,
            "cossim": 0.91484375,
            "l2_ratio": 0.916796875,
            "relative_reconstruction_bias": 1.003125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.621287798881531,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9820147037506104,
            "frac_alive": 0.76953125,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_0_step_4882": {
            "l2_loss": 66.1,
            "l1_loss": 277.0,
            "l0": 20.0,
            "frac_variance_explained": 0.680859375,
            "cossim": 0.8859375,
            "l2_ratio": 0.888671875,
            "relative_reconstruction_bias": 1.00390625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.888194966316223,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9553665339946746,
            "frac_alive": 0.1568467915058136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_4_step_154": {
            "l2_loss": 63.15,
            "l1_loss": 1169.2,
            "l0": 320.0,
            "frac_variance_explained": 0.741015625,
            "cossim": 0.901953125,
            "l2_ratio": 0.903515625,
            "relative_reconstruction_bias": 0.996484375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.703572392463684,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.973752784729004,
            "frac_alive": 0.9632161259651184,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_5_step_154": {
            "l2_loss": 53.375,
            "l1_loss": 1479.2,
            "l0": 640.0,
            "frac_variance_explained": 0.8,
            "cossim": 0.926171875,
            "l2_ratio": 0.9328125,
            "relative_reconstruction_bias": 1.00390625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.5543439626693725,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9886787116527558,
            "frac_alive": 0.9983723759651184,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_4_step_0": {
            "l2_loss": 110.65,
            "l1_loss": 1370.4,
            "l0": 320.0,
            "frac_variance_explained": 0.345703125,
            "cossim": 0.668359375,
            "l2_ratio": 0.708203125,
            "relative_reconstruction_bias": 1.05546875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 3.5167050123214723,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.8926664888858795,
            "frac_alive": 0.5868598222732544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_4_step_48": {
            "l2_loss": 71.75,
            "l1_loss": 1098.4,
            "l0": 320.0,
            "frac_variance_explained": 0.61484375,
            "cossim": 0.869921875,
            "l2_ratio": 0.882421875,
            "relative_reconstruction_bias": 0.998828125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.7715730905532836,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9669955611228943,
            "frac_alive": 0.9564344882965088,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_5_step_1544": {
            "l2_loss": 43.325,
            "l1_loss": 1506.4,
            "l0": 640.0,
            "frac_variance_explained": 0.870703125,
            "cossim": 0.953125,
            "l2_ratio": 0.95625,
            "relative_reconstruction_bias": 1.003125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.484053874015808,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9956881284713746,
            "frac_alive": 0.9110243320465088,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_1_step_48": {
            "l2_loss": 108.0,
            "l1_loss": 338.6,
            "l0": 40.0,
            "frac_variance_explained": 0.305078125,
            "cossim": 0.733203125,
            "l2_ratio": 0.73984375,
            "relative_reconstruction_bias": 0.8953125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 5.098966073989868,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.7346842169761658,
            "frac_alive": 0.33349609375,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_5_step_4882": {
            "l2_loss": 37.8,
            "l1_loss": 1916.0,
            "l0": 639.725,
            "frac_variance_explained": 0.893359375,
            "cossim": 0.962109375,
            "l2_ratio": 0.964453125,
            "relative_reconstruction_bias": 1.003125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.4669814586639403,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9973848223686218,
            "frac_alive": 0.8089192509651184,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_4_step_15440": {
            "l2_loss": 42.125,
            "l1_loss": 1068.0,
            "l0": 320.0,
            "frac_variance_explained": 0.86484375,
            "cossim": 0.952734375,
            "l2_ratio": 0.953125,
            "relative_reconstruction_bias": 1.0015625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.485049676895142,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9955863654613495,
            "frac_alive": 0.729600727558136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_0_step_488": {
            "l2_loss": 73.85,
            "l1_loss": 262.3,
            "l0": 20.0,
            "frac_variance_explained": 0.6015625,
            "cossim": 0.857421875,
            "l2_ratio": 0.85625,
            "relative_reconstruction_bias": 0.996875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 3.600706672668457,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.884125429391861,
            "frac_alive": 0.131618931889534,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_1_step_488": {
            "l2_loss": 69.6,
            "l1_loss": 384.6,
            "l0": 40.0,
            "frac_variance_explained": 0.665625,
            "cossim": 0.872265625,
            "l2_ratio": 0.8796875,
            "relative_reconstruction_bias": 1.0078125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 3.157698321342468,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9283924698829651,
            "frac_alive": 0.2635633647441864,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_1_step_0": {
            "l2_loss": 142.2,
            "l1_loss": 218.0,
            "l0": 40.0,
            "frac_variance_explained": 0.10546875,
            "cossim": 0.36953125,
            "l2_ratio": 0.2482421875,
            "relative_reconstruction_bias": 0.669921875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 10.688310146331787,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.1763722062110901,
            "frac_alive": 0.212185338139534,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_0_step_1544": {
            "l2_loss": 70.4,
            "l1_loss": 267.2,
            "l0": 20.0,
            "frac_variance_explained": 0.633984375,
            "cossim": 0.871484375,
            "l2_ratio": 0.87109375,
            "relative_reconstruction_bias": 1.0,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 3.1963499784469604,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9245945453643799,
            "frac_alive": 0.1436631977558136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_1_step_15440": {
            "l2_loss": 58.45,
            "l1_loss": 394.2,
            "l0": 40.0,
            "frac_variance_explained": 0.780078125,
            "cossim": 0.909375,
            "l2_ratio": 0.911328125,
            "relative_reconstruction_bias": 1.00234375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.612251806259155,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9829114198684692,
            "frac_alive": 0.29541015625,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_3_step_4882": {
            "l2_loss": 50.275,
            "l1_loss": 738.8,
            "l0": 160.0,
            "frac_variance_explained": 0.847265625,
            "cossim": 0.93203125,
            "l2_ratio": 0.9328125,
            "relative_reconstruction_bias": 1.001171875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.529589533805847,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9911516010761261,
            "frac_alive": 0.6820746660232544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_3_step_0": {
            "l2_loss": 121.8,
            "l1_loss": 744.8,
            "l0": 160.0,
            "frac_variance_explained": 0.2640625,
            "cossim": 0.56953125,
            "l2_ratio": 0.4927734375,
            "relative_reconstruction_bias": 0.8609375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 6.267248868942261,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.6180142462253571,
            "frac_alive": 0.4386935830116272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_0_step_48": {
            "l2_loss": 105.15,
            "l1_loss": 179.8,
            "l0": 20.0,
            "frac_variance_explained": 0.18828125,
            "cossim": 0.692578125,
            "l2_ratio": 0.716015625,
            "relative_reconstruction_bias": 0.9984375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 6.1452779293060305,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.6302249014377594,
            "frac_alive": 0.1695421040058136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_0_step_154": {
            "l2_loss": 93.55,
            "l1_loss": 238.6,
            "l0": 20.0,
            "frac_variance_explained": 0.334375,
            "cossim": 0.755078125,
            "l2_ratio": 0.79140625,
            "relative_reconstruction_bias": 1.01484375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 4.918577527999878,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.7525505006313324,
            "frac_alive": 0.1292317658662796,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_1_step_154": {
            "l2_loss": 87.2,
            "l1_loss": 379.6,
            "l0": 40.0,
            "frac_variance_explained": 0.449609375,
            "cossim": 0.7953125,
            "l2_ratio": 0.8234375,
            "relative_reconstruction_bias": 1.015625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 4.139649343490601,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.830296915769577,
            "frac_alive": 0.2669813334941864,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_4_step_4882": {
            "l2_loss": 45.6,
            "l1_loss": 1004.0,
            "l0": 319.99583435058594,
            "frac_variance_explained": 0.86640625,
            "cossim": 0.944921875,
            "l2_ratio": 0.947265625,
            "relative_reconstruction_bias": 0.99921875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.4963902711868284,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9944567561149598,
            "frac_alive": 0.8498806357383728,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_2_step_48": {
            "l2_loss": 91.75,
            "l1_loss": 515.4,
            "l0": 80.0,
            "frac_variance_explained": 0.414453125,
            "cossim": 0.773828125,
            "l2_ratio": 0.78984375,
            "relative_reconstruction_bias": 0.96953125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 4.03226523399353,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.841141802072525,
            "frac_alive": 0.5571831464767456,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_1_step_1544": {
            "l2_loss": 65.55,
            "l1_loss": 343.8,
            "l0": 40.0,
            "frac_variance_explained": 0.665625,
            "cossim": 0.88984375,
            "l2_ratio": 0.888671875,
            "relative_reconstruction_bias": 0.998046875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.863617014884949,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9578355431556702,
            "frac_alive": 0.2782118022441864,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_3_step_48": {
            "l2_loss": 81.95,
            "l1_loss": 813.6,
            "l0": 160.0,
            "frac_variance_explained": 0.5359375,
            "cossim": 0.825390625,
            "l2_ratio": 0.8390625,
            "relative_reconstruction_bias": 1.000390625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 3.210920238494873,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9230841159820556,
            "frac_alive": 0.7958441972732544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_2_step_4882": {
            "l2_loss": 54.45,
            "l1_loss": 593.0,
            "l0": 80.0,
            "frac_variance_explained": 0.847265625,
            "cossim": 0.921875,
            "l2_ratio": 0.923828125,
            "relative_reconstruction_bias": 1.0015625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.5707311153411867,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9870538175106048,
            "frac_alive": 0.4774305522441864,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_3_step_15440": {
            "l2_loss": 48.3,
            "l1_loss": 731.6,
            "l0": 160.0,
            "frac_variance_explained": 0.833203125,
            "cossim": 0.93984375,
            "l2_ratio": 0.9390625,
            "relative_reconstruction_bias": 0.9984375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.512040066719055,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9929002702236176,
            "frac_alive": 0.6171332597732544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_11_checkpoints/trainer_5_step_0": {
            "l2_loss": 107.0,
            "l1_loss": 2512.0,
            "l0": 640.0,
            "frac_variance_explained": 0.3421875,
            "cossim": 0.755078125,
            "l2_ratio": 1.0265625,
            "relative_reconstruction_bias": 1.353125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.8607425451278687,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9581126570701599,
            "frac_alive": 0.7616645097732544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_0_step_0": {
            "l2_loss": 79.4,
            "l1_loss": 65.425,
            "l0": 20.0,
            "frac_variance_explained": 0.06796875,
            "cossim": 0.2947265625,
            "l2_ratio": 0.1853515625,
            "relative_reconstruction_bias": 0.629296875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 9.95833683013916,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.24916650652885436,
            "frac_alive": 0.1384006142616272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_0_step_15440": {
            "l2_loss": 31.0,
            "l1_loss": 169.7,
            "l0": 20.0,
            "frac_variance_explained": 0.769140625,
            "cossim": 0.922265625,
            "l2_ratio": 0.921484375,
            "relative_reconstruction_bias": 1.0,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.6113957166671753,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9829996824264526,
            "frac_alive": 0.1534288227558136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_3_step_154": {
            "l2_loss": 37.45,
            "l1_loss": 440.6,
            "l0": 160.0,
            "frac_variance_explained": 0.683203125,
            "cossim": 0.8890625,
            "l2_ratio": 0.891015625,
            "relative_reconstruction_bias": 1.001953125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.6913110494613646,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9750205039978027,
            "frac_alive": 0.8249782919883728,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_2_step_154": {
            "l2_loss": 42.55,
            "l1_loss": 327.0,
            "l0": 80.0,
            "frac_variance_explained": 0.584765625,
            "cossim": 0.846875,
            "l2_ratio": 0.853125,
            "relative_reconstruction_bias": 1.00703125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.971432828903198,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.947002649307251,
            "frac_alive": 0.567491352558136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_2_step_1544": {
            "l2_loss": 30.8,
            "l1_loss": 301.8,
            "l0": 80.0,
            "frac_variance_explained": 0.76015625,
            "cossim": 0.919140625,
            "l2_ratio": 0.91875,
            "relative_reconstruction_bias": 1.00078125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.6169229984283446,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9824475586414337,
            "frac_alive": 0.5130751132965088,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_1_step_4882": {
            "l2_loss": 31.3375,
            "l1_loss": 231.9,
            "l0": 40.0,
            "frac_variance_explained": 0.759765625,
            "cossim": 0.91640625,
            "l2_ratio": 0.915625,
            "relative_reconstruction_bias": 1.001953125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.598768639564514,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9842611491680145,
            "frac_alive": 0.2821180522441864,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_3_step_488": {
            "l2_loss": 33.9125,
            "l1_loss": 411.6,
            "l0": 160.0,
            "frac_variance_explained": 0.73359375,
            "cossim": 0.90625,
            "l2_ratio": 0.909375,
            "relative_reconstruction_bias": 1.001171875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.601050686836243,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9840281367301941,
            "frac_alive": 0.8039821982383728,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_2_step_488": {
            "l2_loss": 32.75,
            "l1_loss": 343.0,
            "l0": 80.0,
            "frac_variance_explained": 0.7734375,
            "cossim": 0.908203125,
            "l2_ratio": 0.910546875,
            "relative_reconstruction_bias": 1.00078125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.6711817026138305,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9770391523838043,
            "frac_alive": 0.5460612177848816,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_2_step_0": {
            "l2_loss": 73.0,
            "l1_loss": 231.3,
            "l0": 80.0,
            "frac_variance_explained": 0.187109375,
            "cossim": 0.479296875,
            "l2_ratio": 0.35859375,
            "relative_reconstruction_bias": 0.7484375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 8.026517772674561,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.4421375274658203,
            "frac_alive": 0.3435872495174408,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_5_step_15440": {
            "l2_loss": 19.8,
            "l1_loss": 1300.0,
            "l0": 640.0,
            "frac_variance_explained": 0.901953125,
            "cossim": 0.967578125,
            "l2_ratio": 0.970703125,
            "relative_reconstruction_bias": 1.00703125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.471339964866638,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9969493508338928,
            "frac_alive": 0.9496527910232544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_4_step_1544": {
            "l2_loss": 27.6375,
            "l1_loss": 573.6,
            "l0": 320.0,
            "frac_variance_explained": 0.819140625,
            "cossim": 0.9390625,
            "l2_ratio": 0.940625,
            "relative_reconstruction_bias": 1.001953125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.523586940765381,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9917560160160065,
            "frac_alive": 0.9573025107383728,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_4_step_488": {
            "l2_loss": 29.2875,
            "l1_loss": 554.4,
            "l0": 320.0,
            "frac_variance_explained": 0.789453125,
            "cossim": 0.9296875,
            "l2_ratio": 0.93046875,
            "relative_reconstruction_bias": 1.00234375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.541101813316345,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9900118887424469,
            "frac_alive": 0.9561089277267456,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_5_step_488": {
            "l2_loss": 26.05,
            "l1_loss": 777.2,
            "l0": 640.0,
            "frac_variance_explained": 0.834765625,
            "cossim": 0.94453125,
            "l2_ratio": 0.945703125,
            "relative_reconstruction_bias": 1.0015625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.498408341407776,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9942609667778015,
            "frac_alive": 0.9962565302848816,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_5_step_48": {
            "l2_loss": 34.875,
            "l1_loss": 978.4,
            "l0": 640.0,
            "frac_variance_explained": 0.751953125,
            "cossim": 0.905859375,
            "l2_ratio": 0.91875,
            "relative_reconstruction_bias": 1.008203125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.5359509944915772,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9905226826667786,
            "frac_alive": 0.999131977558136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_2_step_15440": {
            "l2_loss": 27.85,
            "l1_loss": 344.2,
            "l0": 80.0,
            "frac_variance_explained": 0.8296875,
            "cossim": 0.9359375,
            "l2_ratio": 0.936328125,
            "relative_reconstruction_bias": 1.0015625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.548701548576355,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.989256089925766,
            "frac_alive": 0.440972238779068,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_3_step_1544": {
            "l2_loss": 28.8625,
            "l1_loss": 401.2,
            "l0": 160.0,
            "frac_variance_explained": 0.79453125,
            "cossim": 0.93125,
            "l2_ratio": 0.932421875,
            "relative_reconstruction_bias": 1.002734375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.563430070877075,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9877831339836121,
            "frac_alive": 0.7734917402267456,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_0_step_4882": {
            "l2_loss": 32.125,
            "l1_loss": 168.2,
            "l0": 20.0,
            "frac_variance_explained": 0.740234375,
            "cossim": 0.912109375,
            "l2_ratio": 0.9125,
            "relative_reconstruction_bias": 1.00078125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.6347166299819946,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.980675333738327,
            "frac_alive": 0.1606987863779068,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_4_step_154": {
            "l2_loss": 34.3875,
            "l1_loss": 615.6,
            "l0": 320.0,
            "frac_variance_explained": 0.73984375,
            "cossim": 0.9109375,
            "l2_ratio": 0.913671875,
            "relative_reconstruction_bias": 1.001171875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.5712565898895265,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9870066344738007,
            "frac_alive": 0.9637044072151184,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_5_step_154": {
            "l2_loss": 28.725,
            "l1_loss": 854.0,
            "l0": 640.0,
            "frac_variance_explained": 0.807421875,
            "cossim": 0.932421875,
            "l2_ratio": 0.937109375,
            "relative_reconstruction_bias": 1.00703125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.511625289916992,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.992942887544632,
            "frac_alive": 0.9987521767616272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_4_step_0": {
            "l2_loss": 61.1,
            "l1_loss": 789.6,
            "l0": 320.0,
            "frac_variance_explained": 0.374609375,
            "cossim": 0.6796875,
            "l2_ratio": 0.730078125,
            "relative_reconstruction_bias": 1.07421875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 3.4105432748794557,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9031490743160248,
            "frac_alive": 0.650987446308136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_4_step_48": {
            "l2_loss": 40.375,
            "l1_loss": 672.4,
            "l0": 320.0,
            "frac_variance_explained": 0.63828125,
            "cossim": 0.86953125,
            "l2_ratio": 0.87734375,
            "relative_reconstruction_bias": 1.003125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.6309582233428954,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9810457110404969,
            "frac_alive": 0.9631618857383728,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_5_step_1544": {
            "l2_loss": 24.175,
            "l1_loss": 838.4,
            "l0": 640.0,
            "frac_variance_explained": 0.86953125,
            "cossim": 0.954296875,
            "l2_ratio": 0.95546875,
            "relative_reconstruction_bias": 1.003515625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.4867657661437987,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9954212665557861,
            "frac_alive": 0.996690571308136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_1_step_48": {
            "l2_loss": 56.8,
            "l1_loss": 205.9,
            "l0": 40.0,
            "frac_variance_explained": 0.31328125,
            "cossim": 0.731640625,
            "l2_ratio": 0.72265625,
            "relative_reconstruction_bias": 0.976171875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 4.934949207305908,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.7508984625339508,
            "frac_alive": 0.3238389790058136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_5_step_4882": {
            "l2_loss": 20.3,
            "l1_loss": 1007.2,
            "l0": 640.0,
            "frac_variance_explained": 0.89140625,
            "cossim": 0.965625,
            "l2_ratio": 0.967578125,
            "relative_reconstruction_bias": 1.001953125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.4793680906295776,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9961497604846954,
            "frac_alive": 0.966796875,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_4_step_15440": {
            "l2_loss": 21.825,
            "l1_loss": 732.4,
            "l0": 320.0,
            "frac_variance_explained": 0.882421875,
            "cossim": 0.961328125,
            "l2_ratio": 0.962890625,
            "relative_reconstruction_bias": 1.001953125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.493744659423828,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9947247564792633,
            "frac_alive": 0.8442925214767456,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_0_step_488": {
            "l2_loss": 35.7125,
            "l1_loss": 166.0,
            "l0": 20.0,
            "frac_variance_explained": 0.673046875,
            "cossim": 0.886328125,
            "l2_ratio": 0.891015625,
            "relative_reconstruction_bias": 1.009375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.839069890975952,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9602638244628906,
            "frac_alive": 0.153591588139534,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_1_step_488": {
            "l2_loss": 35.325,
            "l1_loss": 220.5,
            "l0": 40.0,
            "frac_variance_explained": 0.6875,
            "cossim": 0.8953125,
            "l2_ratio": 0.8984375,
            "relative_reconstruction_bias": 1.0046875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.729294180870056,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9712401390075683,
            "frac_alive": 0.3047960102558136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_1_step_0": {
            "l2_loss": 77.5,
            "l1_loss": 124.4,
            "l0": 40.0,
            "frac_variance_explained": 0.113671875,
            "cossim": 0.3802734375,
            "l2_ratio": 0.256640625,
            "relative_reconstruction_bias": 0.673828125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 9.318093872070312,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.3131313890218735,
            "frac_alive": 0.2225477397441864,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_0_step_1544": {
            "l2_loss": 33.775,
            "l1_loss": 163.3,
            "l0": 20.0,
            "frac_variance_explained": 0.705859375,
            "cossim": 0.898046875,
            "l2_ratio": 0.898046875,
            "relative_reconstruction_bias": 0.999609375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.718431806564331,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9723090648651123,
            "frac_alive": 0.1581488698720932,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_1_step_15440": {
            "l2_loss": 27.475,
            "l1_loss": 233.3,
            "l0": 40.0,
            "frac_variance_explained": 0.814453125,
            "cossim": 0.937890625,
            "l2_ratio": 0.93828125,
            "relative_reconstruction_bias": 1.00390625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.577351212501526,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9863953530788422,
            "frac_alive": 0.2570529580116272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_3_step_4882": {
            "l2_loss": 26.4125,
            "l1_loss": 436.8,
            "l0": 160.0,
            "frac_variance_explained": 0.826171875,
            "cossim": 0.943359375,
            "l2_ratio": 0.94296875,
            "relative_reconstruction_bias": 1.003125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.539991092681885,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9901264131069183,
            "frac_alive": 0.7169596552848816,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_3_step_0": {
            "l2_loss": 68.425,
            "l1_loss": 436.2,
            "l0": 160.0,
            "frac_variance_explained": 0.2875,
            "cossim": 0.5828125,
            "l2_ratio": 0.50859375,
            "relative_reconstruction_bias": 0.873828125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 5.794749927520752,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.6650312125682831,
            "frac_alive": 0.5022786259651184,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_0_step_48": {
            "l2_loss": 60.725,
            "l1_loss": 124.9,
            "l0": 20.0,
            "frac_variance_explained": 0.2296875,
            "cossim": 0.6859375,
            "l2_ratio": 0.669140625,
            "relative_reconstruction_bias": 0.962890625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 6.1103638172149655,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.6335384666919708,
            "frac_alive": 0.1831597238779068,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_0_step_154": {
            "l2_loss": 49.0,
            "l1_loss": 172.5,
            "l0": 20.0,
            "frac_variance_explained": 0.431640625,
            "cossim": 0.794140625,
            "l2_ratio": 0.797265625,
            "relative_reconstruction_bias": 0.99296875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 4.076321721076965,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.8366711139678955,
            "frac_alive": 0.1558702290058136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_1_step_154": {
            "l2_loss": 46.725,
            "l1_loss": 248.9,
            "l0": 40.0,
            "frac_variance_explained": 0.50703125,
            "cossim": 0.821484375,
            "l2_ratio": 0.827734375,
            "relative_reconstruction_bias": 1.000390625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 3.444863748550415,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.8997273623943329,
            "frac_alive": 0.3173828125,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_4_step_4882": {
            "l2_loss": 25.3875,
            "l1_loss": 607.6,
            "l0": 320.0,
            "frac_variance_explained": 0.844921875,
            "cossim": 0.946875,
            "l2_ratio": 0.95,
            "relative_reconstruction_bias": 1.005078125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.5037263154983522,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9937267541885376,
            "frac_alive": 0.9239909052848816,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_2_step_48": {
            "l2_loss": 51.725,
            "l1_loss": 316.8,
            "l0": 80.0,
            "frac_variance_explained": 0.413671875,
            "cossim": 0.77734375,
            "l2_ratio": 0.773828125,
            "relative_reconstruction_bias": 0.98515625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 3.7842599153518677,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.8658327519893646,
            "frac_alive": 0.5611979365348816,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_1_step_1544": {
            "l2_loss": 31.4625,
            "l1_loss": 234.0,
            "l0": 40.0,
            "frac_variance_explained": 0.76328125,
            "cossim": 0.913671875,
            "l2_ratio": 0.914453125,
            "relative_reconstruction_bias": 1.002734375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.668365216255188,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9773101389408112,
            "frac_alive": 0.3059353232383728,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_3_step_48": {
            "l2_loss": 47.925,
            "l1_loss": 479.8,
            "l0": 160.0,
            "frac_variance_explained": 0.519140625,
            "cossim": 0.81953125,
            "l2_ratio": 0.819140625,
            "relative_reconstruction_bias": 0.99296875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.9531614780426025,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9488685250282287,
            "frac_alive": 0.8244900107383728,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_2_step_4882": {
            "l2_loss": 29.3375,
            "l1_loss": 317.8,
            "l0": 80.0,
            "frac_variance_explained": 0.7875,
            "cossim": 0.929296875,
            "l2_ratio": 0.92890625,
            "relative_reconstruction_bias": 1.001953125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.5706660985946654,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9870666921138763,
            "frac_alive": 0.472222238779068,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_3_step_15440": {
            "l2_loss": 24.4125,
            "l1_loss": 459.0,
            "l0": 160.0,
            "frac_variance_explained": 0.8515625,
            "cossim": 0.951171875,
            "l2_ratio": 0.95390625,
            "relative_reconstruction_bias": 1.00625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.5208311319351195,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9920356631278991,
            "frac_alive": 0.640733540058136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3_checkpoints/trainer_5_step_0": {
            "l2_loss": 60.325,
            "l1_loss": 1440.0,
            "l0": 640.0,
            "frac_variance_explained": 0.397265625,
            "cossim": 0.76328125,
            "l2_ratio": 1.0546875,
            "relative_reconstruction_bias": 1.375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.742577600479126,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9698809325695038,
            "frac_alive": 0.83544921875,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15/trainer_4": {
            "l2_loss": 49.31732063293457,
            "l1_loss": 1596.6747680664062,
            "l0": 320.0,
            "frac_variance_explained": 0.9155429899692535,
            "cossim": 0.9657738864421844,
            "l2_ratio": 0.9659751355648041,
            "relative_reconstruction_bias": 0.9998931109905242,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 2.494556260108948,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9954632163047791,
            "frac_alive": 0.7400173544883728,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15/trainer_3": {
            "l2_loss": 56.946068572998044,
            "l1_loss": 1005.3937927246094,
            "l0": 160.0,
            "frac_variance_explained": 0.8639537990093231,
            "cossim": 0.9545037567615509,
            "l2_ratio": 0.9538737773895264,
            "relative_reconstruction_bias": 0.9995295643806458,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 2.524174451828003,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9925116181373597,
            "frac_alive": 0.6183810830116272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15/trainer_2": {
            "l2_loss": 63.84604949951172,
            "l1_loss": 781.8043701171875,
            "l0": 80.0,
            "frac_variance_explained": 0.886254632472992,
            "cossim": 0.9405465126037598,
            "l2_ratio": 0.9406228601932526,
            "relative_reconstruction_bias": 0.999057823419571,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 2.5650960922241213,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.988433837890625,
            "frac_alive": 0.4686957597732544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15/trainer_5": {
            "l2_loss": 41.20635986328125,
            "l1_loss": 3198.0086669921875,
            "l0": 640.0,
            "frac_variance_explained": 0.9310864806175232,
            "cossim": 0.9767521739006042,
            "l2_ratio": 0.9770789384841919,
            "relative_reconstruction_bias": 1.0002823233604432,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 2.4734957695007322,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.997559267282486,
            "frac_alive": 0.7078993320465088,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15/trainer_0": {
            "l2_loss": 82.05952911376953,
            "l1_loss": 387.8919372558594,
            "l0": 20.0,
            "frac_variance_explained": 0.7454514384269715,
            "cossim": 0.9057712197303772,
            "l2_ratio": 0.9036650419235229,
            "relative_reconstruction_bias": 0.9980986058712006,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 2.8554311752319337,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9594433963298797,
            "frac_alive": 0.1574435830116272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15/trainer_1": {
            "l2_loss": 73.52041473388672,
            "l1_loss": 528.9073120117188,
            "l0": 40.0,
            "frac_variance_explained": 0.7958128571510314,
            "cossim": 0.922706949710846,
            "l2_ratio": 0.9236413538455963,
            "relative_reconstruction_bias": 1.0000072419643402,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 2.6429500341415406,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.980656909942627,
            "frac_alive": 0.293511301279068,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3/trainer_4": {
            "l2_loss": 22.321846961975098,
            "l1_loss": 799.7821960449219,
            "l0": 320.0,
            "frac_variance_explained": 0.901763665676117,
            "cossim": 0.9601259887218475,
            "l2_ratio": 0.9598486363887787,
            "relative_reconstruction_bias": 0.9990402400493622,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 2.496252703666687,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9952966928482055,
            "frac_alive": 0.8234049677848816,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3/trainer_3": {
            "l2_loss": 23.478511238098143,
            "l1_loss": 456.1298492431641,
            "l0": 160.0,
            "frac_variance_explained": 0.8591484308242798,
            "cossim": 0.9525353133678436,
            "l2_ratio": 0.9534881770610809,
            "relative_reconstruction_bias": 1.0014338195323944,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 2.521990919113159,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.992733633518219,
            "frac_alive": 0.609971821308136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3/trainer_2": {
            "l2_loss": 25.94360065460205,
            "l1_loss": 327.79884033203126,
            "l0": 80.0,
            "frac_variance_explained": 0.8436449348926545,
            "cossim": 0.9419341802597045,
            "l2_ratio": 0.9421893358230591,
            "relative_reconstruction_bias": 1.000232994556427,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 2.544915461540222,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9904540121555329,
            "frac_alive": 0.4140625,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3/trainer_5": {
            "l2_loss": 19.113201332092284,
            "l1_loss": 1533.4474975585938,
            "l0": 640.0,
            "frac_variance_explained": 0.9071434438228607,
            "cossim": 0.9702927589416503,
            "l2_ratio": 0.9707047760486602,
            "relative_reconstruction_bias": 1.0007278263568877,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 2.4749300956726072,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9974163830280304,
            "frac_alive": 0.895616352558136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3/trainer_0": {
            "l2_loss": 28.266572570800783,
            "l1_loss": 177.4275115966797,
            "l0": 20.0,
            "frac_variance_explained": 0.8498155057430268,
            "cossim": 0.9323096394538879,
            "l2_ratio": 0.9319331288337708,
            "relative_reconstruction_bias": 0.9994702100753784,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 2.6027263402938843,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.984678465127945,
            "frac_alive": 0.1553819477558136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_3/trainer_1": {
            "l2_loss": 27.170896148681642,
            "l1_loss": 237.9600036621094,
            "l0": 40.0,
            "frac_variance_explained": 0.830749922990799,
            "cossim": 0.9341044247150421,
            "l2_ratio": 0.9342280626296997,
            "relative_reconstruction_bias": 0.9999212563037873,
            "loss_original": 2.4489264488220215,
            "loss_reconstructed": 2.568475842475891,
            "loss_zero": 12.452933025360107,
            "frac_recovered": 0.9880999863147736,
            "frac_alive": 0.2572157084941864,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_0_step_0": {
            "l2_loss": 190.2,
            "l1_loss": 152.6,
            "l0": 20.0,
            "frac_variance_explained": 0.063671875,
            "cossim": 0.2880859375,
            "l2_ratio": 0.18115234375,
            "relative_reconstruction_bias": 0.62890625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 11.478903865814209,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.09734811633825302,
            "frac_alive": 0.1331380158662796,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_0_step_15440": {
            "l2_loss": 84.0,
            "l1_loss": 361.8,
            "l0": 20.0,
            "frac_variance_explained": 0.698046875,
            "cossim": 0.8984375,
            "l2_ratio": 0.899609375,
            "relative_reconstruction_bias": 1.00390625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.894393467903137,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9547594070434571,
            "frac_alive": 0.156032994389534,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_3_step_154": {
            "l2_loss": 90.8,
            "l1_loss": 984.8,
            "l0": 160.0,
            "frac_variance_explained": 0.6703125,
            "cossim": 0.883984375,
            "l2_ratio": 0.89140625,
            "relative_reconstruction_bias": 1.003125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 3.0399241209030152,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9401364743709564,
            "frac_alive": 0.7928059697151184,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_2_step_154": {
            "l2_loss": 104.15,
            "l1_loss": 791.2,
            "l0": 80.0,
            "frac_variance_explained": 0.593359375,
            "cossim": 0.850390625,
            "l2_ratio": 0.86015625,
            "relative_reconstruction_bias": 1.004296875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 3.6241471767425537,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.8817910313606262,
            "frac_alive": 0.4998372495174408,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_2_step_1544": {
            "l2_loss": 75.45,
            "l1_loss": 650.4,
            "l0": 80.0,
            "frac_variance_explained": 0.7671875,
            "cossim": 0.9203125,
            "l2_ratio": 0.92109375,
            "relative_reconstruction_bias": 1.0,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.7256054162979124,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9716189205646515,
            "frac_alive": 0.4869791567325592,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_1_step_4882": {
            "l2_loss": 75.55,
            "l1_loss": 519.2,
            "l0": 40.0,
            "frac_variance_explained": 0.780078125,
            "cossim": 0.915234375,
            "l2_ratio": 0.917578125,
            "relative_reconstruction_bias": 1.001953125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.7118747234344482,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9729695200920105,
            "frac_alive": 0.29150390625,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_3_step_488": {
            "l2_loss": 78.55,
            "l1_loss": 882.4,
            "l0": 160.0,
            "frac_variance_explained": 0.75078125,
            "cossim": 0.913671875,
            "l2_ratio": 0.91796875,
            "relative_reconstruction_bias": 1.003125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.699724006652832,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9741968214511871,
            "frac_alive": 0.7721896767616272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_2_step_488": {
            "l2_loss": 82.4,
            "l1_loss": 661.6,
            "l0": 80.0,
            "frac_variance_explained": 0.72890625,
            "cossim": 0.903515625,
            "l2_ratio": 0.90703125,
            "relative_reconstruction_bias": 1.003125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.8219464302062987,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9619998276233673,
            "frac_alive": 0.4825846254825592,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_2_step_0": {
            "l2_loss": 178.5,
            "l1_loss": 544.8,
            "l0": 80.0,
            "frac_variance_explained": 0.17421875,
            "cossim": 0.469140625,
            "l2_ratio": 0.3478515625,
            "relative_reconstruction_bias": 0.741796875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 8.684722423553467,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.3766397684812546,
            "frac_alive": 0.31591796875,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_5_step_15440": {
            "l2_loss": 43.175,
            "l1_loss": 3017.6,
            "l0": 640.0,
            "frac_variance_explained": 0.9296875,
            "cossim": 0.974609375,
            "l2_ratio": 0.97578125,
            "relative_reconstruction_bias": 1.00078125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.469519329071045,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9971326410770416,
            "frac_alive": 0.762803852558136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_4_step_1544": {
            "l2_loss": 62.1,
            "l1_loss": 1234.4,
            "l0": 320.0,
            "frac_variance_explained": 0.84453125,
            "cossim": 0.94296875,
            "l2_ratio": 0.943359375,
            "relative_reconstruction_bias": 1.003125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.5427860260009765,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.989845073223114,
            "frac_alive": 0.9289821982383728,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_4_step_488": {
            "l2_loss": 71.6,
            "l1_loss": 1289.6,
            "l0": 320.0,
            "frac_variance_explained": 0.80625,
            "cossim": 0.930859375,
            "l2_ratio": 0.93359375,
            "relative_reconstruction_bias": 1.00234375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.6019895553588865,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9839423656463623,
            "frac_alive": 0.9495985507965088,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_5_step_488": {
            "l2_loss": 64.85,
            "l1_loss": 1758.4,
            "l0": 640.0,
            "frac_variance_explained": 0.8234375,
            "cossim": 0.93984375,
            "l2_ratio": 0.943359375,
            "relative_reconstruction_bias": 1.00546875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.5422339916229246,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9898876786231995,
            "frac_alive": 0.9901258945465088,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_5_step_48": {
            "l2_loss": 84.0,
            "l1_loss": 2200.0,
            "l0": 640.0,
            "frac_variance_explained": 0.735546875,
            "cossim": 0.902734375,
            "l2_ratio": 0.921875,
            "relative_reconstruction_bias": 1.015625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.6315461158752442,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9809844374656678,
            "frac_alive": 0.9978298544883728,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_2_step_15440": {
            "l2_loss": 66.225,
            "l1_loss": 721.6,
            "l0": 79.95416717529297,
            "frac_variance_explained": 0.83046875,
            "cossim": 0.938671875,
            "l2_ratio": 0.939453125,
            "relative_reconstruction_bias": 1.00234375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.573888349533081,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9867395639419556,
            "frac_alive": 0.464898020029068,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_3_step_1544": {
            "l2_loss": 71.85,
            "l1_loss": 874.0,
            "l0": 160.0,
            "frac_variance_explained": 0.785546875,
            "cossim": 0.928515625,
            "l2_ratio": 0.9328125,
            "relative_reconstruction_bias": 1.00390625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.617552089691162,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9823945164680481,
            "frac_alive": 0.7352430820465088,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_0_step_4882": {
            "l2_loss": 85.7,
            "l1_loss": 384.4,
            "l0": 20.0,
            "frac_variance_explained": 0.708203125,
            "cossim": 0.891015625,
            "l2_ratio": 0.891796875,
            "relative_reconstruction_bias": 0.99921875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.9751620054244996,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9467064619064331,
            "frac_alive": 0.1495768278837204,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_4_step_154": {
            "l2_loss": 81.8,
            "l1_loss": 1368.8,
            "l0": 320.0,
            "frac_variance_explained": 0.726953125,
            "cossim": 0.90625,
            "l2_ratio": 0.912890625,
            "relative_reconstruction_bias": 1.0046875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.7479029655456544,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9693350851535797,
            "frac_alive": 0.9601779580116272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_5_step_154": {
            "l2_loss": 71.35,
            "l1_loss": 1944.0,
            "l0": 640.0,
            "frac_variance_explained": 0.797265625,
            "cossim": 0.929296875,
            "l2_ratio": 0.93671875,
            "relative_reconstruction_bias": 1.00703125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.5808478593826294,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9860338687896728,
            "frac_alive": 0.99755859375,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_4_step_0": {
            "l2_loss": 148.2,
            "l1_loss": 1852.0,
            "l0": 320.0,
            "frac_variance_explained": 0.349609375,
            "cossim": 0.670703125,
            "l2_ratio": 0.7125,
            "relative_reconstruction_bias": 1.059375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 3.601191687583923,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.8842435717582703,
            "frac_alive": 0.587022602558136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_4_step_48": {
            "l2_loss": 98.5,
            "l1_loss": 1762.4,
            "l0": 320.0,
            "frac_variance_explained": 0.674609375,
            "cossim": 0.871875,
            "l2_ratio": 0.887890625,
            "relative_reconstruction_bias": 0.999609375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.8713510036468506,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9570393919944763,
            "frac_alive": 0.94921875,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_5_step_1544": {
            "l2_loss": 53.525,
            "l1_loss": 1890.4,
            "l0": 640.0,
            "frac_variance_explained": 0.878515625,
            "cossim": 0.96015625,
            "l2_ratio": 0.961328125,
            "relative_reconstruction_bias": 1.0015625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.4936158418655396,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9947379648685455,
            "frac_alive": 0.8681098222732544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_1_step_48": {
            "l2_loss": 131.0,
            "l1_loss": 419.0,
            "l0": 40.0,
            "frac_variance_explained": 0.29609375,
            "cossim": 0.745703125,
            "l2_ratio": 0.76328125,
            "relative_reconstruction_bias": 0.983984375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 5.11709246635437,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.7328206181526185,
            "frac_alive": 0.3245985209941864,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_5_step_4882": {
            "l2_loss": 48.35,
            "l1_loss": 2516.8,
            "l0": 640.0,
            "frac_variance_explained": 0.903515625,
            "cossim": 0.9671875,
            "l2_ratio": 0.968359375,
            "relative_reconstruction_bias": 1.003125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.4744928598403932,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9966399788856506,
            "frac_alive": 0.7989909052848816,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_4_step_15440": {
            "l2_loss": 53.075,
            "l1_loss": 1509.6,
            "l0": 319.62916870117186,
            "frac_variance_explained": 0.895703125,
            "cossim": 0.9609375,
            "l2_ratio": 0.960546875,
            "relative_reconstruction_bias": 1.00078125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.4898521900177,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9951108396053314,
            "frac_alive": 0.7687717080116272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_0_step_488": {
            "l2_loss": 97.6,
            "l1_loss": 375.0,
            "l0": 20.0,
            "frac_variance_explained": 0.62890625,
            "cossim": 0.8578125,
            "l2_ratio": 0.86171875,
            "relative_reconstruction_bias": 1.003125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 3.5767399787902834,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.8865642011165619,
            "frac_alive": 0.1312934011220932,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_1_step_488": {
            "l2_loss": 87.45,
            "l1_loss": 500.0,
            "l0": 40.0,
            "frac_variance_explained": 0.69296875,
            "cossim": 0.889453125,
            "l2_ratio": 0.892578125,
            "relative_reconstruction_bias": 1.0078125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 3.089809012413025,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9352370738983155,
            "frac_alive": 0.2636176347732544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_1_step_0": {
            "l2_loss": 187.6,
            "l1_loss": 291.6,
            "l0": 40.0,
            "frac_variance_explained": 0.109375,
            "cossim": 0.37265625,
            "l2_ratio": 0.24990234375,
            "relative_reconstruction_bias": 0.6703125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 10.446138095855712,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.20063219517469405,
            "frac_alive": 0.2118055522441864,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_0_step_1544": {
            "l2_loss": 90.3,
            "l1_loss": 397.0,
            "l0": 20.0,
            "frac_variance_explained": 0.68203125,
            "cossim": 0.884375,
            "l2_ratio": 0.889453125,
            "relative_reconstruction_bias": 1.00546875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 3.205756974220276,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9236590206623078,
            "frac_alive": 0.1467013955116272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_1_step_15440": {
            "l2_loss": 75.05,
            "l1_loss": 541.4,
            "l0": 40.0,
            "frac_variance_explained": 0.805859375,
            "cossim": 0.92421875,
            "l2_ratio": 0.924609375,
            "relative_reconstruction_bias": 1.00234375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.6645459651947023,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9777025818824768,
            "frac_alive": 0.2873263955116272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_3_step_4882": {
            "l2_loss": 64.3,
            "l1_loss": 904.4,
            "l0": 160.0,
            "frac_variance_explained": 0.830078125,
            "cossim": 0.94296875,
            "l2_ratio": 0.941796875,
            "relative_reconstruction_bias": 1.0015625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.5491158962249756,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9892117202281951,
            "frac_alive": 0.6984049677848816,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_3_step_0": {
            "l2_loss": 176.1,
            "l1_loss": 1064.0,
            "l0": 160.0,
            "frac_variance_explained": 0.25390625,
            "cossim": 0.56953125,
            "l2_ratio": 0.4927734375,
            "relative_reconstruction_bias": 0.853515625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 5.878991222381591,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.656810873746872,
            "frac_alive": 0.426812082529068,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_0_step_48": {
            "l2_loss": 139.5,
            "l1_loss": 253.1,
            "l0": 20.0,
            "frac_variance_explained": 0.210546875,
            "cossim": 0.703125,
            "l2_ratio": 0.7328125,
            "relative_reconstruction_bias": 0.9921875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 5.966889142990112,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.648001104593277,
            "frac_alive": 0.173828125,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_0_step_154": {
            "l2_loss": 125.6,
            "l1_loss": 367.8,
            "l0": 20.0,
            "frac_variance_explained": 0.396875,
            "cossim": 0.775390625,
            "l2_ratio": 0.791796875,
            "relative_reconstruction_bias": 0.996875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 4.913777303695679,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.7530180633068084,
            "frac_alive": 0.1446940153837204,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_1_step_154": {
            "l2_loss": 117.25,
            "l1_loss": 551.2,
            "l0": 40.0,
            "frac_variance_explained": 0.502734375,
            "cossim": 0.805859375,
            "l2_ratio": 0.832421875,
            "relative_reconstruction_bias": 1.0078125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 4.291177248954773,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.8151716470718384,
            "frac_alive": 0.265625,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_4_step_4882": {
            "l2_loss": 59.15,
            "l1_loss": 1327.2,
            "l0": 319.84583435058596,
            "frac_variance_explained": 0.874609375,
            "cossim": 0.9515625,
            "l2_ratio": 0.951171875,
            "relative_reconstruction_bias": 0.99921875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.515988826751709,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9925126552581787,
            "frac_alive": 0.9074435830116272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_2_step_48": {
            "l2_loss": 124.2,
            "l1_loss": 683.6,
            "l0": 80.0,
            "frac_variance_explained": 0.394140625,
            "cossim": 0.7765625,
            "l2_ratio": 0.7953125,
            "relative_reconstruction_bias": 0.993359375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 4.2204547882080075,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.8223262250423431,
            "frac_alive": 0.5598958134651184,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_1_step_1544": {
            "l2_loss": 81.2,
            "l1_loss": 540.4,
            "l0": 40.0,
            "frac_variance_explained": 0.75078125,
            "cossim": 0.906640625,
            "l2_ratio": 0.91171875,
            "relative_reconstruction_bias": 1.003125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.873250865936279,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9568659245967865,
            "frac_alive": 0.2742513120174408,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_3_step_48": {
            "l2_loss": 110.3,
            "l1_loss": 1083.6,
            "l0": 160.0,
            "frac_variance_explained": 0.525,
            "cossim": 0.824609375,
            "l2_ratio": 0.843359375,
            "relative_reconstruction_bias": 1.00859375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 3.4192012310028077,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9023053884506226,
            "frac_alive": 0.7994791865348816,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_2_step_4882": {
            "l2_loss": 69.35,
            "l1_loss": 658.8,
            "l0": 80.0,
            "frac_variance_explained": 0.797265625,
            "cossim": 0.9328125,
            "l2_ratio": 0.934375,
            "relative_reconstruction_bias": 1.003125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.605643391609192,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9835797488689423,
            "frac_alive": 0.4813910722732544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_3_step_15440": {
            "l2_loss": 61.4,
            "l1_loss": 1017.2,
            "l0": 159.88333435058593,
            "frac_variance_explained": 0.85546875,
            "cossim": 0.946875,
            "l2_ratio": 0.946875,
            "relative_reconstruction_bias": 1.001953125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.5257870674133303,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9915340363979339,
            "frac_alive": 0.6569553017616272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_15_checkpoints/trainer_5_step_0": {
            "l2_loss": 141.7,
            "l1_loss": 3342.4,
            "l0": 640.0,
            "frac_variance_explained": 0.334375,
            "cossim": 0.755078125,
            "l2_ratio": 1.02890625,
            "relative_reconstruction_bias": 1.36328125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.949670839309692,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9492510080337524,
            "frac_alive": 0.7532551884651184,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_0_step_0": {
            "l2_loss": 98.95,
            "l1_loss": 79.85,
            "l0": 20.0,
            "frac_variance_explained": 0.063671875,
            "cossim": 0.289453125,
            "l2_ratio": 0.18203125,
            "relative_reconstruction_bias": 0.6296875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 9.99864740371704,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.24520010501146317,
            "frac_alive": 0.1371527761220932,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_0_step_15440": {
            "l2_loss": 43.4,
            "l1_loss": 204.7,
            "l0": 20.0,
            "frac_variance_explained": 0.723828125,
            "cossim": 0.904296875,
            "l2_ratio": 0.90625,
            "relative_reconstruction_bias": 1.003125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.647126483917236,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9794343411922455,
            "frac_alive": 0.1592339426279068,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_3_step_154": {
            "l2_loss": 47.5,
            "l1_loss": 521.6,
            "l0": 160.0,
            "frac_variance_explained": 0.683203125,
            "cossim": 0.88671875,
            "l2_ratio": 0.8953125,
            "relative_reconstruction_bias": 1.0078125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.8128823041915894,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.962822437286377,
            "frac_alive": 0.8107096552848816,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_2_step_154": {
            "l2_loss": 53.275,
            "l1_loss": 364.4,
            "l0": 80.0,
            "frac_variance_explained": 0.58515625,
            "cossim": 0.852734375,
            "l2_ratio": 0.862890625,
            "relative_reconstruction_bias": 1.00625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 3.1309916734695435,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.931030935049057,
            "frac_alive": 0.5353190302848816,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_2_step_1544": {
            "l2_loss": 41.975,
            "l1_loss": 352.2,
            "l0": 80.0,
            "frac_variance_explained": 0.748046875,
            "cossim": 0.912109375,
            "l2_ratio": 0.915625,
            "relative_reconstruction_bias": 1.00234375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.60854709148407,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9832943916320801,
            "frac_alive": 0.5107964277267456,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_1_step_4882": {
            "l2_loss": 39.95,
            "l1_loss": 267.9,
            "l0": 40.0,
            "frac_variance_explained": 0.7640625,
            "cossim": 0.919140625,
            "l2_ratio": 0.920703125,
            "relative_reconstruction_bias": 1.0015625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.5750033855438232,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9866260170936585,
            "frac_alive": 0.284722238779068,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_3_step_488": {
            "l2_loss": 43.625,
            "l1_loss": 484.6,
            "l0": 160.0,
            "frac_variance_explained": 0.734765625,
            "cossim": 0.90859375,
            "l2_ratio": 0.9125,
            "relative_reconstruction_bias": 1.00625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.5914368867874145,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9849962055683136,
            "frac_alive": 0.7962239384651184,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_2_step_488": {
            "l2_loss": 44.15,
            "l1_loss": 343.0,
            "l0": 80.0,
            "frac_variance_explained": 0.7140625,
            "cossim": 0.903125,
            "l2_ratio": 0.90390625,
            "relative_reconstruction_bias": 0.996484375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.661093282699585,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9780488312244415,
            "frac_alive": 0.5080295205116272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_2_step_0": {
            "l2_loss": 92.3,
            "l1_loss": 286.2,
            "l0": 80.0,
            "frac_variance_explained": 0.183203125,
            "cossim": 0.47265625,
            "l2_ratio": 0.351171875,
            "relative_reconstruction_bias": 0.7421875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 8.09604024887085,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.4352301359176636,
            "frac_alive": 0.330620676279068,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_5_step_15440": {
            "l2_loss": 23.025,
            "l1_loss": 1850.4,
            "l0": 640.0,
            "frac_variance_explained": 0.921484375,
            "cossim": 0.973046875,
            "l2_ratio": 0.973828125,
            "relative_reconstruction_bias": 1.0,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.457998824119568,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9982805609703064,
            "frac_alive": 0.7088758945465088,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_4_step_1544": {
            "l2_loss": 34.7,
            "l1_loss": 658.8,
            "l0": 320.0,
            "frac_variance_explained": 0.827734375,
            "cossim": 0.941796875,
            "l2_ratio": 0.941015625,
            "relative_reconstruction_bias": 0.99921875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.506504034996033,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9934565842151641,
            "frac_alive": 0.941514790058136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_4_step_488": {
            "l2_loss": 39.5,
            "l1_loss": 665.2,
            "l0": 320.0,
            "frac_variance_explained": 0.77421875,
            "cossim": 0.923046875,
            "l2_ratio": 0.9265625,
            "relative_reconstruction_bias": 1.00390625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.537190818786621,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9904000639915467,
            "frac_alive": 0.953233540058136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_5_step_488": {
            "l2_loss": 34.5,
            "l1_loss": 942.4,
            "l0": 640.0,
            "frac_variance_explained": 0.830078125,
            "cossim": 0.942578125,
            "l2_ratio": 0.944140625,
            "relative_reconstruction_bias": 1.00390625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.4987658500671386,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9942247211933136,
            "frac_alive": 0.983506977558136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_5_step_48": {
            "l2_loss": 45.9,
            "l1_loss": 1130.4,
            "l0": 640.0,
            "frac_variance_explained": 0.709375,
            "cossim": 0.89921875,
            "l2_ratio": 0.91328125,
            "relative_reconstruction_bias": 1.0109375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.53686363697052,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9904285967350006,
            "frac_alive": 0.9985893964767456,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_2_step_15440": {
            "l2_loss": 35.2875,
            "l1_loss": 390.0,
            "l0": 80.0,
            "frac_variance_explained": 0.825,
            "cossim": 0.937890625,
            "l2_ratio": 0.938671875,
            "relative_reconstruction_bias": 1.00078125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.516243076324463,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9924913465976715,
            "frac_alive": 0.4480794370174408,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_3_step_1544": {
            "l2_loss": 37.625,
            "l1_loss": 467.8,
            "l0": 160.0,
            "frac_variance_explained": 0.789453125,
            "cossim": 0.928125,
            "l2_ratio": 0.932421875,
            "relative_reconstruction_bias": 1.00546875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.5421324014663695,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9899133086204529,
            "frac_alive": 0.7516276240348816,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_0_step_4882": {
            "l2_loss": 44.1,
            "l1_loss": 200.0,
            "l0": 20.0,
            "frac_variance_explained": 0.711328125,
            "cossim": 0.89921875,
            "l2_ratio": 0.898046875,
            "relative_reconstruction_bias": 0.99765625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.684427809715271,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.975710517168045,
            "frac_alive": 0.1566297709941864,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_4_step_154": {
            "l2_loss": 44.65,
            "l1_loss": 742.4,
            "l0": 320.0,
            "frac_variance_explained": 0.731640625,
            "cossim": 0.905859375,
            "l2_ratio": 0.91015625,
            "relative_reconstruction_bias": 1.0046875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.5959763288497926,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9845311343669891,
            "frac_alive": 0.9627821445465088,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_5_step_154": {
            "l2_loss": 38.05,
            "l1_loss": 1015.2,
            "l0": 640.0,
            "frac_variance_explained": 0.78984375,
            "cossim": 0.929296875,
            "l2_ratio": 0.934375,
            "relative_reconstruction_bias": 1.00625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.508847784996033,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9932186603546143,
            "frac_alive": 0.9986979365348816,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_4_step_0": {
            "l2_loss": 76.45,
            "l1_loss": 964.8,
            "l0": 320.0,
            "frac_variance_explained": 0.364453125,
            "cossim": 0.673046875,
            "l2_ratio": 0.71484375,
            "relative_reconstruction_bias": 1.06171875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 3.8941278219223023,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.8548661530017853,
            "frac_alive": 0.61083984375,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_4_step_48": {
            "l2_loss": 52.275,
            "l1_loss": 907.2,
            "l0": 320.0,
            "frac_variance_explained": 0.663671875,
            "cossim": 0.86796875,
            "l2_ratio": 0.87578125,
            "relative_reconstruction_bias": 1.00546875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.6827621698379516,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9758654475212097,
            "frac_alive": 0.9623481035232544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_5_step_1544": {
            "l2_loss": 30.6125,
            "l1_loss": 1098.8,
            "l0": 640.0,
            "frac_variance_explained": 0.87265625,
            "cossim": 0.95703125,
            "l2_ratio": 0.957421875,
            "relative_reconstruction_bias": 0.99921875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.4735523223876954,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9967362225055695,
            "frac_alive": 0.9080946445465088,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_1_step_48": {
            "l2_loss": 71.9,
            "l1_loss": 235.8,
            "l0": 40.0,
            "frac_variance_explained": 0.2984375,
            "cossim": 0.730859375,
            "l2_ratio": 0.7328125,
            "relative_reconstruction_bias": 0.985546875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 5.218111610412597,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.7227450847625733,
            "frac_alive": 0.3250325620174408,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_5_step_4882": {
            "l2_loss": 25.45,
            "l1_loss": 1432.8,
            "l0": 640.0,
            "frac_variance_explained": 0.902734375,
            "cossim": 0.966015625,
            "l2_ratio": 0.965625,
            "relative_reconstruction_bias": 0.99921875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.4615091562271116,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9979331851005554,
            "frac_alive": 0.8211262822151184,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_4_step_15440": {
            "l2_loss": 28.5125,
            "l1_loss": 846.8,
            "l0": 320.0,
            "frac_variance_explained": 0.8828125,
            "cossim": 0.96171875,
            "l2_ratio": 0.96171875,
            "relative_reconstruction_bias": 1.00078125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.4759001970291137,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.996501874923706,
            "frac_alive": 0.7259657382965088,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_0_step_488": {
            "l2_loss": 49.175,
            "l1_loss": 212.9,
            "l0": 20.0,
            "frac_variance_explained": 0.6734375,
            "cossim": 0.8734375,
            "l2_ratio": 0.878515625,
            "relative_reconstruction_bias": 1.00546875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 3.089528727531433,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9352387905120849,
            "frac_alive": 0.1478949636220932,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_1_step_488": {
            "l2_loss": 48.05,
            "l1_loss": 264.0,
            "l0": 40.0,
            "frac_variance_explained": 0.66875,
            "cossim": 0.881640625,
            "l2_ratio": 0.884375,
            "relative_reconstruction_bias": 1.003125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.8299009084701536,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9612075924873352,
            "frac_alive": 0.2823893129825592,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_1_step_0": {
            "l2_loss": 102.75,
            "l1_loss": 159.6,
            "l0": 40.0,
            "frac_variance_explained": 0.108203125,
            "cossim": 0.374609375,
            "l2_ratio": 0.25087890625,
            "relative_reconstruction_bias": 0.66875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 9.386548137664795,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.3063706010580063,
            "frac_alive": 0.2197808176279068,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_0_step_1544": {
            "l2_loss": 48.75,
            "l1_loss": 195.5,
            "l0": 20.0,
            "frac_variance_explained": 0.65078125,
            "cossim": 0.8796875,
            "l2_ratio": 0.88359375,
            "relative_reconstruction_bias": 1.00625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.8792571783065797,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.956269359588623,
            "frac_alive": 0.146484375,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_1_step_15440": {
            "l2_loss": 37.125,
            "l1_loss": 273.0,
            "l0": 40.0,
            "frac_variance_explained": 0.803515625,
            "cossim": 0.930078125,
            "l2_ratio": 0.930859375,
            "relative_reconstruction_bias": 1.00078125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.552605724334717,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9888627886772156,
            "frac_alive": 0.2864583432674408,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_3_step_4882": {
            "l2_loss": 34.8375,
            "l1_loss": 535.0,
            "l0": 160.0,
            "frac_variance_explained": 0.860546875,
            "cossim": 0.94140625,
            "l2_ratio": 0.941015625,
            "relative_reconstruction_bias": 0.9984375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.514176058769226,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9926984131336212,
            "frac_alive": 0.6957465410232544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_3_step_0": {
            "l2_loss": 86.15,
            "l1_loss": 534.8,
            "l0": 160.0,
            "frac_variance_explained": 0.27421875,
            "cossim": 0.575390625,
            "l2_ratio": 0.497265625,
            "relative_reconstruction_bias": 0.866796875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 5.911270380020142,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.6534240901470184,
            "frac_alive": 0.4622395932674408,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_0_step_48": {
            "l2_loss": 76.0,
            "l1_loss": 140.25,
            "l0": 20.0,
            "frac_variance_explained": 0.21015625,
            "cossim": 0.69375,
            "l2_ratio": 0.685546875,
            "relative_reconstruction_bias": 0.9703125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 6.198859167098999,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.6247840762138367,
            "frac_alive": 0.1758897602558136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_0_step_154": {
            "l2_loss": 67.775,
            "l1_loss": 207.0,
            "l0": 20.0,
            "frac_variance_explained": 0.424609375,
            "cossim": 0.771875,
            "l2_ratio": 0.785546875,
            "relative_reconstruction_bias": 0.980078125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 4.673088788986206,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.7770695388317108,
            "frac_alive": 0.1438802033662796,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_1_step_154": {
            "l2_loss": 59.9,
            "l1_loss": 304.2,
            "l0": 40.0,
            "frac_variance_explained": 0.523046875,
            "cossim": 0.812890625,
            "l2_ratio": 0.834375,
            "relative_reconstruction_bias": 1.01328125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 3.7924010515213014,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.8649622142314911,
            "frac_alive": 0.2794053852558136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_4_step_4882": {
            "l2_loss": 32.6,
            "l1_loss": 696.4,
            "l0": 320.0,
            "frac_variance_explained": 0.849609375,
            "cossim": 0.95,
            "l2_ratio": 0.95234375,
            "relative_reconstruction_bias": 1.00625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.489767813682556,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9951238095760345,
            "frac_alive": 0.8999565839767456,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_2_step_48": {
            "l2_loss": 66.6,
            "l1_loss": 368.0,
            "l0": 80.0,
            "frac_variance_explained": 0.38515625,
            "cossim": 0.7734375,
            "l2_ratio": 0.776171875,
            "relative_reconstruction_bias": 0.98984375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 4.262200713157654,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.8181838512420654,
            "frac_alive": 0.5559895634651184,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_1_step_1544": {
            "l2_loss": 44.275,
            "l1_loss": 263.3,
            "l0": 40.0,
            "frac_variance_explained": 0.714453125,
            "cossim": 0.90078125,
            "l2_ratio": 0.900390625,
            "relative_reconstruction_bias": 0.99921875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.692185115814209,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9749473631381989,
            "frac_alive": 0.27880859375,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_3_step_48": {
            "l2_loss": 58.8,
            "l1_loss": 563.6,
            "l0": 160.0,
            "frac_variance_explained": 0.516015625,
            "cossim": 0.822265625,
            "l2_ratio": 0.83046875,
            "relative_reconstruction_bias": 0.9984375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 3.1499987840652466,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9291528046131134,
            "frac_alive": 0.8151584267616272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_2_step_4882": {
            "l2_loss": 37.05,
            "l1_loss": 367.6,
            "l0": 80.0,
            "frac_variance_explained": 0.80390625,
            "cossim": 0.932421875,
            "l2_ratio": 0.9328125,
            "relative_reconstruction_bias": 1.00078125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.5410542249679566,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9900187611579895,
            "frac_alive": 0.4778103232383728,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_3_step_15440": {
            "l2_loss": 32.6,
            "l1_loss": 559.8,
            "l0": 160.0,
            "frac_variance_explained": 0.8609375,
            "cossim": 0.948828125,
            "l2_ratio": 0.949609375,
            "relative_reconstruction_bias": 1.00234375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.4919713020324705,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9949017584323883,
            "frac_alive": 0.6184895634651184,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_7_checkpoints/trainer_5_step_0": {
            "l2_loss": 72.8,
            "l1_loss": 1727.2,
            "l0": 640.0,
            "frac_variance_explained": 0.36171875,
            "cossim": 0.75859375,
            "l2_ratio": 1.03203125,
            "relative_reconstruction_bias": 1.3640625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.917159104347229,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9524367094039917,
            "frac_alive": 0.7743055820465088,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_0_step_0": {
            "l2_loss": 290.6,
            "l1_loss": 235.2,
            "l0": 20.0,
            "frac_variance_explained": 0.065234375,
            "cossim": 0.289453125,
            "l2_ratio": 0.18271484375,
            "relative_reconstruction_bias": 0.631640625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 11.838497161865234,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.06133820600807667,
            "frac_alive": 0.1409505158662796,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_0_step_15440": {
            "l2_loss": 126.2,
            "l1_loss": 588.8,
            "l0": 20.0,
            "frac_variance_explained": 0.72265625,
            "cossim": 0.901171875,
            "l2_ratio": 0.902734375,
            "relative_reconstruction_bias": 1.0,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.8494953393936155,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9592397749423981,
            "frac_alive": 0.1686197966337204,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_3_step_154": {
            "l2_loss": 147.7,
            "l1_loss": 1464.0,
            "l0": 160.0,
            "frac_variance_explained": 0.625390625,
            "cossim": 0.861328125,
            "l2_ratio": 0.87109375,
            "relative_reconstruction_bias": 1.00859375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 3.0243191957473754,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9417394459247589,
            "frac_alive": 0.830078125,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_2_step_154": {
            "l2_loss": 167.0,
            "l1_loss": 1076.0,
            "l0": 80.0,
            "frac_variance_explained": 0.5359375,
            "cossim": 0.82421875,
            "l2_ratio": 0.837890625,
            "relative_reconstruction_bias": 1.007421875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 3.4837981939315794,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.8958383560180664,
            "frac_alive": 0.5556640625,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_2_step_1544": {
            "l2_loss": 118.3,
            "l1_loss": 1036.0,
            "l0": 80.0,
            "frac_variance_explained": 0.759375,
            "cossim": 0.91328125,
            "l2_ratio": 0.91484375,
            "relative_reconstruction_bias": 1.0015625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.720684838294983,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9721010744571685,
            "frac_alive": 0.5036892294883728,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_1_step_4882": {
            "l2_loss": 114.75,
            "l1_loss": 768.4,
            "l0": 40.0,
            "frac_variance_explained": 0.7609375,
            "cossim": 0.915234375,
            "l2_ratio": 0.915625,
            "relative_reconstruction_bias": 1.00078125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.7129630565643312,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9728759765625,
            "frac_alive": 0.3045789897441864,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_3_step_488": {
            "l2_loss": 123.9,
            "l1_loss": 1403.2,
            "l0": 160.0,
            "frac_variance_explained": 0.730078125,
            "cossim": 0.9015625,
            "l2_ratio": 0.905078125,
            "relative_reconstruction_bias": 1.00390625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.7305481672286986,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9711121261119843,
            "frac_alive": 0.7883029580116272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_2_step_488": {
            "l2_loss": 127.95,
            "l1_loss": 1101.6,
            "l0": 80.0,
            "frac_variance_explained": 0.73359375,
            "cossim": 0.894921875,
            "l2_ratio": 0.898828125,
            "relative_reconstruction_bias": 1.00390625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.8188110113143923,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.962310516834259,
            "frac_alive": 0.5104166865348816,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_2_step_0": {
            "l2_loss": 277.2,
            "l1_loss": 850.4,
            "l0": 80.0,
            "frac_variance_explained": 0.171875,
            "cossim": 0.473046875,
            "l2_ratio": 0.3517578125,
            "relative_reconstruction_bias": 0.741015625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 7.440323400497436,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.5010212510824203,
            "frac_alive": 0.3150499165058136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_5_step_15440": {
            "l2_loss": 70.5,
            "l1_loss": 4704.0,
            "l0": 640.0,
            "frac_variance_explained": 0.91484375,
            "cossim": 0.969921875,
            "l2_ratio": 0.970703125,
            "relative_reconstruction_bias": 1.00078125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.4923532485961912,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9948698222637177,
            "frac_alive": 0.7985026240348816,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_4_step_1544": {
            "l2_loss": 97.6,
            "l1_loss": 1986.4,
            "l0": 320.0,
            "frac_variance_explained": 0.83359375,
            "cossim": 0.939453125,
            "l2_ratio": 0.9421875,
            "relative_reconstruction_bias": 1.0015625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.5706740856170653,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9870663106441497,
            "frac_alive": 0.9305012822151184,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_4_step_488": {
            "l2_loss": 116.2,
            "l1_loss": 2189.6,
            "l0": 320.0,
            "frac_variance_explained": 0.780078125,
            "cossim": 0.9203125,
            "l2_ratio": 0.92265625,
            "relative_reconstruction_bias": 1.004296875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.655140733718872,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9786317229270936,
            "frac_alive": 0.9635416865348816,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_5_step_488": {
            "l2_loss": 104.05,
            "l1_loss": 2830.4,
            "l0": 640.0,
            "frac_variance_explained": 0.8125,
            "cossim": 0.933984375,
            "l2_ratio": 0.937109375,
            "relative_reconstruction_bias": 1.00234375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.584867167472839,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9856380462646485,
            "frac_alive": 0.998046875,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_5_step_48": {
            "l2_loss": 132.45,
            "l1_loss": 3212.8,
            "l0": 640.0,
            "frac_variance_explained": 0.70234375,
            "cossim": 0.89296875,
            "l2_ratio": 0.909375,
            "relative_reconstruction_bias": 1.01328125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.699756073951721,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9741712868213653,
            "frac_alive": 0.99853515625,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_2_step_15440": {
            "l2_loss": 102.45,
            "l1_loss": 1077.6,
            "l0": 80.0,
            "frac_variance_explained": 0.8140625,
            "cossim": 0.9328125,
            "l2_ratio": 0.934375,
            "relative_reconstruction_bias": 1.0015625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.6034613132476805,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9837961971759797,
            "frac_alive": 0.4701063334941864,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_3_step_1544": {
            "l2_loss": 103.6,
            "l1_loss": 1430.4,
            "l0": 160.0,
            "frac_variance_explained": 0.8140625,
            "cossim": 0.933203125,
            "l2_ratio": 0.934375,
            "relative_reconstruction_bias": 1.0015625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.6129833221435548,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.982846474647522,
            "frac_alive": 0.7294921875,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_0_step_4882": {
            "l2_loss": 129.25,
            "l1_loss": 578.8,
            "l0": 20.0,
            "frac_variance_explained": 0.696484375,
            "cossim": 0.8890625,
            "l2_ratio": 0.8890625,
            "relative_reconstruction_bias": 1.00078125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.9045059442520142,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9537485361099243,
            "frac_alive": 0.1656358540058136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_4_step_154": {
            "l2_loss": 131.3,
            "l1_loss": 2309.6,
            "l0": 320.0,
            "frac_variance_explained": 0.729296875,
            "cossim": 0.895703125,
            "l2_ratio": 0.89921875,
            "relative_reconstruction_bias": 1.00234375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.7776209115982056,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9663821458816528,
            "frac_alive": 0.9741753339767456,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_5_step_154": {
            "l2_loss": 116.5,
            "l1_loss": 3238.4,
            "l0": 640.0,
            "frac_variance_explained": 0.7859375,
            "cossim": 0.915234375,
            "l2_ratio": 0.9203125,
            "relative_reconstruction_bias": 1.00625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.630190372467041,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9811166226863861,
            "frac_alive": 0.9990234375,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_4_step_0": {
            "l2_loss": 222.2,
            "l1_loss": 2817.6,
            "l0": 320.0,
            "frac_variance_explained": 0.358203125,
            "cossim": 0.67421875,
            "l2_ratio": 0.7171875,
            "relative_reconstruction_bias": 1.065625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 3.5219098329544067,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.8921224176883698,
            "frac_alive": 0.6167534589767456,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_4_step_48": {
            "l2_loss": 150.9,
            "l1_loss": 2267.2,
            "l0": 320.0,
            "frac_variance_explained": 0.603515625,
            "cossim": 0.854296875,
            "l2_ratio": 0.874609375,
            "relative_reconstruction_bias": 1.0125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.943194341659546,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9498593986034394,
            "frac_alive": 0.9683159589767456,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_5_step_1544": {
            "l2_loss": 88.6,
            "l1_loss": 2838.4,
            "l0": 640.0,
            "frac_variance_explained": 0.86015625,
            "cossim": 0.95078125,
            "l2_ratio": 0.953125,
            "relative_reconstruction_bias": 1.003125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.529343676567078,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9911853194236755,
            "frac_alive": 0.9651692509651184,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_1_step_48": {
            "l2_loss": 216.3,
            "l1_loss": 648.4,
            "l0": 40.0,
            "frac_variance_explained": 0.274609375,
            "cossim": 0.719921875,
            "l2_ratio": 0.730859375,
            "relative_reconstruction_bias": 0.96171875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 4.922332763671875,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.7522672057151795,
            "frac_alive": 0.3479275107383728,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_5_step_4882": {
            "l2_loss": 74.6,
            "l1_loss": 3915.2,
            "l0": 640.0,
            "frac_variance_explained": 0.909765625,
            "cossim": 0.965234375,
            "l2_ratio": 0.965234375,
            "relative_reconstruction_bias": 1.0,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.497997522354126,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9943046987056732,
            "frac_alive": 0.904893696308136,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_4_step_15440": {
            "l2_loss": 81.65,
            "l1_loss": 2379.2,
            "l0": 320.0,
            "frac_variance_explained": 0.881640625,
            "cossim": 0.958984375,
            "l2_ratio": 0.96015625,
            "relative_reconstruction_bias": 1.0015625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.5211398363113404,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9920058131217957,
            "frac_alive": 0.7404513955116272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_0_step_488": {
            "l2_loss": 150.1,
            "l1_loss": 557.6,
            "l0": 20.0,
            "frac_variance_explained": 0.610546875,
            "cossim": 0.85859375,
            "l2_ratio": 0.862109375,
            "relative_reconstruction_bias": 1.003515625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 3.230862021446228,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9211653947830201,
            "frac_alive": 0.150661900639534,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_1_step_488": {
            "l2_loss": 133.85,
            "l1_loss": 754.4,
            "l0": 40.0,
            "frac_variance_explained": 0.68203125,
            "cossim": 0.881640625,
            "l2_ratio": 0.881640625,
            "relative_reconstruction_bias": 1.0,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.949249505996704,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9492873609066009,
            "frac_alive": 0.2939453125,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_1_step_0": {
            "l2_loss": 282.8,
            "l1_loss": 444.8,
            "l0": 40.0,
            "frac_variance_explained": 0.109765625,
            "cossim": 0.375,
            "l2_ratio": 0.25234375,
            "relative_reconstruction_bias": 0.671875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 9.810188674926758,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.2641167253255844,
            "frac_alive": 0.2122938334941864,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_0_step_1544": {
            "l2_loss": 135.85,
            "l1_loss": 569.2,
            "l0": 20.0,
            "frac_variance_explained": 0.672265625,
            "cossim": 0.883203125,
            "l2_ratio": 0.886328125,
            "relative_reconstruction_bias": 1.001171875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 3.0247864961624145,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.941745525598526,
            "frac_alive": 0.1605902761220932,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_1_step_15440": {
            "l2_loss": 113.3,
            "l1_loss": 790.4,
            "l0": 40.0,
            "frac_variance_explained": 0.7765625,
            "cossim": 0.916796875,
            "l2_ratio": 0.918359375,
            "relative_reconstruction_bias": 0.99921875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.6750154972076414,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9766558885574341,
            "frac_alive": 0.3024088442325592,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_3_step_4882": {
            "l2_loss": 99.85,
            "l1_loss": 1436.8,
            "l0": 160.0,
            "frac_variance_explained": 0.819921875,
            "cossim": 0.93671875,
            "l2_ratio": 0.93515625,
            "relative_reconstruction_bias": 0.998046875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.5777201890945434,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9863627076148986,
            "frac_alive": 0.6957465410232544,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_3_step_0": {
            "l2_loss": 267.9,
            "l1_loss": 1635.2,
            "l0": 160.0,
            "frac_variance_explained": 0.25859375,
            "cossim": 0.575,
            "l2_ratio": 0.498828125,
            "relative_reconstruction_bias": 0.8546875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 4.914085578918457,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.75317023396492,
            "frac_alive": 0.451226145029068,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_0_step_48": {
            "l2_loss": 219.3,
            "l1_loss": 377.0,
            "l0": 20.0,
            "frac_variance_explained": 0.19375,
            "cossim": 0.6859375,
            "l2_ratio": 0.6953125,
            "relative_reconstruction_bias": 0.98515625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 5.777294731140136,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.6669279158115387,
            "frac_alive": 0.1839735209941864,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_0_step_154": {
            "l2_loss": 198.0,
            "l1_loss": 520.4,
            "l0": 20.0,
            "frac_variance_explained": 0.38984375,
            "cossim": 0.75703125,
            "l2_ratio": 0.7765625,
            "relative_reconstruction_bias": 0.98046875,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 4.558078384399414,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.7885506510734558,
            "frac_alive": 0.1609700471162796,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_1_step_154": {
            "l2_loss": 179.1,
            "l1_loss": 748.8,
            "l0": 40.0,
            "frac_variance_explained": 0.4484375,
            "cossim": 0.789453125,
            "l2_ratio": 0.821484375,
            "relative_reconstruction_bias": 1.0234375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 4.051023459434509,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.839172750711441,
            "frac_alive": 0.3034396767616272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_4_step_4882": {
            "l2_loss": 91.25,
            "l1_loss": 2033.6,
            "l0": 320.0,
            "frac_variance_explained": 0.8546875,
            "cossim": 0.95,
            "l2_ratio": 0.947265625,
            "relative_reconstruction_bias": 0.997265625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.538654351234436,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9902595639228821,
            "frac_alive": 0.8887261152267456,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_2_step_48": {
            "l2_loss": 189.4,
            "l1_loss": 993.6,
            "l0": 80.0,
            "frac_variance_explained": 0.37578125,
            "cossim": 0.7609375,
            "l2_ratio": 0.783203125,
            "relative_reconstruction_bias": 1.0109375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 4.112102770805359,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.8331315755844116,
            "frac_alive": 0.5949978232383728,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_1_step_1544": {
            "l2_loss": 128.05,
            "l1_loss": 763.6,
            "l0": 40.0,
            "frac_variance_explained": 0.710546875,
            "cossim": 0.896484375,
            "l2_ratio": 0.901171875,
            "relative_reconstruction_bias": 1.00625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.8199576854705812,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9621783435344696,
            "frac_alive": 0.2947591245174408,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_3_step_48": {
            "l2_loss": 172.6,
            "l1_loss": 1547.2,
            "l0": 160.0,
            "frac_variance_explained": 0.492578125,
            "cossim": 0.81171875,
            "l2_ratio": 0.82421875,
            "relative_reconstruction_bias": 1.003125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 3.4245002269744873,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9017863512039185,
            "frac_alive": 0.8332248330116272,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_2_step_4882": {
            "l2_loss": 105.05,
            "l1_loss": 1054.8,
            "l0": 80.0,
            "frac_variance_explained": 0.805859375,
            "cossim": 0.930078125,
            "l2_ratio": 0.930078125,
            "relative_reconstruction_bias": 0.9984375,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.62584183216095,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9815659761428833,
            "frac_alive": 0.4847005307674408,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_3_step_15440": {
            "l2_loss": 91.2,
            "l1_loss": 1544.0,
            "l0": 160.0,
            "frac_variance_explained": 0.852734375,
            "cossim": 0.94609375,
            "l2_ratio": 0.94609375,
            "relative_reconstruction_bias": 1.00078125,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 2.5553539514541628,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.988594776391983,
            "frac_alive": 0.6384548544883728,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        },
        "gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19_checkpoints/trainer_5_step_0": {
            "l2_loss": 217.4,
            "l1_loss": 5139.2,
            "l0": 640.0,
            "frac_variance_explained": 0.3359375,
            "cossim": 0.756640625,
            "l2_ratio": 1.034375,
            "relative_reconstruction_bias": 1.36640625,
            "loss_original": 2.440642213821411,
            "loss_reconstructed": 3.0001665115356446,
            "loss_zero": 12.452932643890382,
            "frac_recovered": 0.9441926419734955,
            "frac_alive": 0.7566189169883728,
            "hyperparameters": {
                "n_inputs": 250,
                "context_length": 128
            }
        }
    }
}