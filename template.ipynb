{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will display the dataframe containing SAEBench releases and saes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from sae_lens.toolkit.pretrained_saes_directory import get_pretrained_saes_directory\n",
    "\n",
    "# TODO: Make this nicer.\n",
    "df = pd.DataFrame.from_records(\n",
    "    {k: v.__dict__ for k, v in get_pretrained_saes_directory().items()}\n",
    ").T\n",
    "df.drop(\n",
    "    columns=[\"expected_var_explained\", \"expected_l0\", \"config_overrides\", \"conversion_func\"],\n",
    "    inplace=True,\n",
    ")\n",
    "filtered_df = df[\n",
    "    df.release.str.contains(\"bench\")\n",
    "]  # Each row is a \"release\" which has multiple SAEs which may have different configs / match different hook points in a model.\n",
    "\n",
    "print(filtered_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are 8 SAE Bench releases: 4 for Pythia and 4 for Gemma-2-2B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filtered_df.release)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each idea will contain a dict of sae_id: sae_name. The ids are used to load the SAEs into SAELens.\n",
    "\n",
    "We use the SAE names as keys in our results dictionaries, rather than the SAE ids. This is because the names are unique, and there's no possibility of mixing data between different SAEs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_release = \"sae_bench_gemma-2-2b_sweep_topk_ctx128_ef8_0824\"\n",
    "sae_id_to_name_map = filtered_df.saes_map[sae_release]\n",
    "sae_name_to_id_map = {v: k for k, v in sae_id_to_name_map.items()}\n",
    "\n",
    "print(f\"First sae id: {list(sae_id_to_name_map.keys())[0]}\")\n",
    "print(f\"First sae name: {list(sae_id_to_name_map.values())[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of loading a Pythia SAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sae_lens import SAE\n",
    "\n",
    "device = \"cpu\"\n",
    "sae, cfg_dict, sparsity = SAE.from_pretrained(\n",
    "    release=\"sae_bench_pythia70m_sweep_topk_ctx128_0730\",\n",
    "    sae_id=\"blocks.4.hook_resid_post__trainer_10\",\n",
    "    device=device,\n",
    ")\n",
    "sae = sae.to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is an example input of `sae_names` and `sae_release` for the `sparse_probing` eval function input. I'm using the names, not ids, to match the convention of our results dictionaries, but you could also pass in SAE ids if you prefer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_release = \"sae_bench_gemma-2-2b_sweep_topk_ctx128_ef8_0824\"\n",
    "\n",
    "sae_names = [\n",
    "    \"gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19/trainer_0\",\n",
    "    \"gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19/trainer_1\",\n",
    "    \"gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19/trainer_2\",\n",
    "    \"gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19/trainer_3\",\n",
    "    \"gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19/trainer_4\",\n",
    "    \"gemma-2-2b_sweep_topk_ctx128_ef8_0824/resid_post_layer_19/trainer_5\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already committed `sae_bench_data/{release_name}_data.json`. This contains the config used in the `dictionary_learning` repo, which includes training hyperparameters, SAE type, etc. It also contains the `basic_eval_results`, which includes the `l0` and `frac_recovered`, which was obtained using the `dictionary_learning evaluate()` function. These are already computed, so we can use them when making graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "release_name = \"sae_bench_gemma-2-2b_sweep_topk_ctx128_ef8_0824\"\n",
    "\n",
    "folder_path = \"sparse_probing/src/sparse_probing_results\"\n",
    "filename = f\"example_results_{release_name}_eval_results.json\"\n",
    "\n",
    "filepath = os.path.join(folder_path, filename)\n",
    "\n",
    "with open(filepath, \"r\") as f:\n",
    "    custom_eval_results = json.load(f)\n",
    "\n",
    "sae_data_filename = f\"sae_bench_data/{release_name}_data.json\"\n",
    "\n",
    "with open(sae_data_filename, \"r\") as f:\n",
    "    sae_data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, `sae_data` contains two keys: 'sae_config_dictionary_learning' and 'basic_eval_results'. Within each key, we have all SAE names for that release."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sae_data.keys())\n",
    "first_key = list(sae_data.keys())[0]\n",
    "print(list(sae_data[first_key].keys())[:5])\n",
    "first_sae_key = list(sae_data[first_key].keys())[0]\n",
    "print(\"\\n\", sae_data[first_key][first_sae_key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our custom eval results should look like the following. It should contain a `custom_eval_config` key, which contains all hyperparameters and config values to reproduce the results.\n",
    "\n",
    "`custom_eval_results` contains a dict, where every key is an SAE name, and every value is another dict containing various results from the eval. This dict can be immediately loaded in to `graph_sae_results.ipynb` to create various plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(custom_eval_results.keys())\n",
    "print(custom_eval_results[\"custom_eval_config\"])\n",
    "print(custom_eval_results[\"custom_eval_results\"][first_sae_key])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
